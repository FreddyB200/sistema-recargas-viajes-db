{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af3f2c89",
   "metadata": {},
   "source": [
    "# Data Generation and Insertion for Transport Database\n",
    "\n",
    "This notebook replaces the old SQL insert scripts with Python scripts for generating and inserting synthetic data into the database, using the new English schema. It uses Faker and pandas for data generation and manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f10dcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 25166 users...\n",
      "SQL script for users generated: /home/kali/Documents/remote reps/distributed-systems-lab/travel-recharge-database/db/data/generated_sql_scripts/1_insert_users.sql\n",
      "Generating 23202 cards (aiming for at least 20000 active)...\n",
      "SQL script for cards generated: /home/kali/Documents/remote reps/distributed-systems-lab/travel-recharge-database/db/data/generated_sql_scripts/2_insert_cards.sql\n",
      "Total active cards generated: 20643\n"
     ]
    }
   ],
   "source": [
    "import faker\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "# Initialize Faker for Colombian Spanish (to keep proper nouns in Spanish)\n",
    "# Using 'es_CO' for names, cities, addresses if bogota_address is not specific enough\n",
    "fake_co = faker.Faker('es_CO')\n",
    "# For more diverse international-looking names if needed for some users, though 'es_CO' is primary\n",
    "fake_generic = faker.Faker() # Can add other locales like fake_en = faker.Faker('en_US')\n",
    "\n",
    "\n",
    "def generate_bogota_address():\n",
    "    \"\"\"Generates a more plausible Bogota-style address.\"\"\"\n",
    "    street_type = random.choice([\"Calle\", \"Carrera\", \"Avenida\", \"Transversal\", \"Diagonal\"])\n",
    "    street_number = random.randint(1, 200)\n",
    "    \n",
    "    # Primary number, letter (optional), secondary number, complement (optional)\n",
    "    part1 = random.randint(1, 150)\n",
    "    part1_letter = random.choice([\"\", \"A\", \"B\", \"C\", \"Bis\"]) if random.random() > 0.5 else \"\"\n",
    "    part2 = random.randint(1, 99)\n",
    "    part3_complement = random.choice([\"\", f\" Interior {random.randint(1,10)}\", f\" Apartamento {random.randint(100,1000)}\", f\" Oficina {random.randint(10,50)}\"]) if random.random() > 0.7 else \"\"\n",
    "    \n",
    "    address_detail = f\"{part1}{part1_letter} # {part2}-{random.randint(1,50)}\"\n",
    "    \n",
    "    # Common neighborhoods in Bogota for added realism if desired, though Faker's city might be enough\n",
    "    # neighborhoods = [\"Chapinero\", \"Usaquén\", \"Suba\", \"Engativá\", \"Fontibón\", \"Kennedy\", \"Bosa\", \"Ciudad Bolívar\", \"Teusaquillo\", \"Barrios Unidos\"]\n",
    "    # neighborhood_detail = f\", {random.choice(neighborhoods)}\" if random.random() > 0.5 else \"\"\n",
    "    \n",
    "    return f\"{street_type} {street_number} {address_detail}\"\n",
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "output_folder = \"generated_sql_scripts\"\n",
    "users_output_file = os.path.join(output_folder, \"1_insert_users.sql\")\n",
    "cards_output_file = os.path.join(output_folder, \"2_insert_cards.sql\")\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Number of records - using ranges for realism\n",
    "# Target ~2.5M users\n",
    "num_users = random.randint(24500, 25500)\n",
    "\n",
    "# Target ~2M active cards (some users might have more than one card over time, but let's start with one active per user mostly)\n",
    "# Let's make it so that most users get one active card.\n",
    "# Total cards will be slightly more to account for some inactive/lost cards.\n",
    "num_total_cards = random.randint(23000, 24000)\n",
    "min_active_cards_target = 20000\n",
    "\n",
    "\n",
    "# --- Lists for Data Generation ---\n",
    "genders_list = ['M', 'F', 'O'] # O for Other\n",
    "\n",
    "# --- Generate Users ---\n",
    "print(f\"Generating {num_users} users...\")\n",
    "user_ids_generated = [] # To keep track of generated user_ids for card assignment\n",
    "\n",
    "with open(users_output_file, 'w', encoding='utf-8') as file:\n",
    "    file.write(\"INSERT INTO users (user_id, first_name, last_name, contact_number, email, gender, date_of_birth, residential_address, id_number, city_of_birth, registration_date) VALUES\\n\")\n",
    "\n",
    "    batch_size = 1000 # Insert 1000 records at a time then restart VALUES\n",
    "    for i in range(num_users):\n",
    "        user_id = i + 1 # Assuming user_id starts from 1 and is sequential for this script\n",
    "        user_ids_generated.append(user_id)\n",
    "\n",
    "        # Mix of Colombian and more generic names for wider appearance\n",
    "        if random.random() < 0.85: # 85% Colombian-style names\n",
    "            first_name_val = fake_co.first_name().replace(\"'\", \"''\")\n",
    "            last_name_val = fake_co.last_name().replace(\"'\", \"''\")\n",
    "        else:\n",
    "            first_name_val = fake_generic.first_name().replace(\"'\", \"''\")\n",
    "            last_name_val = fake_generic.last_name().replace(\"'\", \"''\")\n",
    "            \n",
    "        contact_number_val = fake_co.phone_number() # Colombian format\n",
    "        email_val = fake_co.unique.email() # Ensure unique email\n",
    "        gender_val = random.choice(genders_list)\n",
    "        \n",
    "        birth_date_obj = fake_co.date_of_birth(minimum_age=16, maximum_age=85)\n",
    "        date_of_birth_val = birth_date_obj.strftime('%Y-%m-%d')\n",
    "        \n",
    "        residential_address_val = generate_bogota_address().replace(\"'\", \"''\")\n",
    "        # Generate a unique national ID number (Cédula)\n",
    "        id_number_val = str(fake_co.unique.random_number(digits=10, fix_len=True))\n",
    "        \n",
    "        city_of_birth_val = fake_co.city().replace(\"'\", \"''\") # Colombian city\n",
    "        \n",
    "        registration_date_obj = fake_co.date_between(start_date='-10y', end_date='today')\n",
    "        registration_date_val = registration_date_obj.strftime('%Y-%m-%d')\n",
    "        \n",
    "        # SQL formatting\n",
    "        file.write(f\"({user_id}, '{first_name_val}', '{last_name_val}', '{contact_number_val}', '{email_val}', '{gender_val}', '{date_of_birth_val}', '{residential_address_val}', '{id_number_val}', '{city_of_birth_val}', '{registration_date_val}')\")\n",
    "\n",
    "        if (i + 1) % batch_size == 0 and i < num_users -1:\n",
    "            file.write(\";\\n\")\n",
    "            file.write(\"INSERT INTO users (user_id, first_name, last_name, contact_number, email, gender, date_of_birth, residential_address, id_number, city_of_birth, registration_date) VALUES\\n\")\n",
    "        elif i < num_users - 1:\n",
    "            file.write(\",\\n\")\n",
    "        else:\n",
    "            file.write(\";\\n\")\n",
    "            \n",
    "print(f\"SQL script for users generated: {os.path.abspath(users_output_file)}\")\n",
    "\n",
    "\n",
    "# --- Generate Cards ---\n",
    "print(f\"Generating {num_total_cards} cards (aiming for at least {min_active_cards_target} active)...\")\n",
    "active_cards_count = 0\n",
    "card_statuses = ['active', 'inactive', 'blocked', 'lost']\n",
    "\n",
    "with open(cards_output_file, 'w', encoding='utf-8') as file:\n",
    "    file.write(\"INSERT INTO cards (card_id, card_number, user_id, acquisition_date, status, balance, last_used_date, update_date) VALUES\\n\")\n",
    "    \n",
    "    assigned_users_for_cards = set() # To ensure a user gets at least one card if possible\n",
    "\n",
    "    for i in range(num_total_cards):\n",
    "        card_id = i + 1 # Assuming card_id starts from 1\n",
    "        \n",
    "        # Generate a unique card number (can be more complex if needed)\n",
    "        card_number_val = str(fake_co.unique.random_number(digits=16, fix_len=True))\n",
    "        \n",
    "        user_id_val = None\n",
    "        # Try to assign to a user who doesn't have many cards yet or ensure enough users get one\n",
    "        if user_ids_generated:\n",
    "            if len(assigned_users_for_cards) < len(user_ids_generated) and active_cards_count < min_active_cards_target :\n",
    "                 # Prioritize users who haven't been assigned a card yet for active cards\n",
    "                potential_users = [uid for uid in user_ids_generated if uid not in assigned_users_for_cards]\n",
    "                if potential_users:\n",
    "                    user_id_val = random.choice(potential_users)\n",
    "                    assigned_users_for_cards.add(user_id_val)\n",
    "                else: # all users got one, assign randomly\n",
    "                    user_id_val = random.choice(user_ids_generated)\n",
    "            else: # Random assignment after targets are met or if all users have one\n",
    "                 user_id_val = random.choice(user_ids_generated)\n",
    "\n",
    "\n",
    "        if user_id_val is None: # Fallback if no users somehow (should not happen with num_users > 0)\n",
    "            user_id_val = \"NULL\"\n",
    "\n",
    "\n",
    "        acquisition_date_obj = fake_co.date_between(start_date='-8y', end_date='today') # Card acquired after user registration potentially\n",
    "        acquisition_date_val = acquisition_date_obj.strftime('%Y-%m-%d')\n",
    "        \n",
    "        status_val = 'inactive' # Default\n",
    "        if active_cards_count < min_active_cards_target:\n",
    "            # Higher chance of being active until target is met\n",
    "            status_val = random.choices(card_statuses, weights=[0.9, 0.05, 0.03, 0.02], k=1)[0]\n",
    "        else:\n",
    "            # Normal distribution after target\n",
    "            status_val = random.choices(card_statuses, weights=[0.7, 0.15, 0.1, 0.05], k=1)[0]\n",
    "        \n",
    "        if status_val == 'active':\n",
    "            active_cards_count += 1\n",
    "            \n",
    "        balance_val = 0.0\n",
    "        if status_val == 'active' and random.random() < 0.8: # 80% of active cards have some balance\n",
    "            balance_val = round(random.uniform(1000, 50000) / 50) * 50 # Multiples of 50 COP\n",
    "            \n",
    "        last_used_date_val = \"NULL\"\n",
    "        if status_val == 'active' and random.random() < 0.9: # 90% of active cards have been used\n",
    "            last_used_datetime_obj = fake_co.date_time_between(start_date=acquisition_date_obj, end_date='now', tzinfo=None)\n",
    "            last_used_date_val = f\"'{last_used_datetime_obj.strftime('%Y-%m-%d %H:%M:%S')}'\"\n",
    "            \n",
    "        update_date_obj = fake_co.date_between(start_date=acquisition_date_obj, end_date='today')\n",
    "        update_date_val = update_date_obj.strftime('%Y-%m-%d')\n",
    "\n",
    "        file.write(f\"({card_id}, '{card_number_val}', {user_id_val}, '{acquisition_date_val}', '{status_val}', {balance_val}, {last_used_date_val}, '{update_date_val}')\")\n",
    "\n",
    "        if (i + 1) % batch_size == 0 and i < num_total_cards -1:\n",
    "            file.write(\";\\n\")\n",
    "            file.write(\"INSERT INTO cards (card_id, card_number, user_id, acquisition_date, status, balance, last_used_date, update_date) VALUES\\n\")\n",
    "        elif i < num_total_cards - 1:\n",
    "            file.write(\",\\n\")\n",
    "        else:\n",
    "            file.write(\";\\n\")\n",
    "\n",
    "print(f\"SQL script for cards generated: {os.path.abspath(cards_output_file)}\")\n",
    "print(f\"Total active cards generated: {active_cards_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84a8aa91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 13 locations (operational zones)...\n",
      "SQL script for locations generated: /home/kali/Documents/remote reps/distributed-systems-lab/travel-recharge-database/db/data/generated_sql_scripts/3_insert_locations.sql\n",
      "Generating 4834 recharge points...\n",
      "SQL script for recharge points generated: /home/kali/Documents/remote reps/distributed-systems-lab/travel-recharge-database/db/data/generated_sql_scripts/4_insert_recharge_points.sql\n"
     ]
    }
   ],
   "source": [
    "import faker\n",
    "import random\n",
    "from datetime import datetime\n",
    "import os\n",
    "import unicodedata\n",
    "\n",
    "# Initialize Faker for Colombian Spanish\n",
    "fake_co = faker.Faker('es_CO')\n",
    "\n",
    "# --- Configuration ---\n",
    "output_folder = \"generated_sql_scripts\" # Defined in the previous script\n",
    "locations_output_file = os.path.join(output_folder, \"3_insert_locations.sql\")\n",
    "recharge_points_output_file = os.path.join(output_folder, \"4_insert_recharge_points.sql\")\n",
    "\n",
    "# Ensure output directory exists (though previous script should have created it)\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Number of records\n",
    "num_locations = 13 # Based on \"13 Zonas de Operación\" [cite: 28]\n",
    "# Based on \"4,864 puntos de recarga externos\" [cite: 28]\n",
    "num_recharge_points = random.randint(4800, 4900)\n",
    "\n",
    "# Function to generate a more plausible Bogota-style address (can be shared across scripts)\n",
    "def generate_bogota_address_simple():\n",
    "    \"\"\"Generates a simplified plausible Bogota-style address for recharge points.\"\"\"\n",
    "    street_type = random.choice([\"Calle\", \"Carrera\", \"Avenida\", \"Transversal\", \"Diagonal\"])\n",
    "    street_number = random.randint(1, 200)\n",
    "    part1 = random.randint(1, 150)\n",
    "    part2 = random.randint(1, 99)\n",
    "    address_detail = f\"{part1} # {part2}-{random.randint(1,50)}\"\n",
    "    return f\"{street_type} {street_number} {address_detail}\"\n",
    "\n",
    "def slugify(text):\n",
    "    \"\"\"Converts text to a simple slug.\"\"\"\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('ascii')\n",
    "    text = text.lower().replace(' ', '_').replace('.', '').replace(',', '')\n",
    "    return text\n",
    "\n",
    "\n",
    "# --- Generate Locations (Zonas de Operación) ---\n",
    "print(f\"Generating {num_locations} locations (operational zones)...\")\n",
    "\n",
    "# Names based on zones mentioned or implied in the document [cite: 25]\n",
    "# Tunal, Sur, Américas, Calle 80, Norte, Suba, Usme, Engativá, San Cristóbal,\n",
    "# Usaquén, Fontibón, Kennedy, Ciudad Bolívar. We need 13.\n",
    "# Some from concessionaire zones[cite: 25]: Engativá, San Cristóbal, Usaquén, Calle 80, Tintal Zona Franca (use Fontibón for this), Bosa, Suba Oriental, Kennedy, Ciudad Bolívar, Fontibón, Usme, Suba Centro, Perdomo.\n",
    "# Let's refine the list to 13 distinct major zones often referenced.\n",
    "location_names_base = [\n",
    "    \"Usaquén\", \"Chapinero\", \"Santa Fe\", \"San Cristóbal\", \"Usme\", \"Tunjuelito\",\n",
    "    \"Bosa\", \"Kennedy\", \"Fontibón\", \"Engativá\", \"Suba\", \"Barrios Unidos\", \"Teusaquillo\"\n",
    "    # \"Puente Aranda\", \"Los Mártires\", \"Antonio Nariño\", \"Ciudad Bolívar\", \"Sumapaz\" # Other Localidades\n",
    "]\n",
    "if len(location_names_base) < num_locations:\n",
    "    location_names_base.extend([f\"Zona Operativa {i+1}\" for i in range(num_locations - len(location_names_base))])\n",
    "elif len(location_names_base) > num_locations:\n",
    "    location_names_base = random.sample(location_names_base, num_locations)\n",
    "\n",
    "\n",
    "location_ids_generated = []\n",
    "\n",
    "with open(locations_output_file, 'w', encoding='utf-8') as file:\n",
    "    file.write(\"INSERT INTO locations (location_id, name, description) VALUES\\n\")\n",
    "    batch_size = 1000\n",
    "\n",
    "    for i in range(num_locations):\n",
    "        location_id = i + 1 # Assuming location_id starts from 1\n",
    "        location_ids_generated.append(location_id)\n",
    "        \n",
    "        name_val = location_names_base[i].replace(\"'\", \"''\")\n",
    "        description_val = f\"Zona de operación {name_val} en Bogotá.\".replace(\"'\", \"''\")\n",
    "        \n",
    "        file.write(f\"({location_id}, '{name_val}', '{description_val}')\")\n",
    "        \n",
    "        if (i + 1) % batch_size == 0 and i < num_locations -1 :\n",
    "            file.write(\";\\n\")\n",
    "            file.write(\"INSERT INTO locations (location_id, name, description) VALUES\\n\")\n",
    "        elif i < num_locations - 1:\n",
    "            file.write(\",\\n\")\n",
    "        else:\n",
    "            file.write(\";\\n\")\n",
    "\n",
    "print(f\"SQL script for locations generated: {os.path.abspath(locations_output_file)}\")\n",
    "\n",
    "\n",
    "# --- Generate Recharge Points ---\n",
    "print(f\"Generating {num_recharge_points} recharge points...\")\n",
    "\n",
    "recharge_point_operators = [\"PuntoRed\", \"SuRed\", \"MoviiRed\", \"PagaTodo\", \"Station Kiosk\", \"Online Platform\"]\n",
    "\n",
    "with open(recharge_points_output_file, 'w', encoding='utf-8') as file:\n",
    "    file.write(\"INSERT INTO recharge_points (recharge_point_id, name, address, latitude, longitude, location_id, operator) VALUES\\n\")\n",
    "    batch_size = 1000\n",
    "\n",
    "    for i in range(num_recharge_points):\n",
    "        recharge_point_id = i + 1 # Assuming recharge_point_id starts from 1\n",
    "        \n",
    "        # Generate a plausible name for the recharge point\n",
    "        point_type = random.choice([\"Tienda\", \"Papelería\", \"Droguería\", \"Miscelánea\", \"Kiosko Estación\", \"Plataforma Web\"])\n",
    "        base_name_for_point = fake_co.company().split(' ')[0].replace(',', '') + \" \" + fake_co.street_name().split(' ')[-1]\n",
    "        name_val = f\"{point_type} {base_name_for_point}\".replace(\"'\", \"''\")\n",
    "        if \"Plataforma Web\" in name_val:\n",
    "            name_val = \"Plataforma de Recarga Online TransMilenio\" # Make it more unique if it's an online platform\n",
    "            address_val = \"NULL\" # No physical address for online\n",
    "            # Bogota's general coordinates for online services or use NULL\n",
    "            latitude_val = \"NULL\"\n",
    "            longitude_val = \"NULL\"\n",
    "            operator_val = \"Online Platform\"\n",
    "        else:\n",
    "            address_val = f\"'{generate_bogota_address_simple().replace(\"'\", \"''\")}'\"\n",
    "            # Generate Lat/Long for Bogotá (approximate bounds)\n",
    "            # Lat: 4.4 to 4.8, Lon: -74.0 to -74.2\n",
    "            latitude_val = round(random.uniform(4.400000, 4.800000), 6)\n",
    "            longitude_val = round(random.uniform(-74.200000, -74.000000), 6)\n",
    "            operator_val = random.choice(recharge_point_operators)\n",
    "\n",
    "\n",
    "        location_id_val = random.choice(location_ids_generated) if location_ids_generated else \"NULL\"\n",
    "        \n",
    "        file.write(f\"({recharge_point_id}, '{name_val}', {address_val}, {latitude_val}, {longitude_val}, {location_id_val}, '{operator_val}')\")\n",
    "\n",
    "        if (i + 1) % batch_size == 0 and i < num_recharge_points -1 :\n",
    "            file.write(\";\\n\")\n",
    "            file.write(\"INSERT INTO recharge_points (recharge_point_id, name, address, latitude, longitude, location_id, operator) VALUES\\n\")\n",
    "        elif i < num_recharge_points - 1:\n",
    "            file.write(\",\\n\")\n",
    "        else:\n",
    "            file.write(\";\\n\")\n",
    "            \n",
    "print(f\"SQL script for recharge points generated: {os.path.abspath(recharge_points_output_file)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0db248a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 71783 recharge records...\n",
      "SQL script for recharges generated: /home/kali/Documents/remote reps/distributed-systems-lab/travel-recharge-database/db/data/generated_sql_scripts/5_insert_recharges.sql\n"
     ]
    }
   ],
   "source": [
    "import faker\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "# Initialize Faker for Colombian Spanish\n",
    "fake_co = faker.Faker('es_CO')\n",
    "\n",
    "# --- Configuration ---\n",
    "output_folder = \"generated_sql_scripts\" # Defined in previous scripts\n",
    "recharges_output_file = os.path.join(output_folder, \"5_insert_recharges.sql\")\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Max IDs from previous scripts (using upper end of their generation ranges)\n",
    "# From 2_insert_cards.sql: num_total_cards = random.randint(2300000, 2400000)\n",
    "max_card_id = 24000\n",
    "# From 2_insert_cards.sql: min_active_cards_target = 2000000 (these cards should see more activity)\n",
    "assumed_active_card_threshold_id = 20000\n",
    "\n",
    "# From 4_insert_recharge_points.sql: num_recharge_points = random.randint(4800, 4900)\n",
    "max_recharge_point_id = 4900\n",
    "# Assume one of the recharge points was the \"Online Platform\" as per logic in 4_insert_recharge_points\n",
    "# For simplicity, let's assume the last ID could be an online one, or a specific known ID if designated.\n",
    "# For now, we'll treat all physical points similarly popular, with online being an option.\n",
    "\n",
    "# Number of recharge records\n",
    "num_recharges = random.randint(65000, 80000) # e.g., 7 million recharges (real file estimate)\n",
    "\n",
    "# Common recharge amounts in COP\n",
    "recharge_amounts_cop = [\n",
    "    3000, 3200, 3950, 7000, 10000, 11800, 15000, 20000, 23600, 30000, 70000, 50000, 100000\n",
    "]\n",
    "# Weights for these amounts (e.g., 10000 and 20000 are very common)\n",
    "recharge_amounts_weights = [\n",
    "    10, 5, 10, 20, 5, 25, 10, 5, 20, 5, 3, 10, 2\n",
    "]\n",
    "\n",
    "\n",
    "# --- Generate Recharges ---\n",
    "print(f\"Generating {num_recharges} recharge records...\")\n",
    "\n",
    "with open(recharges_output_file, 'w', encoding='utf-8') as file:\n",
    "    file.write(\"INSERT INTO recharges (recharge_id, card_id, recharge_point_id, amount, recharge_timestamp, transaction_id) VALUES\\n\")\n",
    "    \n",
    "    batch_size = 1000 # SQL statements per batch\n",
    "\n",
    "    for i in range(num_recharges):\n",
    "        recharge_id = i + 1 # Assuming recharge_id starts from 1\n",
    "\n",
    "        # Select card_id: Prioritize \"active\" cards\n",
    "        if random.random() < 0.85 and assumed_active_card_threshold_id > 0 : # 85% of recharges go to presumed active cards\n",
    "            card_id_val = random.randint(1, assumed_active_card_threshold_id)\n",
    "        else:\n",
    "            card_id_val = random.randint(1, max_card_id)\n",
    "\n",
    "        # Select recharge_point_id\n",
    "        # Give a slight preference to non-online points for more \"physical\" transactions\n",
    "        if random.random() < 0.05: # 5% chance of using the \"Online Platform\" (assuming it's the last ID or a known one)\n",
    "            # If the online platform was the last ID in recharge_points script:\n",
    "            recharge_point_id_val = max_recharge_point_id\n",
    "            # Or if it had a specific name/ID, you'd target that. For now, last ID is a placeholder.\n",
    "        else:\n",
    "            recharge_point_id_val = random.randint(1, max_recharge_point_id -1 if max_recharge_point_id > 1 else 1)\n",
    "\n",
    "\n",
    "        amount_val = random.choices(recharge_amounts_cop, weights=recharge_amounts_weights, k=1)[0]\n",
    "\n",
    "        # Simulate card acquisition date (consistent with card generation logic)\n",
    "        # Cards are acquired between 8 years ago and today.\n",
    "        # A card's recharges must happen after its acquisition.\n",
    "        # For simplicity, we simulate an acquisition window for each recharge event.\n",
    "        # A more complex approach would be to pre-generate acquisition dates for all cards.\n",
    "        # Here, we assume older cards (lower IDs) could have been acquired earlier.\n",
    "        years_ago_for_card = min(8, max(1, int(8 * (card_id_val / max_card_id)))) # Rough estimate: newer cards acquired more recently\n",
    "        \n",
    "        try:\n",
    "            # Simulate a plausible acquisition date for this specific card_id_val\n",
    "            # To ensure recharge_timestamp is after this.\n",
    "            simulated_acquisition_date = datetime.now() - timedelta(days=random.randint(30, years_ago_for_card * 365))\n",
    "            if simulated_acquisition_date > datetime.now() - timedelta(days=30): # Ensure it's at least 30 days old\n",
    "                simulated_acquisition_date = datetime.now() - timedelta(days=30)\n",
    "\n",
    "            recharge_datetime_obj = fake_co.date_time_between(start_date=simulated_acquisition_date, end_date='now', tzinfo=None)\n",
    "        except: # Fallback if date ranges are problematic\n",
    "             recharge_datetime_obj = fake_co.date_time_between(start_date='-5y', end_date='now', tzinfo=None)\n",
    "\n",
    "        recharge_timestamp_val = recharge_datetime_obj.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        transaction_id_val = str(uuid.uuid4())\n",
    "\n",
    "        # SQL formatting\n",
    "        file.write(f\"({recharge_id}, {card_id_val}, {recharge_point_id_val}, {amount_val}, '{recharge_timestamp_val}', '{transaction_id_val}')\")\n",
    "\n",
    "        if (i + 1) % batch_size == 0 and i < num_recharges - 1:\n",
    "            file.write(\";\\n\")\n",
    "            file.write(\"INSERT INTO recharges (recharge_id, card_id, recharge_point_id, amount, recharge_timestamp, transaction_id) VALUES\\n\")\n",
    "        elif i < num_recharges - 1:\n",
    "            file.write(\",\\n\")\n",
    "        else:\n",
    "            file.write(\";\\n\")\n",
    "            \n",
    "print(f\"SQL script for recharges generated: {os.path.abspath(recharges_output_file)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04479c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating concessionaire records...\n",
      "SQL script for concessionaires generated: /home/kali/Documents/remote reps/distributed-systems-lab/travel-recharge-database/db/data/generated_sql_scripts/6_insert_concessionaires.sql\n",
      "Generating depot records...\n",
      "SQL script for depots generated: /home/kali/Documents/remote reps/distributed-systems-lab/travel-recharge-database/db/data/generated_sql_scripts/7_insert_depots.sql\n"
     ]
    }
   ],
   "source": [
    "import faker\n",
    "import random\n",
    "import os\n",
    "import unicodedata\n",
    "\n",
    "# Initialize Faker for Colombian Spanish\n",
    "fake_co = faker.Faker('es_CO')\n",
    "\n",
    "# --- Configuration ---\n",
    "output_folder = \"generated_sql_scripts\"\n",
    "concessionaires_output_file = os.path.join(output_folder, \"6_insert_concessionaires.sql\")\n",
    "depots_output_file = os.path.join(output_folder, \"7_insert_depots.sql\")\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Max location_id from 3_insert_locations.sql (assuming 13 locations were generated)\n",
    "max_location_id = 13\n",
    "\n",
    "# Helper function (if not already defined in a shared utility)\n",
    "def generate_bogota_address_simple():\n",
    "    street_type = random.choice([\"Calle\", \"Carrera\", \"Avenida\", \"Transversal\", \"Diagonal\"])\n",
    "    street_number = random.randint(1, 200)\n",
    "    part1 = random.randint(1, 150)\n",
    "    part2 = random.randint(1, 99)\n",
    "    address_detail = f\"{part1} # {part2}-{random.randint(1,50)}\"\n",
    "    return f\"{street_type} {street_number} {address_detail}\"\n",
    "\n",
    "# --- Generate Concessionaires ---\n",
    "print(\"Generating concessionaire records...\")\n",
    "\n",
    "# Data extracted and consolidated from PDF page 7 [cite: 25] and page summary [cite: 24]\n",
    "concessionaire_data = [\n",
    "    {\"name\": \"Bogotá Móvil Operación Sur BMO SUR S.A.S\", \"troncal\": True, \"zonal_uce\": False, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"name\": \"Connexion Móvil S.A.S.\", \"troncal\": True, \"zonal_uce\": False, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"name\": \"Capitalbus S.A.S.\", \"troncal\": True, \"zonal_uce\": False, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"name\": \"SI18 Calle 80 S.A.S.\", \"troncal\": True, \"zonal_uce\": True, \"zonal_alimentacion\": False, \"cable\": False}, # Marked for Troncal and UCE (from ☑ ✓)\n",
    "    {\"name\": \"SI18 Norte S.A.S.\", \"troncal\": True, \"zonal_uce\": False, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"name\": \"SI18 Suba S.A.S.\", \"troncal\": True, \"zonal_uce\": False, \"zonal_alimentacion\": False, \"cable\": False}, # Marked for Troncal\n",
    "    {\"name\": \"Somos Bogotá Usme S.A.S.\", \"troncal\": True, \"zonal_uce\": False, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"name\": \"Gmovil S.A.S.\", \"troncal\": True, \"zonal_uce\": True, \"zonal_alimentacion\": True, \"cable\": False},\n",
    "    {\"name\": \"Consorcio Express S.A.S.\", \"troncal\": True, \"zonal_uce\": True, \"zonal_alimentacion\": True, \"cable\": False}, # Operates in multiple zones/types\n",
    "    {\"name\": \"Este Es Mi Bus S.A.S.\", \"troncal\": False, \"zonal_uce\": False, \"zonal_alimentacion\": True, \"cable\": False},\n",
    "    {\"name\": \"ETIB S.A.S.\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": True, \"cable\": False},\n",
    "    {\"name\": \"Masivo Capital S.A.S.\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": True, \"cable\": False}, # Operates in multiple zones/types\n",
    "    {\"name\": \"Organización Suma S.A.S.\", \"troncal\": False, \"zonal_uce\": False, \"zonal_alimentacion\": True, \"cable\": False},\n",
    "    {\"name\": \"E-Somos Fontibón S.A.S.\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": False, \"cable\": False}, # From Gran Americas Fontibon I group\n",
    "    {\"name\": \"Mueve Fontibón S.A.S.\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": False, \"cable\": False}, # From Gran Americas Fontibon I group\n",
    "    {\"name\": \"ZMO Fontibón III S.A.S.\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": False, \"cable\": False}, # From Gran Americas Fontibon I group\n",
    "    {\"name\": \"ZMO Fontíbón V S.A.S.\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": False, \"cable\": False}, # From Gran Americas Fontibon I group\n",
    "    {\"name\": \"Emasivo 10 S.A.S.\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": False, \"cable\": False}, # From Gran Americas Fontibon I group (Suba Centro UF 10)\n",
    "    {\"name\": \"Emasivo 16 S.A.S.\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": False, \"cable\": False}, # From Gran Americas Fontibon I group (Suba Centro UF 16)\n",
    "    {\"name\": \"Operadora Distrital de Transporte La Rolita\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"name\": \"E-Somos Alimentación S.A.S.\", \"troncal\": False, \"zonal_uce\": False, \"zonal_alimentacion\": True, \"cable\": False},\n",
    "    {\"name\": \"Gran Américas Usme S.A.S\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": False, \"cable\": False}, # Assuming UCE based on context if not specified\n",
    "    {\"name\": \"Mueve Usme S.A.S.\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": False, \"cable\": False}, # Assuming UCE\n",
    "    # Need to ensure we have 27 unique concessionaires as per document [cite: 24]\n",
    "    # The list above is 23. Adding a few more generic ones or specific ones if details are missed.\n",
    "    # Let's add a Cable operator explicitly\n",
    "    {\"name\": \"Cable Movil de Bogota S.A.S.\", \"troncal\": False, \"zonal_uce\": False, \"zonal_alimentacion\": False, \"cable\": True},\n",
    "    # Adding a few more zonal operators to reach near 27 count if needed, or assume some listed are distinct enough.\n",
    "    # For now, we have 24. Let's assume some from \"Gran Americas Fontibón I S.A.S.\" group are distinct enough.\n",
    "    # If the table on P7 is exhaustive of names, we might have fewer unique named entities if some are operational names vs legal.\n",
    "    # The PDF states \"Actualmente, el sistema cuenta con 27 concesionarios de operación\" [cite: 24]\n",
    "    # The table lists rows which sometimes repeat names for different zones. My list has 24 distinct names.\n",
    "    # I will add 3 more generic ones to match the 27 count.\n",
    "    {\"name\": \"Transportes Urbanos Integrados S.A.S.\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": True, \"cable\": False},\n",
    "    {\"name\": \"Movilidad Estratégica del Oriente S.A.\", \"troncal\": True, \"zonal_uce\": False, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"name\": \"Conexión Capital S.P.A.\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "]\n",
    "# Ensure we have exactly 27 for the script as per doc, or use the distinct ones from the table if preferred.\n",
    "# For this script, I will use the 27 from the list above.\n",
    "num_concessionaires_to_generate = len(concessionaire_data)\n",
    "concessionaire_ids_generated = []\n",
    "\n",
    "\n",
    "with open(concessionaires_output_file, 'w', encoding='utf-8') as file:\n",
    "    file.write(\"INSERT INTO concessionaires (concessionaire_id, name, operates_troncal, operates_zonal_uce, operates_zonal_alimentacion, operates_cable) VALUES\\n\")\n",
    "    batch_size = 1000\n",
    "\n",
    "    for i, data in enumerate(concessionaire_data):\n",
    "        concessionaire_id = i + 1\n",
    "        concessionaire_ids_generated.append(concessionaire_id)\n",
    "        \n",
    "        name_val = data[\"name\"].replace(\"'\", \"''\")\n",
    "        troncal_val = data[\"troncal\"]\n",
    "        zonal_uce_val = data[\"zonal_uce\"]\n",
    "        zonal_alim_val = data[\"zonal_alimentacion\"]\n",
    "        cable_val = data[\"cable\"]\n",
    "        \n",
    "        file.write(f\"({concessionaire_id}, '{name_val}', {troncal_val}, {zonal_uce_val}, {zonal_alim_val}, {cable_val})\")\n",
    "        \n",
    "        if (i + 1) % batch_size == 0 and i < num_concessionaires_to_generate -1:\n",
    "            file.write(\";\\n\")\n",
    "            file.write(\"INSERT INTO concessionaires (concessionaire_id, name, operates_troncal, operates_zonal_uce, operates_zonal_alimentacion, operates_cable) VALUES\\n\")\n",
    "        elif i < num_concessionaires_to_generate - 1:\n",
    "            file.write(\",\\n\")\n",
    "        else:\n",
    "            file.write(\";\\n\")\n",
    "            \n",
    "print(f\"SQL script for concessionaires generated: {os.path.abspath(concessionaires_output_file)}\")\n",
    "\n",
    "# --- Generate Depots ---\n",
    "print(\"Generating depot records...\")\n",
    "\n",
    "depot_specs = [\n",
    "    {\"type\": \"TALLER\", \"count\": 13, \"name_prefix\": \"Patio Taller Principal\"},\n",
    "    {\"type\": \"TRANSITORIO\", \"count\": 32, \"name_prefix\": \"Patio Transitorio\"},\n",
    "    {\"type\": \"ELECTRICO\", \"count\": 9, \"name_prefix\": \"ElectroPatio\"},\n",
    "    {\"type\": \"BAJAS_EMISIONES\", \"count\": 4, \"name_prefix\": \"Patio Eco\"}\n",
    "]\n",
    "total_depots_to_generate = sum(spec[\"count\"] for spec in depot_specs)\n",
    "depot_id_counter = 0\n",
    "\n",
    "with open(depots_output_file, 'w', encoding='utf-8') as file:\n",
    "    file.write(\"INSERT INTO depots (depot_id, name, address, depot_type, capacity_vehicles, location_id, concessionaire_id) VALUES\\n\")\n",
    "    batch_size = 1000\n",
    "    first_entry_in_batch = True\n",
    "\n",
    "    for spec in depot_specs:\n",
    "        for i in range(spec[\"count\"]):\n",
    "            depot_id_counter += 1\n",
    "            depot_id = depot_id_counter\n",
    "            \n",
    "            # Generate a unique name for the depot\n",
    "            zone_name_part = fake_co.city_suffix() # e.g., \"Norte\", \"Sur\", or a random word\n",
    "            name_val = f\"{spec['name_prefix']} {zone_name_part} {i+1}\".replace(\"'\", \"''\")\n",
    "            \n",
    "            address_val = generate_bogota_address_simple().replace(\"'\", \"''\")\n",
    "            depot_type_val = spec[\"type\"]\n",
    "            capacity_vehicles_val = random.randint(50, 300) # General capacity\n",
    "            if depot_type_val == \"TALLER\":\n",
    "                capacity_vehicles_val = random.randint(150, 500)\n",
    "            elif depot_type_val == \"ELECTRICO\":\n",
    "                capacity_vehicles_val = random.randint(80, 250)\n",
    "                \n",
    "            location_id_val = random.randint(1, max_location_id) if max_location_id > 0 else \"NULL\"\n",
    "            \n",
    "            # Assigning concessionaire_id can be random or based on some logic (e.g., type of depot)\n",
    "            # For now, random assignment, or could be NULL if not exclusively used.\n",
    "            concessionaire_id_val = random.choice(concessionaire_ids_generated) if concessionaire_ids_generated and random.random() > 0.3 else \"NULL\"\n",
    "\n",
    "            if not first_entry_in_batch:\n",
    "                file.write(\",\\n\")\n",
    "            else:\n",
    "                first_entry_in_batch = False\n",
    "\n",
    "            file.write(f\"({depot_id}, '{name_val}', '{address_val}', '{depot_type_val}', {capacity_vehicles_val}, {location_id_val}, {concessionaire_id_val})\")\n",
    "\n",
    "            if depot_id_counter % batch_size == 0 and depot_id_counter < total_depots_to_generate:\n",
    "                file.write(\";\\n\")\n",
    "                file.write(\"INSERT INTO depots (depot_id, name, address, depot_type, capacity_vehicles, location_id, concessionaire_id) VALUES\\n\")\n",
    "                first_entry_in_batch = True\n",
    "    \n",
    "    if depot_id_counter > 0 and depot_id_counter % batch_size != 0 : # Ensure the last batch ends with a semicolon\n",
    "         file.write(\";\\n\")\n",
    "    elif depot_id_counter == 0: # Handle empty file case\n",
    "        file.seek(0)\n",
    "        file.truncate()\n",
    "\n",
    "\n",
    "print(f\"SQL script for depots generated: {os.path.abspath(depots_output_file)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa3603e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating station records...\n",
      "SQL script for stations generated: /home/kali/Documents/remote reps/distributed-systems-lab/travel-recharge-database/db/data/generated_sql_scripts/8_insert_stations.sql\n",
      "Total stations generated: 7765\n"
     ]
    }
   ],
   "source": [
    "import faker\n",
    "import random\n",
    "import os\n",
    "import unicodedata\n",
    "\n",
    "# Initialize Faker for Colombian Spanish\n",
    "fake_co = faker.Faker('es_CO')\n",
    "\n",
    "# --- Configuration ---\n",
    "output_folder = \"generated_sql_scripts\"\n",
    "stations_output_file = os.path.join(output_folder, \"8_insert_stations.sql\")\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Max location_id from 3_insert_locations.sql (assuming 13 locations were generated)\n",
    "max_location_id = 13\n",
    "\n",
    "# Station counts from PDF\n",
    "NUM_PORTALS = 9\n",
    "NUM_CABLE_STATIONS = 4\n",
    "TOTAL_STATIONS_INC_CABLE = 142 # Includes portals and cable stations [cite: 14, 28]\n",
    "NUM_TRONCAL_STATIONS_OTHER = TOTAL_STATIONS_INC_CABLE - NUM_PORTALS - NUM_CABLE_STATIONS # Should be 129\n",
    "NUM_ZONAL_PARADEROS = 7623 # [cite: 19, 30]\n",
    "\n",
    "NUM_STATIONS_WITH_CYCLE_PARKING = 27 # [cite: 29]\n",
    "TOTAL_CYCLE_PARKING_SPOTS = 7351 # [cite: 29]\n",
    "\n",
    "# Station Names from PDF (page 16, 17) [cite: 66, 68, 71]\n",
    "portal_names_pdf = [\n",
    "    \"Portal Américas\", \"Cabecera Autopista Norte\", \"Portal Suba\", \"Cabecera Calle 80\",\n",
    "    \"Portal Sur - JFK Cooperativa Financiera\", \"Portal Eldorado\", \"Portal Tunal\", \"Portal 20 de Julio\", \"Cabecera Usme\"\n",
    "]\n",
    "# Ensure exactly NUM_PORTALS\n",
    "if len(portal_names_pdf) > NUM_PORTALS:\n",
    "    portal_names_pdf = portal_names_pdf[:NUM_PORTALS]\n",
    "elif len(portal_names_pdf) < NUM_PORTALS:\n",
    "    for i in range(NUM_PORTALS - len(portal_names_pdf)):\n",
    "        portal_names_pdf.append(f\"Portal Principal {chr(65+i)}\")\n",
    "\n",
    "\n",
    "troncal_station_names_pdf = [\n",
    "    \"SAN MATEO - C.C. UNISUR\", \"Calle 100 - Marketmedios\", \"Banderas\", \"Avenida Jiménez Centro\", # Changed \"Avenida Jimenez\" to be more specific\n",
    "    \"Toberín - Foundever\", \"Calle 76 - San Felipe\", \"TERREROS\", \"Calle 57 - Tecnoparque Sena\", \"Alcalá - Colegio Virgen del Pilar\", \"Calle 45 - American School Way\",\n",
    "    \"León XIII\", \"Despensa\", \"Bosa Estación\" # Soacha stations, Bosa adapted\n",
    "]\n",
    "# Add more common Troncal station names patterns\n",
    "generic_troncal_street_names = [f\"Calle {i}\" for i in range(10, 200, 5)]\n",
    "generic_troncal_av_names = [f\"Avenida {name}\" for name in [\"Chile\", \"Caracas\", \"NQS Central\", \"Ciudad de Cali\", \"Boyacá\", \"El Dorado\"]]\n",
    "generic_troncal_landmarks = [\"Universidades - CityU\", \"Museo Nacional\", \"CAD\", \"Paloquemao\", \"Ricaurte\", \"Sabana\", \"Profamilia\", \"Marly\", \"Flores\"]\n",
    "\n",
    "# TransMiCable station names (actual names for realism)\n",
    "cable_station_names = [\"Portal Tunal - Cable\", \"Juan Pablo II - Cable\", \"Manitas - Cable\", \"Mirador del Paraíso - Cable\"]\n",
    "\n",
    "# Helper function\n",
    "def generate_bogota_address_simple():\n",
    "    street_type = random.choice([\"Calle\", \"Carrera\", \"Avenida\", \"Transversal\", \"Diagonal\"])\n",
    "    street_number = random.randint(1, 200)\n",
    "    part1 = random.randint(1, 150)\n",
    "    part2 = random.randint(1, 99)\n",
    "    address_detail = f\"{part1} # {part2}-{random.randint(1,50)}\"\n",
    "    return f\"{street_type} {street_number} {address_detail}\"\n",
    "\n",
    "def generate_station_code(station_type, counter, zone_prefix=None):\n",
    "    if station_type == \"PORTAL\":\n",
    "        return f\"P{str(counter).zfill(2)}\"\n",
    "    elif station_type == \"CABLE\":\n",
    "        return f\"TC{str(counter).zfill(2)}\"\n",
    "    elif station_type.startswith(\"TRONCAL\"):\n",
    "        # Use a letter prefix for troncales (e.g., A-NQS, B-Autonorte, C-Suba, etc.)\n",
    "        # This is a simplification; real codes are more complex.\n",
    "        line_letter = chr(65 + random.randint(0, 10)) # A-K for different conceptual lines\n",
    "        return f\"{line_letter}{str(counter).zfill(2)}\"\n",
    "    elif station_type == \"ZONAL_PARADERO\":\n",
    "        # Mimic \"206A03\" [cite: 107]\n",
    "        part1 = zone_prefix if zone_prefix else str(random.randint(100,999))\n",
    "        part2 = chr(65 + random.randint(0,25)) # Random letter\n",
    "        part3 = str(counter).zfill(2) # Counter within that zone/letter combo (will not be unique globally here this way, needs global counter for part3 or make part1/part2 more unique)\n",
    "                                        # For script simplicity, we'll make counter global for this part\n",
    "        return f\"{part1}{part2}{str(counter % 100).zfill(2)}\" # modulo 100 for the last part to keep it 2 digits\n",
    "    return f\"UNK{str(counter).zfill(4)}\"\n",
    "\n",
    "# --- Generate Stations ---\n",
    "print(\"Generating station records...\")\n",
    "station_id_counter = 0\n",
    "all_station_records = []\n",
    "station_codes_generated = set() # To ensure uniqueness\n",
    "\n",
    "# Assign cycle parking\n",
    "# Distribute NUM_STATIONS_WITH_CYCLE_PARKING among portals and some troncal stations\n",
    "station_ids_for_cycle_parking = [] # Will store (station_id, type) for later spot assignment\n",
    "\n",
    "# --- 1. Portals ---\n",
    "portal_records = []\n",
    "for i in range(NUM_PORTALS):\n",
    "    station_id_counter += 1\n",
    "    name = portal_names_pdf[i].replace(\"'\", \"''\")\n",
    "    \n",
    "    code_prefix_num = 0 # Not strictly needed for portal code PXX\n",
    "    while True:\n",
    "        code = generate_station_code(\"PORTAL\", i + 1)\n",
    "        if code not in station_codes_generated:\n",
    "            station_codes_generated.add(code)\n",
    "            break\n",
    "        code_prefix_num +=1 # Should not happen for simple PXX\n",
    "\n",
    "    # Portals are major hubs, often with more amenities\n",
    "    has_parking = True # All portals get parking in this model\n",
    "    station_ids_for_cycle_parking.append({\"id\": station_id_counter, \"type\": \"PORTAL\"})\n",
    "\n",
    "    record = {\n",
    "        \"station_id\": station_id_counter,\n",
    "        \"name\": name,\n",
    "        \"station_code\": code,\n",
    "        \"station_type\": \"PORTAL\",\n",
    "        \"address\": f\"Portal {name}\".replace(\"'\", \"''\"),\n",
    "        \"location_id\": random.randint(1, max_location_id) if max_location_id > 0 else \"NULL\",\n",
    "        \"latitude\": round(random.uniform(4.45, 4.75), 6), # Spread out portals\n",
    "        \"longitude\": round(random.uniform(-74.18, -74.02), 6),\n",
    "        \"has_cycle_parking\": has_parking,\n",
    "        \"cycle_parking_spots\": 0, # Will be assigned later\n",
    "        \"is_active\": True\n",
    "    }\n",
    "    portal_records.append(record)\n",
    "all_station_records.extend(portal_records)\n",
    "\n",
    "# --- 2. Cable Stations ---\n",
    "cable_records = []\n",
    "for i in range(NUM_CABLE_STATIONS):\n",
    "    station_id_counter += 1\n",
    "    name = cable_station_names[i].replace(\"'\", \"''\")\n",
    "    \n",
    "    while True:\n",
    "        code = generate_station_code(\"CABLE\", i + 1)\n",
    "        if code not in station_codes_generated:\n",
    "            station_codes_generated.add(code)\n",
    "            break\n",
    "    \n",
    "    # Some cable stations might have cycle parking\n",
    "    has_parking = random.random() < 0.5\n",
    "    if has_parking and len(station_ids_for_cycle_parking) < NUM_STATIONS_WITH_CYCLE_PARKING:\n",
    "        station_ids_for_cycle_parking.append({\"id\": station_id_counter, \"type\": \"CABLE\"})\n",
    "    else:\n",
    "        has_parking = False\n",
    "\n",
    "\n",
    "    record = {\n",
    "        \"station_id\": station_id_counter,\n",
    "        \"name\": name,\n",
    "        \"station_code\": code,\n",
    "        \"station_type\": \"CABLE\",\n",
    "        \"address\": f\"Estación Cable {name}\".replace(\"'\", \"''\"),\n",
    "        \"location_id\": random.randint(1, max_location_id) if max_location_id > 0 else \"NULL\",\n",
    "        \"latitude\": round(random.uniform(4.50, 4.60), 6), # Cable cars often in specific hilly zones\n",
    "        \"longitude\": round(random.uniform(-74.15, -74.10), 6),\n",
    "        \"has_cycle_parking\": has_parking,\n",
    "        \"cycle_parking_spots\": 0,\n",
    "        \"is_active\": True\n",
    "    }\n",
    "    cable_records.append(record)\n",
    "all_station_records.extend(cable_records)\n",
    "\n",
    "# --- 3. Other Troncal Stations ---\n",
    "troncal_other_records = []\n",
    "available_troncal_names = troncal_station_names_pdf + \\\n",
    "                          [f\"{name_base} - {chr(65+i%5)}{i}\" for i, name_base in enumerate(generic_troncal_street_names * 2 + generic_troncal_av_names + generic_troncal_landmarks)]\n",
    "random.shuffle(available_troncal_names)\n",
    "\n",
    "troncal_code_counter = 0\n",
    "for i in range(NUM_TRONCAL_STATIONS_OTHER):\n",
    "    station_id_counter += 1\n",
    "    troncal_code_counter +=1\n",
    "    name = available_troncal_names[i % len(available_troncal_names)].replace(\"'\", \"''\") # Cycle through names\n",
    "    \n",
    "    station_type = random.choice([\"TRONCAL_SIMPLE\", \"TRONCAL_INTERMEDIA\", \"TRONCAL_CABECERA\"])\n",
    "    \n",
    "    while True:\n",
    "        code = generate_station_code(station_type, troncal_code_counter)\n",
    "        if code not in station_codes_generated:\n",
    "            station_codes_generated.add(code)\n",
    "            break\n",
    "        troncal_code_counter +=1 # Increment specific troncal counter to vary code\n",
    "\n",
    "    has_parking = False\n",
    "    if len(station_ids_for_cycle_parking) < NUM_STATIONS_WITH_CYCLE_PARKING and random.random() < 0.3: # Lower chance for non-portals\n",
    "        station_ids_for_cycle_parking.append({\"id\": station_id_counter, \"type\": station_type})\n",
    "        has_parking = True\n",
    "    \n",
    "    record = {\n",
    "        \"station_id\": station_id_counter,\n",
    "        \"name\": name,\n",
    "        \"station_code\": code,\n",
    "        \"station_type\": station_type,\n",
    "        \"address\": f\"Estación {name}\".replace(\"'\", \"''\"),\n",
    "        \"location_id\": random.randint(1, max_location_id) if max_location_id > 0 else \"NULL\",\n",
    "        \"latitude\": round(random.uniform(4.55, 4.70), 6), # Troncal stations along corridors\n",
    "        \"longitude\": round(random.uniform(-74.12, -74.05), 6),\n",
    "        \"has_cycle_parking\": has_parking,\n",
    "        \"cycle_parking_spots\": 0,\n",
    "        \"is_active\": True\n",
    "    }\n",
    "    troncal_other_records.append(record)\n",
    "all_station_records.extend(troncal_other_records)\n",
    "\n",
    "# Distribute cycle parking spots\n",
    "if station_ids_for_cycle_parking:\n",
    "    spots_per_station_avg = TOTAL_CYCLE_PARKING_SPOTS // len(station_ids_for_cycle_parking)\n",
    "    remaining_spots = TOTAL_CYCLE_PARKING_SPOTS % len(station_ids_for_cycle_parking)\n",
    "    \n",
    "    temp_spots_assignment = {}\n",
    "    for item in station_ids_for_cycle_parking:\n",
    "        base_spots = spots_per_station_avg\n",
    "        if item[\"type\"] == \"PORTAL\": # Portals get more\n",
    "            base_spots = int(spots_per_station_avg * random.uniform(1.2, 2.0))\n",
    "        elif item[\"type\"] == \"TRONCAL_INTERMEDIA\" or item[\"type\"] == \"TRONCAL_CABECERA\":\n",
    "            base_spots = int(spots_per_station_avg * random.uniform(0.8, 1.2))\n",
    "        else: # Cable, Troncal_Simple\n",
    "             base_spots = int(spots_per_station_avg * random.uniform(0.5, 0.8))\n",
    "        temp_spots_assignment[item[\"id\"]] = max(10, base_spots) # Minimum 10 spots if it has parking\n",
    "\n",
    "    # Normalize to match TOTAL_CYCLE_PARKING_SPOTS\n",
    "    current_assigned_total = sum(temp_spots_assignment.values())\n",
    "    if current_assigned_total > 0:\n",
    "        factor = TOTAL_CYCLE_PARKING_SPOTS / current_assigned_total\n",
    "        final_spots_assignment = {}\n",
    "        normalized_total = 0\n",
    "        for station_id_pk, spots in temp_spots_assignment.items():\n",
    "            assigned = int(spots * factor)\n",
    "            final_spots_assignment[station_id_pk] = assigned\n",
    "            normalized_total += assigned\n",
    "        \n",
    "        # Distribute any rounding difference to the first few stations\n",
    "        diff = TOTAL_CYCLE_PARKING_SPOTS - normalized_total\n",
    "        for station_id_pk in final_spots_assignment.keys():\n",
    "            if diff == 0: break\n",
    "            final_spots_assignment[station_id_pk] += 1\n",
    "            diff -=1\n",
    "            if diff == 0: break\n",
    "\n",
    "        for station_record in all_station_records:\n",
    "            if station_record[\"station_id\"] in final_spots_assignment:\n",
    "                station_record[\"cycle_parking_spots\"] = final_spots_assignment[station_record[\"station_id\"]]\n",
    "            # Ensure has_cycle_parking is True if spots > 0\n",
    "            if station_record[\"cycle_parking_spots\"] > 0:\n",
    "                 station_record[\"has_cycle_parking\"] = True\n",
    "            elif station_record[\"has_cycle_parking\"] and station_record[\"cycle_parking_spots\"] == 0 : # Had parking flag but no spots assigned\n",
    "                 station_record[\"has_cycle_parking\"] = False\n",
    "\n",
    "\n",
    "# --- 4. Zonal Paraderos ---\n",
    "zonal_paradero_records = []\n",
    "paradero_code_main_counter = 0\n",
    "paradero_zone_prefixes = [str(random.randint(100, 999)) for _ in range(max_location_id if max_location_id > 0 else 1)] # One prefix per location\n",
    "\n",
    "for i in range(NUM_ZONAL_PARADEROS):\n",
    "    station_id_counter += 1\n",
    "    paradero_code_main_counter +=1\n",
    "\n",
    "    loc_id = random.randint(1, max_location_id) if max_location_id > 0 else 1\n",
    "    # Use street name for paradero name for simplicity\n",
    "    name = f\"Paradero {fake_co.street_name()} - {fake_co.street_suffix()}\".replace(\"'\", \"''\")\n",
    "    \n",
    "    while True: # Find unique code\n",
    "        code = generate_station_code(\"ZONAL_PARADERO\", paradero_code_main_counter, zone_prefix=paradero_zone_prefixes[loc_id-1])\n",
    "        if code not in station_codes_generated:\n",
    "            station_codes_generated.add(code)\n",
    "            break\n",
    "        paradero_code_main_counter += 1 # Ensure next attempt gets a new number part for code\n",
    "\n",
    "    record = {\n",
    "        \"station_id\": station_id_counter,\n",
    "        \"name\": name,\n",
    "        \"station_code\": code,\n",
    "        \"station_type\": \"ZONAL_PARADERO\",\n",
    "        \"address\": f\"{name}, Bogotá\".replace(\"'\", \"''\"), # Simplified address\n",
    "        \"location_id\": loc_id,\n",
    "        \"latitude\": round(random.uniform(4.40, 4.80), 6), # Paraderos are widespread\n",
    "        \"longitude\": round(random.uniform(-74.20, -74.00), 6),\n",
    "        \"has_cycle_parking\": False, # Generally no cycle parking at paraderos\n",
    "        \"cycle_parking_spots\": 0,\n",
    "        \"is_active\": True\n",
    "    }\n",
    "    zonal_paradero_records.append(record)\n",
    "all_station_records.extend(zonal_paradero_records)\n",
    "\n",
    "\n",
    "# --- Write to SQL file ---\n",
    "with open(stations_output_file, 'w', encoding='utf-8') as file:\n",
    "    file.write(\"INSERT INTO stations (station_id, name, station_code, station_type, address, location_id, latitude, longitude, has_cycle_parking, cycle_parking_spots, is_active) VALUES\\n\")\n",
    "    \n",
    "    batch_size = 1000\n",
    "    total_records = len(all_station_records)\n",
    "\n",
    "    for i, record in enumerate(all_station_records):\n",
    "        # Ensure location_id is not NULL string if it's meant to be integer or actual NULL\n",
    "        loc_id_val = record['location_id'] if isinstance(record['location_id'], int) else \"NULL\"\n",
    "\n",
    "        file.write(f\"({record['station_id']}, '{record['name']}', '{record['station_code']}', '{record['station_type']}', '{record['address']}', \"\n",
    "                   f\"{loc_id_val}, {record['latitude']}, {record['longitude']}, {record['has_cycle_parking']}, \"\n",
    "                   f\"{record['cycle_parking_spots']}, {record['is_active']})\")\n",
    "\n",
    "        if (i + 1) % batch_size == 0 and i < total_records - 1:\n",
    "            file.write(\";\\n\")\n",
    "            file.write(\"INSERT INTO stations (station_id, name, station_code, station_type, address, location_id, latitude, longitude, has_cycle_parking, cycle_parking_spots, is_active) VALUES\\n\")\n",
    "        elif i < total_records - 1:\n",
    "            file.write(\",\\n\")\n",
    "        else:\n",
    "            file.write(\";\\n\")\n",
    "\n",
    "print(f\"SQL script for stations generated: {os.path.abspath(stations_output_file)}\")\n",
    "print(f\"Total stations generated: {station_id_counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebc2bb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 10563 vehicle records...\n",
      "Generating 24446 driver records...\n",
      "SQL script for vehicles and drivers generated: /home/kali/Documents/remote reps/distributed-systems-lab/travel-recharge-database/db/data/generated_sql_scripts/9_insert_vehicles_and_drivers.sql\n"
     ]
    }
   ],
   "source": [
    "import faker\n",
    "import random\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Initialize Faker for Colombian Spanish\n",
    "fake_co = faker.Faker('es_CO')\n",
    "\n",
    "# --- Configuration ---\n",
    "output_folder = \"generated_sql_scripts\"\n",
    "vehicles_drivers_output_file = os.path.join(output_folder, \"9_insert_vehicles_and_drivers.sql\")\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Max IDs from previous scripts\n",
    "# From 6_insert_concessionaires.sql (assuming 27 concessionaires were generated)\n",
    "max_concessionaire_id = 27\n",
    "# From 7_insert_depots.sql (assuming 58 depots were generated)\n",
    "max_depot_id = 58\n",
    "\n",
    "\n",
    "# Vehicle specifications from PDF (Page 10)\n",
    "vehicle_specs = [\n",
    "    {\"type\": \"ALIMENTADOR_50\", \"capacity\": 50, \"count\": 86, \"component\": \"ALIMENTACION\"},\n",
    "    {\"type\": \"ALIMENTADOR_80\", \"capacity\": 80, \"count\": 862, \"component\": \"ALIMENTACION\"},\n",
    "    {\"type\": \"ARTICULADO\", \"capacity\": 160, \"count\": 602, \"component\": \"TRONCAL\"}, # Typical capacity\n",
    "    {\"type\": \"BIARTICULADO\", \"capacity\": 250, \"count\": 1317, \"component\": \"TRONCAL\"}, # Typical capacity\n",
    "    {\"type\": \"PADRON_DUAL\", \"capacity\": 80, \"count\": 272, \"component\": \"TRONCAL\"}, # Operates on Troncal/Zonal\n",
    "    {\"type\": \"BUS_19\", \"capacity\": 19, \"count\": 5, \"component\": \"ZONAL\"},\n",
    "    {\"type\": \"BUS_40\", \"capacity\": 40, \"count\": 611, \"component\": \"ZONAL\"},\n",
    "    {\"type\": \"BUS_50\", \"capacity\": 50, \"count\": 3511, \"component\": \"ZONAL\"},\n",
    "    {\"type\": \"BUS_80\", \"capacity\": 80, \"count\": 3297, \"component\": \"ZONAL\"},\n",
    "]\n",
    "total_vehicles_from_spec = sum(spec[\"count\"] for spec in vehicle_specs) # Should be 10563\n",
    "\n",
    "technology_counts = {\n",
    "    \"ELECTRICO\": 1486,\n",
    "    \"GNV\": 2144,\n",
    "    \"HIBRIDO\": 348,\n",
    "    \"DIESEL_EURO_VI\": 2382,\n",
    "    \"DIESEL_EURO_V\": 4162,\n",
    "}\n",
    "total_tech_vehicles = sum(technology_counts.values()) # 10522\n",
    "# Distribute the remainder (10563 - 10522 = 41) to Diesel Euro V as it's the largest diesel category\n",
    "technology_counts[\"DIESEL_EURO_V\"] += (total_vehicles_from_spec - total_tech_vehicles)\n",
    "\n",
    "\n",
    "# Model year distribution from PDF (Page 10 \"FLOTA POR MODELO\") - approximate\n",
    "model_year_pdf_counts = {\n",
    "    2023: 336, 2022: 1007, 2021: 1799, 2020: 1624, 2019: 313,\n",
    "    2017: 63, 2016: 160, 2015: 1264, 2014: 333, 2013: 335,\n",
    "    2012: 292, 2011: 142, 2010: 234, 2009: 53, 2008: 15\n",
    "}\n",
    "total_vehicles_in_year_dist = sum(model_year_pdf_counts.values()) # approx 7670\n",
    "\n",
    "# Driver counts from PDF (Page 9)\n",
    "driver_counts_component = {\n",
    "    \"TRONCAL\": 5003,\n",
    "    \"ZONAL_UCE\": 16544, # For Zonal UCE component\n",
    "    \"ALIMENTACION\": 2899 # For Zonal Alimentacion component\n",
    "}\n",
    "total_drivers_to_generate = sum(driver_counts_component.values()) # 24446\n",
    "\n",
    "# Helper to get concessionaire IDs by operational type (mocked, real script would query DB or use generated list)\n",
    "# This needs to be based on the actual 'concessionaire_data' from script 6.\n",
    "# For now, I'll create a placeholder list based on the structure of that data\n",
    "# Placeholder for concessionaire types - this should align with output of 6_insert_concessionaires.sql\n",
    "# In a real scenario, you'd fetch this or have access to the list of concessionaires and their types.\n",
    "# Let's assume we have access to `concessionaire_ids_generated` and their types from script 6.\n",
    "# For this script, I'll make a simplified assignment logic.\n",
    "# We know concessionaire IDs are 1 to max_concessionaire_id (27)\n",
    "# We'll need to map these to their operational capabilities.\n",
    "# This is a simplification:\n",
    "concessionaires_by_type = {\n",
    "    \"TRONCAL\": [cid for cid in range(1, 11)], # First 10\n",
    "    \"ZONAL_UCE\": [cid for cid in range(11, 25)], # Next 14 for Zonal\n",
    "    \"ALIMENTACION\": [cid for cid in range(18, 28)], # Some overlap, some specific\n",
    "    \"CABLE\": [25] # Assume one specific ID for Cable\n",
    "}\n",
    "# A more robust way would be to use the flags (operates_troncal etc.) from the concessionaire generation.\n",
    "# Let's assume:\n",
    "# IDs 1-10: Troncal focused (some may also do Zonal)\n",
    "# IDs 11-26: Zonal/Alimentacion focused\n",
    "# ID 27: Cable focused\n",
    "# This is a broad simplification for assigning vehicles/drivers.\n",
    "\n",
    "# --- Generate Vehicles ---\n",
    "print(f\"Generating {total_vehicles_from_spec} vehicle records...\")\n",
    "all_vehicle_records = []\n",
    "vehicle_id_counter = 0\n",
    "assigned_tech_counts = {tech: 0 for tech in technology_counts}\n",
    "assigned_year_counts = {year: 0 for year in model_year_pdf_counts}\n",
    "\n",
    "# Create a list of all model years based on PDF counts\n",
    "model_years_list = []\n",
    "for year, count in model_year_pdf_counts.items():\n",
    "    model_years_list.extend([year] * count)\n",
    "\n",
    "# For the remaining vehicles, assign model years from a reasonable range (e.g., 2010-2018)\n",
    "remaining_vehicles_for_year_assignment = total_vehicles_from_spec - len(model_years_list)\n",
    "if remaining_vehicles_for_year_assignment > 0:\n",
    "    model_years_list.extend(random.choices(range(2010, 2019), k=remaining_vehicles_for_year_assignment))\n",
    "random.shuffle(model_years_list)\n",
    "\n",
    "# Create a list of all technologies based on counts\n",
    "technologies_list = []\n",
    "for tech, count in technology_counts.items():\n",
    "    technologies_list.extend([tech] * count)\n",
    "random.shuffle(technologies_list)\n",
    "\n",
    "\n",
    "for spec in vehicle_specs:\n",
    "    for _ in range(spec[\"count\"]):\n",
    "        vehicle_id_counter += 1\n",
    "        \n",
    "        license_plate = fake_co.unique.license_plate()\n",
    "        vehicle_type_val = spec[\"type\"]\n",
    "        capacity_val = spec[\"capacity\"]\n",
    "        \n",
    "        # Assign technology\n",
    "        tech_val = \"DIESEL_EURO_V\" # Default\n",
    "        if technologies_list:\n",
    "            tech_val = technologies_list.pop()\n",
    "        \n",
    "        # Assign model year\n",
    "        model_year_val = random.randint(2008, 2023) # Default\n",
    "        if model_years_list:\n",
    "            model_year_val = model_years_list.pop()\n",
    "\n",
    "        # Assign concessionaire_id based on vehicle component\n",
    "        con_id_val = None\n",
    "        if spec[\"component\"] == \"TRONCAL\": # Includes PADRON_DUAL for troncal assignment here\n",
    "            # Assign to concessionaires that operate troncal\n",
    "            # Simplified: pick from first few concessionaires assumed to be troncal\n",
    "             con_id_val = random.choice([cid for cid in range(1,11)] + [cid for cid in range(1, max_concessionaire_id + 1) if random.random() < 0.1]) # Some randomness\n",
    "        elif spec[\"component\"] == \"ZONAL\" or spec[\"component\"] == \"ALIMENTACION\":\n",
    "            # Assign to concessionaires that operate zonal/alimentacion\n",
    "            # Simplified: pick from later concessionaires assumed to be zonal/feeder\n",
    "            con_id_val = random.choice([cid for cid in range(11, max_concessionaire_id)] + [cid for cid in range(1, max_concessionaire_id + 1) if random.random() < 0.1])\n",
    "        \n",
    "        if con_id_val is None or con_id_val > max_concessionaire_id: # Fallback\n",
    "            con_id_val = random.randint(1,max_concessionaire_id)\n",
    "\n",
    "        status_val = \"active\" if random.random() < 0.95 else random.choice([\"maintenance\", \"inactive\"])\n",
    "        current_depot_id_val = random.randint(1, max_depot_id) if max_depot_id > 0 else \"NULL\"\n",
    "\n",
    "        all_vehicle_records.append(\n",
    "            f\"({vehicle_id_counter}, '{license_plate}', '{vehicle_type_val}', {capacity_val}, '{tech_val}', \"\n",
    "            f\"{model_year_val}, {con_id_val}, '{status_val}', {current_depot_id_val})\"\n",
    "        )\n",
    "\n",
    "# --- Generate Drivers ---\n",
    "print(f\"Generating {total_drivers_to_generate} driver records...\")\n",
    "all_driver_records = []\n",
    "driver_id_counter = 0\n",
    "\n",
    "driver_component_assignment_list = []\n",
    "for component, count in driver_counts_component.items():\n",
    "    driver_component_assignment_list.extend([component] * count)\n",
    "random.shuffle(driver_component_assignment_list)\n",
    "\n",
    "for i in range(total_drivers_to_generate):\n",
    "    driver_id_counter += 1\n",
    "    \n",
    "    employee_id_val = fake_co.unique.ssn().replace('-', '') # Using SSN format as unique employee ID\n",
    "    first_name_val = fake_co.first_name().replace(\"'\", \"''\")\n",
    "    last_name_val = fake_co.last_name().replace(\"'\", \"''\")\n",
    "    \n",
    "    # Assign concessionaire based on driver's component\n",
    "    component_type = driver_component_assignment_list[i]\n",
    "    con_id_val = None\n",
    "    if component_type == \"TRONCAL\":\n",
    "        con_id_val = random.choice([cid for cid in range(1,11)] + [cid for cid in range(1, max_concessionaire_id + 1) if random.random() < 0.1])\n",
    "    elif component_type == \"ZONAL_UCE\" or component_type == \"ALIMENTACION\":\n",
    "         con_id_val = random.choice([cid for cid in range(11, max_concessionaire_id)] + [cid for cid in range(1, max_concessionaire_id + 1) if random.random() < 0.1])\n",
    "\n",
    "    if con_id_val is None or con_id_val > max_concessionaire_id: # Fallback\n",
    "        con_id_val = random.randint(1,max_concessionaire_id)\n",
    "\n",
    "    hire_date_obj = fake_co.date_between(start_date='-15y', end_date='-1m') # Hired at least 1 month ago\n",
    "    hire_date_val = hire_date_obj.strftime('%Y-%m-%d')\n",
    "    \n",
    "    license_number_val = f\"{chr(random.randint(65,90))}{chr(random.randint(65,90))}{random.randint(1000,9999)}\" # Simple license format\n",
    "    \n",
    "    license_expiry_date_obj = fake_co.date_between(start_date='today', end_date='+5y')\n",
    "    license_expiry_date_val = license_expiry_date_obj.strftime('%Y-%m-%d')\n",
    "    \n",
    "    status_val = \"active\" if random.random() < 0.9 else random.choice([\"on_leave\", \"inactive\"])\n",
    "\n",
    "    all_driver_records.append(\n",
    "        f\"({driver_id_counter}, '{employee_id_val}', '{first_name_val}', '{last_name_val}', {con_id_val}, \"\n",
    "        f\"'{hire_date_val}', '{license_number_val}', '{license_expiry_date_val}', '{status_val}')\"\n",
    "    )\n",
    "\n",
    "# --- Write to SQL file ---\n",
    "with open(vehicles_drivers_output_file, 'w', encoding='utf-8') as file:\n",
    "    batch_size = 1000\n",
    "\n",
    "    # Write Vehicles\n",
    "    file.write(\"INSERT INTO vehicles (vehicle_id, license_plate, vehicle_type, capacity, technology, model_year, concessionaire_id, status, current_depot_id) VALUES\\n\")\n",
    "    for i, record_string in enumerate(all_vehicle_records):\n",
    "        file.write(record_string)\n",
    "        if (i + 1) % batch_size == 0 and i < len(all_vehicle_records) - 1:\n",
    "            file.write(\";\\n\")\n",
    "            file.write(\"INSERT INTO vehicles (vehicle_id, license_plate, vehicle_type, capacity, technology, model_year, concessionaire_id, status, current_depot_id) VALUES\\n\")\n",
    "        elif i < len(all_vehicle_records) - 1:\n",
    "            file.write(\",\\n\")\n",
    "        else:\n",
    "            file.write(\";\\n\")\n",
    "    \n",
    "    file.write(\"\\n\\n\") # Separator\n",
    "\n",
    "    # Write Drivers\n",
    "    file.write(\"INSERT INTO drivers (driver_id, employee_id, first_name, last_name, concessionaire_id, hire_date, license_number, license_expiry_date, status) VALUES\\n\")\n",
    "    for i, record_string in enumerate(all_driver_records):\n",
    "        file.write(record_string)\n",
    "        if (i + 1) % batch_size == 0 and i < len(all_driver_records) - 1:\n",
    "            file.write(\";\\n\")\n",
    "            file.write(\"INSERT INTO drivers (driver_id, employee_id, first_name, last_name, concessionaire_id, hire_date, license_number, license_expiry_date, status) VALUES\\n\")\n",
    "        elif i < len(all_driver_records) - 1:\n",
    "            file.write(\",\\n\")\n",
    "        else:\n",
    "            file.write(\";\\n\")\n",
    "\n",
    "print(f\"SQL script for vehicles and drivers generated: {os.path.abspath(vehicles_drivers_output_file)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65458168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating routes and intermediate station sequences...\n",
      "SQL script for routes and intermediate stations generated: /home/kali/Documents/remote reps/distributed-systems-lab/travel-recharge-database/db/data/generated_sql_scripts/10_insert_routes_and_sequences.sql\n"
     ]
    }
   ],
   "source": [
    "import faker\n",
    "import random\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize Faker for Colombian Spanish\n",
    "fake_co = faker.Faker('es_CO')\n",
    "\n",
    "# --- Configuration ---\n",
    "output_folder = \"generated_sql_scripts\"\n",
    "routes_sequences_output_file = os.path.join(output_folder, \"10_insert_routes_and_sequences.sql\")\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# --- Counts from PDF ---\n",
    "NUM_TRONCAL_ROUTES = 99\n",
    "NUM_ZONAL_UCE_ROUTES = 347\n",
    "NUM_ALIMENTADORA_ROUTES = 106\n",
    "NUM_CABLE_ROUTES = 1 # Main cable line\n",
    "DUAL_ROUTE_CODES = [\"DM81\", \"MK86\", \"ML82\", \"MC84\", \"M83\"] # Page 18\n",
    "NUM_DUAL_ROUTES = len(DUAL_ROUTE_CODES)\n",
    "\n",
    "# Max IDs from previous scripts (essential for FK integrity)\n",
    "# From 6_insert_concessionaires.sql\n",
    "max_concessionaire_id = 27\n",
    "# From 8_insert_stations.sql\n",
    "# station_id_counter was ~7765. Ranges:\n",
    "PORTAL_IDS = list(range(1, NUM_PORTALS + 1)) # 1-9\n",
    "CABLE_STATION_IDS = list(range(NUM_PORTALS + 1, NUM_PORTALS + NUM_CABLE_STATIONS + 1)) # 10-13\n",
    "TRONCAL_STATION_IDS_OTHER = list(range(NUM_PORTALS + NUM_CABLE_STATIONS + 1, TOTAL_STATIONS_INC_CABLE + 1)) # 14-142\n",
    "ZONAL_PARADERO_IDS = list(range(TOTAL_STATIONS_INC_CABLE + 1, 7765 + 1)) # Approx 143 - 7765 (adjust if exact final count from script 8 differs)\n",
    "ALL_TRONCAL_STATIONS = PORTAL_IDS + TRONCAL_STATION_IDS_OTHER # All stations usable by troncal routes\n",
    "\n",
    "# Mapping concessionaires to types (simplified from script 6 logic)\n",
    "# This needs to be robust. Re-establish based on how concessionaires were defined.\n",
    "# For this script, we'll create a list of concessionaires for each type.\n",
    "# Concessionaire data from script 6:\n",
    "concessionaire_definitions = [\n",
    "    {\"id\": 1, \"name\": \"Bogotá Móvil Operación Sur BMO SUR S.A.S\", \"troncal\": True, \"zonal_uce\": False, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"id\": 2, \"name\": \"Connexion Móvil S.A.S.\", \"troncal\": True, \"zonal_uce\": False, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"id\": 3, \"name\": \"Capitalbus S.A.S.\", \"troncal\": True, \"zonal_uce\": False, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"id\": 4, \"name\": \"SI18 Calle 80 S.A.S.\", \"troncal\": True, \"zonal_uce\": True, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"id\": 5, \"name\": \"SI18 Norte S.A.S.\", \"troncal\": True, \"zonal_uce\": False, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"id\": 6, \"name\": \"SI18 Suba S.A.S.\", \"troncal\": True, \"zonal_uce\": False, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"id\": 7, \"name\": \"Somos Bogotá Usme S.A.S.\", \"troncal\": True, \"zonal_uce\": False, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"id\": 8, \"name\": \"Gmovil S.A.S.\", \"troncal\": True, \"zonal_uce\": True, \"zonal_alimentacion\": True, \"cable\": False},\n",
    "    {\"id\": 9, \"name\": \"Consorcio Express S.A.S.\", \"troncal\": True, \"zonal_uce\": True, \"zonal_alimentacion\": True, \"cable\": False},\n",
    "    {\"id\": 10, \"name\": \"Este Es Mi Bus S.A.S.\", \"troncal\": False, \"zonal_uce\": False, \"zonal_alimentacion\": True, \"cable\": False},\n",
    "    {\"id\": 11, \"name\": \"ETIB S.A.S.\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": True, \"cable\": False},\n",
    "    {\"id\": 12, \"name\": \"Masivo Capital S.A.S.\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": True, \"cable\": False},\n",
    "    {\"id\": 13, \"name\": \"Organización Suma S.A.S.\", \"troncal\": False, \"zonal_uce\": False, \"zonal_alimentacion\": True, \"cable\": False},\n",
    "    {\"id\": 14, \"name\": \"E-Somos Fontibón S.A.S.\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"id\": 15, \"name\": \"Mueve Fontibón S.A.S.\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"id\": 16, \"name\": \"ZMO Fontibón III S.A.S.\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"id\": 17, \"name\": \"ZMO Fontíbón V S.A.S.\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"id\": 18, \"name\": \"Emasivo 10 S.A.S.\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"id\": 19, \"name\": \"Emasivo 16 S.A.S.\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"id\": 20, \"name\": \"Operadora Distrital de Transporte La Rolita\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"id\": 21, \"name\": \"E-Somos Alimentación S.A.S.\", \"troncal\": False, \"zonal_uce\": False, \"zonal_alimentacion\": True, \"cable\": False},\n",
    "    {\"id\": 22, \"name\": \"Gran Américas Usme S.A.S\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"id\": 23, \"name\": \"Mueve Usme S.A.S.\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"id\": 24, \"name\": \"Cable Movil de Bogota S.A.S.\", \"troncal\": False, \"zonal_uce\": False, \"zonal_alimentacion\": False, \"cable\": True}, # Cable operator\n",
    "    {\"id\": 25, \"name\": \"Transportes Urbanos Integrados S.A.S.\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": True, \"cable\": False},\n",
    "    {\"id\": 26, \"name\": \"Movilidad Estratégica del Oriente S.A.\", \"troncal\": True, \"zonal_uce\": False, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"id\": 27, \"name\": \"Conexión Capital S.P.A.\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "]\n",
    "\n",
    "concessionaires_troncal_ids = [c[\"id\"] for c in concessionaire_definitions if c[\"troncal\"]]\n",
    "concessionaires_zonal_uce_ids = [c[\"id\"] for c in concessionaire_definitions if c[\"zonal_uce\"]]\n",
    "concessionaires_alimentacion_ids = [c[\"id\"] for c in concessionaire_definitions if c[\"zonal_alimentacion\"]]\n",
    "concessionaires_cable_ids = [c[\"id\"] for c in concessionaire_definitions if c[\"cable\"]]\n",
    "\n",
    "# Ensure lists are not empty\n",
    "if not concessionaires_troncal_ids: concessionaires_troncal_ids = [1]\n",
    "if not concessionaires_zonal_uce_ids: concessionaires_zonal_uce_ids = [14]\n",
    "if not concessionaires_alimentacion_ids: concessionaires_alimentacion_ids = [10]\n",
    "if not concessionaires_cable_ids: concessionaires_cable_ids = [24]\n",
    "\n",
    "\n",
    "# Zonal route codes from PDF p23\n",
    "zonal_route_codes_pdf = [\"T11\", \"T13\", \"BH907\", \"330\", \"T25\", \"CG147\", \"94\", \"SE14\", \"614\", \"SE6\"]\n",
    "\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def generate_route_code(route_type, counter, existing_codes):\n",
    "    code = \"\"\n",
    "    attempts = 0\n",
    "    while attempts < 100: # Max attempts to find a unique code\n",
    "        if route_type == \"TRONCAL\":\n",
    "            # B1, C17, H20, K43, L82, M51, F23, G45, J70, E32\n",
    "            prefix = random.choice([\"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"J\", \"K\", \"L\", \"M\"])\n",
    "            num = random.randint(1, 99)\n",
    "            code = f\"{prefix}{num}\"\n",
    "        elif route_type == \"DUAL\": # Will be categorized as TRONCAL type in DB schema\n",
    "            # Use pre-defined DUAL_ROUTE_CODES first\n",
    "            if counter < len(DUAL_ROUTE_CODES):\n",
    "                code = DUAL_ROUTE_CODES[counter]\n",
    "            else: # Generate if more dual routes are needed than pre-defined\n",
    "                prefix = random.choice([\"DM\", \"MD\", \"ML\", \"LM\", \"CM\"])\n",
    "                num = random.randint(80, 99)\n",
    "                code = f\"{prefix}{num}\"\n",
    "        elif route_type == \"ZONAL_UCE\":\n",
    "            if counter < len(zonal_route_codes_pdf):\n",
    "                code = zonal_route_codes_pdf[counter]\n",
    "            elif random.random() < 0.5: # Number based\n",
    "                code = str(random.randint(1, 999))\n",
    "                if random.random() < 0.3: # Add a dash sometimes\n",
    "                    code += f\"-{random.randint(1,10)}\"\n",
    "            else: # Letter + Number\n",
    "                prefix = random.choice([\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"K\", \"L\", \"P\", \"S\", \"T\", \"U\", \"Z\"]) + \\\n",
    "                         random.choice([\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]) + \\\n",
    "                         random.choice([\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"])\n",
    "                code = prefix\n",
    "                if random.random() < 0.2 : code = \"SITP\" + code # SITP prefix for some\n",
    "        elif route_type == \"ALIMENTADORA\":\n",
    "            # e.g., 1-1, 10-3, B902 (some alimentadores look like zonal/troncal codes too)\n",
    "            if random.random() < 0.6:\n",
    "                prefix = str(random.randint(1,16)) # Based on common portal/zone numbers\n",
    "                suffix = str(random.randint(1,10))\n",
    "                code = f\"{prefix}-{suffix}\"\n",
    "            else:\n",
    "                prefix = random.choice(PORTAL_IDS) # Use portal ID as part of the code logic\n",
    "                code = f\"A{prefix}{random.randint(0,9)}\"\n",
    "\n",
    "        elif route_type == \"CABLE\":\n",
    "            code = f\"TC{counter+1}\" # TransMiCable 1\n",
    "\n",
    "        if code not in existing_codes:\n",
    "            existing_codes.add(code)\n",
    "            return code\n",
    "        counter +=1 # To help vary generation if first try fails\n",
    "        attempts +=1\n",
    "    return f\"FAIL{route_type}{counter}\" # Fallback unique code\n",
    "\n",
    "# --- Generate Routes and Intermediate Stations ---\n",
    "print(\"Generating routes and intermediate station sequences...\")\n",
    "all_route_records = []\n",
    "all_intermediate_station_records = []\n",
    "route_id_counter = 0\n",
    "intermediate_station_id_counter = 0\n",
    "generated_route_codes = set()\n",
    "\n",
    "route_definitions = [\n",
    "    {\"type\": \"TRONCAL\", \"count\": NUM_TRONCAL_ROUTES, \"con_ids\": concessionaires_troncal_ids, \"orig_dest_pool\": ALL_TRONCAL_STATIONS, \"inter_pool\": ALL_TRONCAL_STATIONS, \"min_stops\": 3, \"max_stops\": 15},\n",
    "    {\"type\": \"DUAL\", \"count\": NUM_DUAL_ROUTES, \"con_ids\": concessionaires_troncal_ids, \"orig_dest_pool\": PORTAL_IDS + TRONCAL_STATION_IDS_OTHER, \"inter_pool\": ALL_TRONCAL_STATIONS + ZONAL_PARADERO_IDS, \"min_stops\": 8, \"max_stops\": 25}, # Dual routes use both\n",
    "    {\"type\": \"ZONAL_UCE\", \"count\": NUM_ZONAL_UCE_ROUTES, \"con_ids\": concessionaires_zonal_uce_ids, \"orig_dest_pool\": ZONAL_PARADERO_IDS + TRONCAL_STATION_IDS_OTHER, \"inter_pool\": ZONAL_PARADERO_IDS, \"min_stops\": 10, \"max_stops\": 40},\n",
    "    {\"type\": \"ALIMENTADORA\", \"count\": NUM_ALIMENTADORA_ROUTES, \"con_ids\": concessionaires_alimentacion_ids, \"orig_dest_pool_orig\": PORTAL_IDS + TRONCAL_STATION_IDS_OTHER, \"orig_dest_pool_dest\": ZONAL_PARADERO_IDS, \"inter_pool\": ZONAL_PARADERO_IDS, \"min_stops\": 5, \"max_stops\": 20},\n",
    "    {\"type\": \"CABLE\", \"count\": NUM_CABLE_ROUTES, \"con_ids\": concessionaires_cable_ids, \"orig_dest_pool\": CABLE_STATION_IDS, \"inter_pool\": CABLE_STATION_IDS, \"min_stops\": 1, \"max_stops\": 2} # Cable has fixed intermediate stations\n",
    "]\n",
    "\n",
    "for definition in route_definitions:\n",
    "    route_type_db = definition[\"type\"]\n",
    "    if route_type_db == \"DUAL\": # Schema maps DUAL to TRONCAL type for now\n",
    "        route_type_db = \"TRONCAL\"\n",
    "\n",
    "    for i in range(definition[\"count\"]):\n",
    "        route_id_counter += 1\n",
    "        \n",
    "        route_code_val = generate_route_code(definition[\"type\"], i, generated_route_codes)\n",
    "        \n",
    "        # Select Origin and Destination\n",
    "        origin_station_id_val = None\n",
    "        destination_station_id_val = None\n",
    "\n",
    "        if definition[\"type\"] == \"ALIMENTADORA\":\n",
    "            origin_station_id_val = random.choice(definition[\"orig_dest_pool_orig\"])\n",
    "            destination_station_id_val = random.choice(definition[\"orig_dest_pool_dest\"])\n",
    "        elif definition[\"type\"] == \"CABLE\":\n",
    "            # Cable route is fixed: Portal Tunal Cable -> Juan Pablo II -> Manitas -> Mirador del Paraiso\n",
    "            # CABLE_STATION_IDS are 10, 11, 12, 13\n",
    "            origin_station_id_val = CABLE_STATION_IDS[0] # e.g., Portal Tunal Cable\n",
    "            destination_station_id_val = CABLE_STATION_IDS[-1] # e.g., Mirador del Paraiso\n",
    "        else:\n",
    "            if len(definition[\"orig_dest_pool\"]) >=2:\n",
    "                origin_station_id_val, destination_station_id_val = random.sample(definition[\"orig_dest_pool\"], 2)\n",
    "            else: # Fallback for small pools\n",
    "                origin_station_id_val = random.choice(definition[\"orig_dest_pool\"])\n",
    "                destination_station_id_val = random.choice(definition[\"orig_dest_pool\"])\n",
    "\n",
    "\n",
    "        route_name_val = f\"{route_code_val}: Est. {origin_station_id_val} - Est. {destination_station_id_val}\".replace(\"'\", \"''\")\n",
    "        concessionaire_id_val = random.choice(definition[\"con_ids\"])\n",
    "        is_active_val = True if random.random() < 0.95 else False # Most routes active\n",
    "\n",
    "        all_route_records.append(\n",
    "            f\"({route_id_counter}, '{route_code_val}', '{route_name_val}', '{route_type_db}', \"\n",
    "            f\"{origin_station_id_val}, {destination_station_id_val}, {concessionaire_id_val}, {is_active_val})\"\n",
    "        )\n",
    "\n",
    "        # Generate Intermediate Stations for this route\n",
    "        num_intermediate_stops = random.randint(definition[\"min_stops\"], definition[\"max_stops\"])\n",
    "        \n",
    "        # Ensure intermediate pool is not empty and has enough unique stations\n",
    "        current_inter_pool = [s for s in definition[\"inter_pool\"] if s != origin_station_id_val and s != destination_station_id_val]\n",
    "        \n",
    "        if not current_inter_pool: # If pool is empty after removing origin/dest, skip intermediate\n",
    "            continue\n",
    "\n",
    "        # Special handling for CABLE route intermediate stations\n",
    "        if definition[\"type\"] == \"CABLE\" and len(CABLE_STATION_IDS) > 2:\n",
    "            # Fixed intermediate stations for the main cable line\n",
    "            # Assuming CABLE_STATION_IDS are [Origin, Inter1, Inter2, ..., Dest]\n",
    "            # For 4 stations: [0]=Origin, [1]=Inter1, [2]=Inter2, [3]=Dest\n",
    "            # Intermediate are CABLE_STATION_IDS[1] and CABLE_STATION_IDS[2]\n",
    "            stops_to_add = CABLE_STATION_IDS[1:-1] # Exclude first (origin) and last (destination)\n",
    "        else:\n",
    "            if len(current_inter_pool) < num_intermediate_stops:\n",
    "                num_intermediate_stops = len(current_inter_pool) # Max available\n",
    "            stops_to_add = random.sample(current_inter_pool, num_intermediate_stops)\n",
    "\n",
    "        for seq_order, station_id_val in enumerate(stops_to_add):\n",
    "            intermediate_station_id_counter += 1\n",
    "            all_intermediate_station_records.append(\n",
    "                f\"({intermediate_station_id_counter}, {route_id_counter}, {station_id_val}, {seq_order + 1})\"\n",
    "            )\n",
    "\n",
    "\n",
    "# --- Write to SQL file ---\n",
    "with open(routes_sequences_output_file, 'w', encoding='utf-8') as file:\n",
    "    batch_size = 1000\n",
    "\n",
    "    # Write Routes\n",
    "    file.write(\"INSERT INTO routes (route_id, route_code, route_name, route_type, origin_station_id, destination_station_id, concessionaire_id, is_active) VALUES\\n\")\n",
    "    for i, record_string in enumerate(all_route_records):\n",
    "        file.write(record_string)\n",
    "        if (i + 1) % batch_size == 0 and i < len(all_route_records) - 1:\n",
    "            file.write(\";\\n\")\n",
    "            file.write(\"INSERT INTO routes (route_id, route_code, route_name, route_type, origin_station_id, destination_station_id, concessionaire_id, is_active) VALUES\\n\")\n",
    "        elif i < len(all_route_records) - 1:\n",
    "            file.write(\",\\n\")\n",
    "        else:\n",
    "            file.write(\";\\n\")\n",
    "    \n",
    "    file.write(\"\\n\\n\")\n",
    "\n",
    "    # Write Intermediate Stations\n",
    "    file.write(\"INSERT INTO intermediate_stations (intermediate_station_id, route_id, station_id, sequence_order) VALUES\\n\")\n",
    "    for i, record_string in enumerate(all_intermediate_station_records):\n",
    "        file.write(record_string)\n",
    "        if (i + 1) % batch_size == 0 and i < len(all_intermediate_station_records) - 1:\n",
    "            file.write(\";\\n\")\n",
    "            file.write(\"INSERT INTO intermediate_stations (intermediate_station_id, route_id, station_id, sequence_order) VALUES\\n\")\n",
    "        elif i < len(all_intermediate_station_records) - 1:\n",
    "            file.write(\",\\n\")\n",
    "        else:\n",
    "            file.write(\";\\n\")\n",
    "\n",
    "print(f\"SQL script for routes and intermediate stations generated: {os.path.abspath(routes_sequences_output_file)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8eeb55db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating fare records...\n",
      "SQL script for fares generated: /home/kali/Documents/remote reps/distributed-systems-lab/travel-recharge-database/db/data/generated_sql_scripts/11_insert_fares.sql\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import date\n",
    "\n",
    "# --- Configuration ---\n",
    "output_folder = \"generated_sql_scripts\"\n",
    "fares_output_file = os.path.join(output_folder, \"11_insert_fares.sql\")\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Define fare data\n",
    "# Current SITP standard fare is 2950 COP.\n",
    "# Transfers are 0 or 200 COP.\n",
    "# We'll define these for a period covering June 2024 through a future date.\n",
    "# Given current date is June 1, 2025, let's make these fares active.\n",
    "\n",
    "fare_data = [\n",
    "    {\n",
    "        \"fare_id\": 1,\n",
    "        \"fare_type\": \"STANDARD_SITP\", # General standard fare for Troncal/Zonal\n",
    "        \"value\": 2950.00,\n",
    "        \"start_date\": date(2024, 1, 15).strftime('%Y-%m-%d'), # Assuming a start date in early 2024\n",
    "        \"end_date\": \"NULL\", # Currently active\n",
    "        \"description\": \"Tarifa estándar del componente Troncal y Zonal del SITP.\"\n",
    "    },\n",
    "    {\n",
    "        \"fare_id\": 2,\n",
    "        \"fare_type\": \"TRANSFER_0_COST\",\n",
    "        \"value\": 0.00,\n",
    "        \"start_date\": date(2024, 1, 15).strftime('%Y-%m-%d'),\n",
    "        \"end_date\": \"NULL\", # Currently active\n",
    "        \"description\": \"Transbordo sin costo adicional (dentro de la ventana de tiempo y condiciones).\"\n",
    "    },\n",
    "    {\n",
    "        \"fare_id\": 3,\n",
    "        \"fare_type\": \"TRANSFER_200_COST\",\n",
    "        \"value\": 200.00,\n",
    "        \"start_date\": date(2024, 1, 15).strftime('%Y-%m-%d'),\n",
    "        \"end_date\": \"NULL\", # Currently active\n",
    "        \"description\": \"Transbordo con costo de $200 COP (dentro de la ventana de tiempo y condiciones).\"\n",
    "    },\n",
    "    {\n",
    "        \"fare_id\": 4,\n",
    "        \"fare_type\": \"STANDARD_CABLE\", # TransMiCable might have the same standard fare\n",
    "        \"value\": 2950.00,\n",
    "        \"start_date\": date(2024, 1, 15).strftime('%Y-%m-%d'),\n",
    "        \"end_date\": \"NULL\", # Currently active\n",
    "        \"description\": \"Tarifa estándar para TransMiCable.\"\n",
    "    },\n",
    "    # Example of an older fare for historical data, if needed later\n",
    "    # {\n",
    "    #     \"fare_id\": 5,\n",
    "    #     \"fare_type\": \"STANDARD_SITP_OLD\",\n",
    "    #     \"value\": 2650.00,\n",
    "    #     \"start_date\": date(2023, 1, 10).strftime('%Y-%m-%d'),\n",
    "    #     \"end_date\": date(2024, 1, 14).strftime('%Y-%m-%d'),\n",
    "    #     \"description\": \"Tarifa estándar antigua del SITP.\"\n",
    "    # }\n",
    "]\n",
    "\n",
    "# --- Generate Fares SQL ---\n",
    "print(\"Generating fare records...\")\n",
    "\n",
    "with open(fares_output_file, 'w', encoding='utf-8') as file:\n",
    "    file.write(\"INSERT INTO fares (fare_id, fare_type, value, start_date, end_date, description) VALUES\\n\")\n",
    "    \n",
    "    for i, fare in enumerate(fare_data):\n",
    "        fare_id_val = fare[\"fare_id\"]\n",
    "        fare_type_val = fare[\"fare_type\"].replace(\"'\", \"''\")\n",
    "        value_val = fare[\"value\"]\n",
    "        start_date_val = fare[\"start_date\"]\n",
    "        end_date_val = f\"'{fare['end_date']}'\" if fare[\"end_date\"] != \"NULL\" else \"NULL\"\n",
    "        description_val = fare[\"description\"].replace(\"'\", \"''\")\n",
    "        \n",
    "        file.write(f\"({fare_id_val}, '{fare_type_val}', {value_val}, '{start_date_val}', {end_date_val}, '{description_val}')\")\n",
    "        \n",
    "        if i < len(fare_data) - 1:\n",
    "            file.write(\",\\n\")\n",
    "        else:\n",
    "            file.write(\";\\n\")\n",
    "\n",
    "print(f\"SQL script for fares generated: {os.path.abspath(fares_output_file)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
