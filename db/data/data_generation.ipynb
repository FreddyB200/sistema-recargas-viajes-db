{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af3f2c89",
   "metadata": {},
   "source": [
    "# Data Generation and Insertion for Transport Database\n",
    "\n",
    "This notebook replaces the old SQL insert scripts with Python scripts for generating and inserting synthetic data into the database, using the new English schema. It uses Faker and pandas for data generation and manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f10dcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 13 locations (operational zones)...\n",
      "SQL script for locations generated successfully: /home/kali/Documents/remote reps/distributed-systems-lab/travel-recharge-database/db/data/01_insert_locations.sql\n"
     ]
    }
   ],
   "source": [
    "import faker\n",
    "import random\n",
    "import os\n",
    "import unicodedata\n",
    "\n",
    "# Initialize Faker for Colombian Spanish\n",
    "fake_co = faker.Faker('es_CO')\n",
    "\n",
    "# --- Configuration ---\n",
    "output_file = \"01_insert_locations.sql\"\n",
    "\n",
    "# Number of records (PDF mentioned 13 \"Zonas de Operación\")\n",
    "num_locations = 13\n",
    "\n",
    "# --- Generate Locations (Zonas de Operación) ---\n",
    "print(f\"Generating {num_locations} locations (operational zones)...\")\n",
    "\n",
    "location_names_base = [\n",
    "    \"Usaquén\", \"Chapinero\", \"Santa Fe\", \"San Cristóbal\", \"Usme\", \"Tunjuelito\",\n",
    "    \"Bosa\", \"Kennedy\", \"Fontibón\", \"Engativá\", \"Suba\", \"Barrios Unidos\", \"Teusaquillo\"\n",
    "]\n",
    "if len(location_names_base) > num_locations:\n",
    "    location_names_base = random.sample(location_names_base, num_locations)\n",
    "elif len(location_names_base) < num_locations:\n",
    "    for i in range(num_locations - len(location_names_base)):\n",
    "        location_names_base.append(f\"Zona Operativa Adicional {i+1}\")\n",
    "\n",
    "all_records_strings = []\n",
    "for i in range(num_locations):\n",
    "    location_id_val = i + 1 # Python controla el ID\n",
    "    \n",
    "    name_val = location_names_base[i].replace(\"'\", \"''\")\n",
    "    description_val = f\"Zona de operación principal: {name_val} en Bogotá D.C.\".replace(\"'\", \"''\")\n",
    "    \n",
    "    all_records_strings.append(\n",
    "        f\"({location_id_val}, '{name_val}', '{description_val}')\"\n",
    "    )\n",
    "\n",
    "# --- Write to SQL file ---\n",
    "try:\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(\"INSERT INTO locations (location_id, name, description) OVERRIDING SYSTEM VALUE VALUES\\n\")\n",
    "        \n",
    "        for i, record_string in enumerate(all_records_strings):\n",
    "            file.write(record_string)\n",
    "            if i < len(all_records_strings) - 1:\n",
    "                file.write(\",\\n\")\n",
    "            else:\n",
    "                file.write(\";\\n\")\n",
    "    print(f\"SQL script for locations generated successfully: {os.path.abspath(output_file)}\")\n",
    "except IOError as e:\n",
    "    print(f\"Error writing to file {output_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84a8aa91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating concessionaire records...\n",
      "SQL script for concessionaires generated successfully: /home/kali/Documents/remote reps/distributed-systems-lab/travel-recharge-database/db/data/02_insert_concessionaires.sql\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "# Guarda el .sql en el mismo directorio que este script .py\n",
    "output_file = \"02_insert_concessionaires.sql\"\n",
    "\n",
    "# --- Generate Concessionaires ---\n",
    "print(\"Generating concessionaire records...\")\n",
    "\n",
    "\n",
    "concessionaire_data_definitions = [\n",
    "    {\"id\": 1, \"name\": \"Bogotá Móvil Operación Sur BMO SUR S.A.S\", \"troncal\": True, \"zonal_uce\": False, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"id\": 2, \"name\": \"Connexion Móvil S.A.S.\", \"troncal\": True, \"zonal_uce\": False, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"id\": 3, \"name\": \"Capitalbus S.A.S.\", \"troncal\": True, \"zonal_uce\": False, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"id\": 4, \"name\": \"SI18 Calle 80 S.A.S.\", \"troncal\": True, \"zonal_uce\": True, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"id\": 5, \"name\": \"SI18 Norte S.A.S.\", \"troncal\": True, \"zonal_uce\": False, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"id\": 6, \"name\": \"SI18 Suba S.A.S.\", \"troncal\": True, \"zonal_uce\": False, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"id\": 7, \"name\": \"Somos Bogotá Usme S.A.S.\", \"troncal\": True, \"zonal_uce\": False, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"id\": 8, \"name\": \"Gmovil S.A.S.\", \"troncal\": True, \"zonal_uce\": True, \"zonal_alimentacion\": True, \"cable\": False},\n",
    "    {\"id\": 9, \"name\": \"Consorcio Express S.A.S.\", \"troncal\": True, \"zonal_uce\": True, \"zonal_alimentacion\": True, \"cable\": False},\n",
    "    {\"id\": 10, \"name\": \"Este Es Mi Bus S.A.S.\", \"troncal\": False, \"zonal_uce\": False, \"zonal_alimentacion\": True, \"cable\": False},\n",
    "    {\"id\": 11, \"name\": \"ETIB S.A.S.\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": True, \"cable\": False},\n",
    "    {\"id\": 12, \"name\": \"Masivo Capital S.A.S.\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": True, \"cable\": False},\n",
    "    {\"id\": 13, \"name\": \"Organización Suma S.A.S.\", \"troncal\": False, \"zonal_uce\": False, \"zonal_alimentacion\": True, \"cable\": False},\n",
    "    {\"id\": 14, \"name\": \"E-Somos Fontibón S.A.S.\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"id\": 15, \"name\": \"Mueve Fontibón S.A.S.\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"id\": 16, \"name\": \"ZMO Fontibón III S.A.S.\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"id\": 17, \"name\": \"ZMO Fontíbón V S.A.S.\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"id\": 18, \"name\": \"Emasivo 10 S.A.S.\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"id\": 19, \"name\": \"Emasivo 16 S.A.S.\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"id\": 20, \"name\": \"Operadora Distrital de Transporte La Rolita\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": False, \"cable\": False},\n",
    "    {\"id\": 21, \"name\": \"E-Somos Alimentación S.A.S.\", \"troncal\": False, \"zonal_uce\": False, \"zonal_alimentacion\": True, \"cable\": False},\n",
    "    {\"id\": 22, \"name\": \"Gran Américas Usme S.A.S\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": False, \"cable\": False}, # Asumido UCE\n",
    "    {\"id\": 23, \"name\": \"Mueve Usme S.A.S.\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": False, \"cable\": False}, # Asumido UCE\n",
    "    {\"id\": 24, \"name\": \"Cable Movil de Bogota S.A.S.\", \"troncal\": False, \"zonal_uce\": False, \"zonal_alimentacion\": False, \"cable\": True}, # Operador de Cable\n",
    "    {\"id\": 25, \"name\": \"Transportes Urbanos Integrados S.A.S.\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": True, \"cable\": False}, # Genérico\n",
    "    {\"id\": 26, \"name\": \"Movilidad Estratégica del Oriente S.A.\", \"troncal\": True, \"zonal_uce\": False, \"zonal_alimentacion\": False, \"cable\": False}, # Genérico\n",
    "    {\"id\": 27, \"name\": \"Conexión Capital S.P.A.\", \"troncal\": False, \"zonal_uce\": True, \"zonal_alimentacion\": False, \"cable\": False}, # Genérico\n",
    "]\n",
    "\n",
    "all_records_strings = []\n",
    "for data in concessionaire_data_definitions:\n",
    "    concessionaire_id_val = data[\"id\"] # Python controla el ID\n",
    "    name_val = data[\"name\"].replace(\"'\", \"''\")\n",
    "    troncal_val = data[\"troncal\"]\n",
    "    zonal_uce_val = data[\"zonal_uce\"]\n",
    "    zonal_alim_val = data[\"zonal_alimentacion\"]\n",
    "    cable_val = data[\"cable\"]\n",
    "    \n",
    "    all_records_strings.append(\n",
    "        f\"({concessionaire_id_val}, '{name_val}', {troncal_val}, {zonal_uce_val}, {zonal_alim_val}, {cable_val})\"\n",
    "    )\n",
    "\n",
    "# --- Write to SQL file ---\n",
    "try:\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        # IMPORTANTE: Añadir OVERRIDING SYSTEM VALUE aquí\n",
    "        file.write(\"INSERT INTO concessionaires (concessionaire_id, name, operates_troncal, operates_zonal_uce, operates_zonal_alimentacion, operates_cable) OVERRIDING SYSTEM VALUE VALUES\\n\")\n",
    "        \n",
    "        for i, record_string in enumerate(all_records_strings):\n",
    "            file.write(record_string)\n",
    "            if i < len(all_records_strings) - 1:\n",
    "                file.write(\",\\n\")\n",
    "            else:\n",
    "                file.write(\";\\n\")\n",
    "    print(f\"SQL script for concessionaires generated successfully: {os.path.abspath(output_file)}\")\n",
    "except IOError as e:\n",
    "    print(f\"Error writing to file {output_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0db248a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating depot records...\n",
      "SQL script for depots generated successfully: /home/kali/Documents/remote reps/distributed-systems-lab/travel-recharge-database/db/data/03_insert_depots.sql\n"
     ]
    }
   ],
   "source": [
    "import faker\n",
    "import random\n",
    "import os\n",
    "\n",
    "fake_co = faker.Faker('es_CO')\n",
    "\n",
    "output_file = \"03_insert_depots.sql\"\n",
    "\n",
    "\n",
    "max_location_id = 13\n",
    "max_concessionaire_id = 27\n",
    "\n",
    "print(\"Generating depot records...\")\n",
    "\n",
    "depot_specs = [\n",
    "    {\"type\": \"TALLER\", \"count\": 13, \"name_prefix\": \"Patio Taller Principal\"},\n",
    "    {\"type\": \"TRANSITORIO\", \"count\": 32, \"name_prefix\": \"Patio Transitorio\"},\n",
    "    {\"type\": \"ELECTRICO\", \"count\": 9, \"name_prefix\": \"ElectroPatio\"},\n",
    "    {\"type\": \"BAJAS_EMISIONES\", \"count\": 4, \"name_prefix\": \"Patio Eco\"}\n",
    "]\n",
    "total_depots_to_generate = sum(spec[\"count\"] for spec in depot_specs) # 58 depots\n",
    "depot_id_counter = 0\n",
    "all_records_strings = []\n",
    "\n",
    "for spec in depot_specs:\n",
    "    for i in range(spec[\"count\"]):\n",
    "        depot_id_counter += 1\n",
    "        depot_id_val = depot_id_counter # Python controla el ID\n",
    "\n",
    "        zone_name_part = fake_co.city_suffix().replace(\"'\", \"''\")\n",
    "        name_val = f\"{spec['name_prefix']} {zone_name_part} {i+1}\".replace(\"'\", \"''\")\n",
    "        \n",
    "        address_val = f\"{random.choice(['Calle', 'Carrera', 'Avenida'])} {random.randint(1,200)} # {random.randint(1,150)}-{random.randint(1,99)}, {fake_co.city().replace(\"'\", \"''\")}\"\n",
    "        depot_type_val = spec[\"type\"]\n",
    "        \n",
    "        capacity_vehicles_val = random.randint(50, 300)\n",
    "        if depot_type_val == \"TALLER\":\n",
    "            capacity_vehicles_val = random.randint(150, 500)\n",
    "        elif depot_type_val == \"ELECTRICO\":\n",
    "            capacity_vehicles_val = random.randint(80, 250)\n",
    "            \n",
    "        location_id_val = random.randint(1, max_location_id) if max_location_id > 0 else \"NULL\"\n",
    "        \n",
    "        concessionaire_id_val_str = \"NULL\"\n",
    "        if max_concessionaire_id > 0 and random.random() > 0.3: # 70% chance of being assigned to a concessionaire\n",
    "            concessionaire_id_val_str = str(random.randint(1, max_concessionaire_id))\n",
    "\n",
    "        all_records_strings.append(\n",
    "            f\"({depot_id_val}, '{name_val}', '{address_val}', '{depot_type_val}', \"\n",
    "            f\"{capacity_vehicles_val}, {location_id_val}, {concessionaire_id_val_str})\"\n",
    "        )\n",
    "\n",
    "try:\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(\"INSERT INTO depots (depot_id, name, address, depot_type, capacity_vehicles, location_id, concessionaire_id) OVERRIDING SYSTEM VALUE VALUES\\n\")\n",
    "        for i, record_string in enumerate(all_records_strings):\n",
    "            file.write(record_string)\n",
    "            if i < len(all_records_strings) - 1:\n",
    "                file.write(\",\\n\")\n",
    "            else:\n",
    "                file.write(\";\\n\")\n",
    "    print(f\"SQL script for depots generated successfully: {os.path.abspath(output_file)}\")\n",
    "except IOError as e:\n",
    "    print(f\"Error writing to file {output_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04479c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 25000 scaled user records...\n",
      "SQL script for users generated successfully: /home/kali/Documents/remote reps/distributed-systems-lab/travel-recharge-database/db/data/04_insert_users.sql\n"
     ]
    }
   ],
   "source": [
    "import faker\n",
    "import random\n",
    "import os\n",
    "from datetime import timedelta, date\n",
    "\n",
    "fake_co = faker.Faker('es_CO')\n",
    "fake_generic = faker.Faker() # For more diverse names\n",
    "\n",
    "output_file = \"04_insert_users.sql\"\n",
    "\n",
    "# Data Scaling: Original target ~2.5M, scaled by 1/100\n",
    "num_users_original_target = 2500000\n",
    "num_users = num_users_original_target // 100  # Approx 25,000\n",
    "\n",
    "print(f\"Generating {num_users} scaled user records...\")\n",
    "\n",
    "genders_list = ['M', 'F', 'O']\n",
    "all_records_strings = []\n",
    "user_id_counter = 0\n",
    "\n",
    "# To ensure unique emails and id_numbers with Faker when generating many records\n",
    "# It's better to track them or use fake.unique within the loop.\n",
    "# For this scale, direct unique calls should be mostly fine.\n",
    "\n",
    "for i in range(num_users):\n",
    "    user_id_counter += 1\n",
    "    user_id_val = user_id_counter # Python controla el ID\n",
    "\n",
    "    if random.random() < 0.85:\n",
    "        first_name_val = fake_co.first_name().replace(\"'\", \"''\")\n",
    "        last_name_val = fake_co.last_name().replace(\"'\", \"''\")\n",
    "    else:\n",
    "        first_name_val = fake_generic.first_name().replace(\"'\", \"''\")\n",
    "        last_name_val = fake_generic.last_name().replace(\"'\", \"''\")\n",
    "        \n",
    "    contact_number_val = fake_co.phone_number()\n",
    "    email_val = fake_co.unique.email().replace(\"'\", \"''\")\n",
    "    gender_val = random.choice(genders_list)\n",
    "    \n",
    "    birth_date_obj = fake_co.date_of_birth(minimum_age=16, maximum_age=85)\n",
    "    date_of_birth_val = birth_date_obj.strftime('%Y-%m-%d')\n",
    "    \n",
    "    street_type = random.choice([\"Calle\", \"Carrera\", \"Avenida\", \"Transversal\", \"Diagonal\"])\n",
    "    street_number = random.randint(1, 200)\n",
    "    part1 = random.randint(1, 150)\n",
    "    part1_letter = random.choice([\"\", \"A\", \"B\", \"C\", \"Bis\"]) if random.random() > 0.5 else \"\"\n",
    "    part2 = random.randint(1, 99)\n",
    "    address_detail_num = f\"{part1}{part1_letter} # {part2}-{random.randint(1,50)}\"\n",
    "    residential_address_val = f\"{street_type} {street_number} {address_detail_num}, {fake_co.city().replace(\"'\", \"''\")}\".replace(\"'\", \"''\")\n",
    "    \n",
    "    id_number_val = str(fake_co.unique.random_number(digits=10, fix_len=True))\n",
    "    city_of_birth_val = fake_co.city().replace(\"'\", \"''\")\n",
    "    \n",
    "    registration_date_obj = fake_co.date_between(start_date='-10y', end_date='today')\n",
    "    registration_date_val = registration_date_obj.strftime('%Y-%m-%d')\n",
    "    \n",
    "    all_records_strings.append(\n",
    "        f\"({user_id_val}, '{first_name_val}', '{last_name_val}', '{contact_number_val}', '{email_val}', \"\n",
    "        f\"'{gender_val}', '{date_of_birth_val}', '{residential_address_val}', '{id_number_val}', \"\n",
    "        f\"'{city_of_birth_val}', '{registration_date_val}')\"\n",
    "    )\n",
    "\n",
    "try:\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(\"INSERT INTO users (user_id, first_name, last_name, contact_number, email, gender, date_of_birth, residential_address, id_number, city_of_birth, registration_date) OVERRIDING SYSTEM VALUE VALUES\\n\")\n",
    "        batch_size = 1000 # For larger datasets, batching INSERTs is good practice\n",
    "        \n",
    "        for i, record_string in enumerate(all_records_strings):\n",
    "            file.write(record_string)\n",
    "            # Logic for batching INSERT statements for performance if num_users was very large\n",
    "            # For 25k, a single VALUES clause is fine, but this handles future scaling.\n",
    "            if (i + 1) % batch_size == 0 and i < len(all_records_strings) - 1:\n",
    "                file.write(\";\\n\")\n",
    "                file.write(\"INSERT INTO users (user_id, first_name, last_name, contact_number, email, gender, date_of_birth, residential_address, id_number, city_of_birth, registration_date) OVERRIDING SYSTEM VALUE VALUES\\n\")\n",
    "            elif i < len(all_records_strings) - 1:\n",
    "                file.write(\",\\n\")\n",
    "            else:\n",
    "                file.write(\";\\n\")\n",
    "    print(f\"SQL script for users generated successfully: {os.path.abspath(output_file)}\")\n",
    "except IOError as e:\n",
    "    print(f\"Error writing to file {output_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa3603e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 24000 scaled card records (aiming for ~20000 active)...\n",
      "SQL script for cards generated successfully: /home/kali/Documents/remote reps/distributed-systems-lab/travel-recharge-database/db/data/05_insert_cards.sql\n",
      "Actual active cards generated: 21268\n"
     ]
    }
   ],
   "source": [
    "# Nombre del archivo: generate_cards.py\n",
    "import faker\n",
    "import random\n",
    "import os\n",
    "from datetime import timedelta, date, datetime\n",
    "\n",
    "fake_co = faker.Faker('es_CO')\n",
    "\n",
    "output_file = \"05_insert_cards.sql\"\n",
    "\n",
    "# IDs máximos de scripts anteriores\n",
    "# De 04_insert_users.sql (asumimos 25,000 usuarios generados)\n",
    "max_user_id = 2500000 // 100\n",
    "\n",
    "# Data Scaling: Original target ~2.3-2.4M cards, with ~2M active. Scaled by 1/100.\n",
    "num_total_cards_original_target = 2400000\n",
    "min_active_cards_original_target = 2000000\n",
    "\n",
    "num_total_cards = num_total_cards_original_target // 100 # Approx 24,000\n",
    "min_active_cards_target = min_active_cards_original_target // 100 # Approx 20,000\n",
    "\n",
    "print(f\"Generating {num_total_cards} scaled card records (aiming for ~{min_active_cards_target} active)...\")\n",
    "\n",
    "card_statuses = ['active', 'inactive', 'blocked', 'lost']\n",
    "all_records_strings = []\n",
    "card_id_counter = 0\n",
    "active_cards_count = 0\n",
    "# Keep track of users who got a card to try and give each user at least one \"active\" card if possible\n",
    "assigned_users_for_active_cards = set()\n",
    "\n",
    "\n",
    "for i in range(num_total_cards):\n",
    "    card_id_counter += 1\n",
    "    card_id_val = card_id_counter # Python controla el ID\n",
    "\n",
    "    card_number_val = str(fake_co.unique.random_number(digits=16, fix_len=True))\n",
    "    \n",
    "    user_id_val = None\n",
    "    # Attempt to assign cards more evenly, ensuring most \"active\" card quota goes to unique users first\n",
    "    if active_cards_count < min_active_cards_target and len(assigned_users_for_active_cards) < max_user_id :\n",
    "        # Try to pick a user who hasn't received an \"active\" card yet\n",
    "        potential_user_ids = list(set(range(1, max_user_id + 1)) - assigned_users_for_active_cards)\n",
    "        if potential_user_ids:\n",
    "            user_id_val = random.choice(potential_user_ids)\n",
    "            # assigned_users_for_active_cards.add(user_id_val) # Add when confirmed active\n",
    "        else: # All users got one attempt for active card, assign randomly\n",
    "            user_id_val = random.randint(1, max_user_id)\n",
    "    else: # Assign randomly if active card target met or all users have one attempt\n",
    "        user_id_val = random.randint(1, max_user_id)\n",
    "\n",
    "\n",
    "    acquisition_date_obj = fake_co.date_between(start_date='-8y', end_date='today')\n",
    "    acquisition_date_val = acquisition_date_obj.strftime('%Y-%m-%d')\n",
    "    \n",
    "    status_val = 'inactive'\n",
    "    if active_cards_count < min_active_cards_target:\n",
    "        status_val = random.choices(card_statuses, weights=[0.90, 0.05, 0.03, 0.02], k=1)[0] # Higher chance of active\n",
    "    else:\n",
    "        status_val = random.choices(card_statuses, weights=[0.70, 0.15, 0.10, 0.05], k=1)[0] # Normal distribution\n",
    "    \n",
    "    if status_val == 'active':\n",
    "        active_cards_count += 1\n",
    "        if user_id_val: assigned_users_for_active_cards.add(user_id_val)\n",
    "\n",
    "    balance_val = 0.0\n",
    "    if status_val == 'active' and random.random() < 0.8:\n",
    "        balance_val = round(random.uniform(1000, 50000) / 50) * 50\n",
    "        \n",
    "    last_used_date_val_str = \"NULL\"\n",
    "    if status_val == 'active' and random.random() < 0.9:\n",
    "        # Ensure last_used_date is after acquisition_date\n",
    "        try:\n",
    "            last_used_datetime_obj = fake_co.date_time_between_dates(datetime_start=datetime.combine(acquisition_date_obj, datetime.min.time()), datetime_end=datetime.now())\n",
    "            last_used_date_val_str = f\"'{last_used_datetime_obj.strftime('%Y-%m-%d %H:%M:%S')}'\"\n",
    "        except: # Fallback if acquisition_date is today\n",
    "            last_used_date_val_str = f\"'{datetime.combine(acquisition_date_obj, fake_co.time_object()).strftime('%Y-%m-%d %H:%M:%S')}'\"\n",
    "\n",
    "    update_date_obj = fake_co.date_between_dates(date_start=acquisition_date_obj, date_end=date.today())\n",
    "    update_date_val = update_date_obj.strftime('%Y-%m-%d')\n",
    "\n",
    "    all_records_strings.append(\n",
    "        f\"({card_id_val}, '{card_number_val}', {user_id_val}, '{acquisition_date_val}', '{status_val}', \"\n",
    "        f\"{balance_val}, {last_used_date_val_str}, '{update_date_val}')\"\n",
    "    )\n",
    "\n",
    "try:\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(\"INSERT INTO cards (card_id, card_number, user_id, acquisition_date, status, balance, last_used_date, update_date) OVERRIDING SYSTEM VALUE VALUES\\n\")\n",
    "        batch_size = 1000\n",
    "        for i, record_string in enumerate(all_records_strings):\n",
    "            file.write(record_string)\n",
    "            if (i + 1) % batch_size == 0 and i < len(all_records_strings) - 1:\n",
    "                file.write(\";\\n\")\n",
    "                file.write(\"INSERT INTO cards (card_id, card_number, user_id, acquisition_date, status, balance, last_used_date, update_date) OVERRIDING SYSTEM VALUE VALUES\\n\")\n",
    "            elif i < len(all_records_strings) - 1:\n",
    "                file.write(\",\\n\")\n",
    "            else:\n",
    "                file.write(\";\\n\")\n",
    "    print(f\"SQL script for cards generated successfully: {os.path.abspath(output_file)}\")\n",
    "    print(f\"Actual active cards generated: {active_cards_count}\")\n",
    "except IOError as e:\n",
    "    print(f\"Error writing to file {output_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebc2bb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 4850 recharge point records...\n",
      "SQL script for recharge_points (fixed 4850 records) generated successfully: /home/kali/Documents/remote reps/distributed-systems-lab/travel-recharge-database/db/data/06_insert_recharge_points.sql\n"
     ]
    }
   ],
   "source": [
    "# Nombre del archivo: generate_recharge_points.py\n",
    "import faker\n",
    "import random\n",
    "import os\n",
    "\n",
    "fake_co = faker.Faker('es_CO')\n",
    "\n",
    "output_file = \"06_insert_recharge_points.sql\"\n",
    "\n",
    "# IDs máximos de scripts anteriores\n",
    "max_location_id = 13 # De 01_insert_locations.sql\n",
    "\n",
    "# --- NÚMERO FIJO DE PUNTOS DE RECARGA ---\n",
    "# Usaremos un número fijo para que el script de recargas sepa el máximo ID exacto.\n",
    "# Este número está dentro del rango random.randint(4800, 4900) que tenías.\n",
    "FIXED_NUM_RECHARGE_POINTS = 4850\n",
    "num_recharge_points = FIXED_NUM_RECHARGE_POINTS\n",
    "\n",
    "print(f\"Generating {num_recharge_points} recharge point records...\")\n",
    "\n",
    "recharge_point_operators = [\"PuntoRed\", \"SuRed\", \"MoviiRed\", \"PagaTodo\", \"Station Kiosk\", \"Online Platform\"]\n",
    "all_records_strings = []\n",
    "recharge_point_id_counter = 0\n",
    "online_platform_created = False # Para asegurar solo una plataforma online principal\n",
    "\n",
    "for i in range(num_recharge_points):\n",
    "    recharge_point_id_counter += 1\n",
    "    recharge_point_id_val = recharge_point_id_counter\n",
    "\n",
    "    operator_val = random.choice(recharge_point_operators)\n",
    "    \n",
    "    name_content = \"\"\n",
    "    address_sql_formatted = \"NULL\"\n",
    "    latitude_sql_formatted = \"NULL\"\n",
    "    longitude_sql_formatted = \"NULL\"\n",
    "    location_id_sql_formatted = \"NULL\"\n",
    "\n",
    "    is_online_platform_scenario = False\n",
    "    if operator_val == \"Online Platform\":\n",
    "        if not online_platform_created:\n",
    "            name_content = \"Plataforma de Recarga Online Principal\"\n",
    "            online_platform_created = True\n",
    "            is_online_platform_scenario = True\n",
    "        else:\n",
    "            # Si ya se creó la online, forzar otro tipo de operador para este punto\n",
    "            operator_val = random.choice([op for op in recharge_point_operators if op != \"Online Platform\"])\n",
    "            # Y continuar como si fuera un punto físico (más abajo)\n",
    "\n",
    "    if not is_online_platform_scenario: # Para todos los puntos físicos\n",
    "        point_type = random.choice([\"Tienda\", \"Papelería\", \"Droguería\", \"Miscelánea\", \"Kiosko Estación\"])\n",
    "        # Generar nombre y dirección base\n",
    "        base_name_part1 = fake_co.company().split(' ')[0].replace(',', '').replace(\"'\", \"''\")\n",
    "        base_name_part2 = fake_co.street_name().split(' ')[-1].replace(\"'\", \"''\")\n",
    "        name_content = f\"{point_type} {base_name_part1}-{base_name_part2} {random.randint(1,100)}\"\n",
    "\n",
    "        street_t = random.choice([\"Calle\", \"Carrera\", \"Avenida\", \"Transversal\", \"Diagonal\"])\n",
    "        address_raw_content = f\"{street_t} {random.randint(1,200)} # {random.randint(1,99)}-{random.randint(1,99)}\"\n",
    "        # Escapar comillas internas y añadir comillas externas para SQL\n",
    "        address_sql_formatted = f\"'{address_raw_content.replace(\"'\", \"''\")}'\"\n",
    "        \n",
    "        latitude_sql_formatted = str(round(random.uniform(4.40, 4.80), 6))\n",
    "        longitude_sql_formatted = str(round(random.uniform(-74.20, -74.00), 6))\n",
    "        if max_location_id > 0:\n",
    "            location_id_sql_formatted = str(random.randint(1, max_location_id))\n",
    "\n",
    "    # Escapar comillas simples en el nombre final\n",
    "    name_val_sql_escaped = name_content.replace(\"'\", \"''\")\n",
    "    \n",
    "    all_records_strings.append(\n",
    "        f\"({recharge_point_id_val}, '{name_val_sql_escaped}', {address_sql_formatted}, \"\n",
    "        f\"{latitude_sql_formatted}, {longitude_sql_formatted}, \"\n",
    "        f\"{location_id_sql_formatted}, '{operator_val}')\"\n",
    "    )\n",
    "\n",
    "try:\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(\"INSERT INTO recharge_points (recharge_point_id, name, address, latitude, longitude, location_id, operator) OVERRIDING SYSTEM VALUE VALUES\\n\")\n",
    "        batch_size = 1000\n",
    "        for i, record_string in enumerate(all_records_strings):\n",
    "            file.write(record_string)\n",
    "            if (i + 1) % batch_size == 0 and i < len(all_records_strings) - 1:\n",
    "                file.write(\";\\n\")\n",
    "                file.write(\"INSERT INTO recharge_points (recharge_point_id, name, address, latitude, longitude, location_id, operator) OVERRIDING SYSTEM VALUE VALUES\\n\")\n",
    "            elif i < len(all_records_strings) - 1:\n",
    "                file.write(\",\\n\")\n",
    "            else:\n",
    "                file.write(\";\\n\")\n",
    "    print(f\"SQL script for recharge_points (fixed {num_recharge_points} records) generated successfully: {os.path.abspath(output_file)}\")\n",
    "except IOError as e:\n",
    "    print(f\"Error writing to file {output_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65458168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 4 fare records...\n",
      "SQL script for fares generated successfully: /home/kali/Documents/remote reps/distributed-systems-lab/travel-recharge-database/db/data/07_insert_fares.sql\n"
     ]
    }
   ],
   "source": [
    "# Nombre del archivo: generate_fares.py\n",
    "import os\n",
    "from datetime import date\n",
    "\n",
    "output_file = \"07_insert_fares.sql\"\n",
    "\n",
    "# Basado en tarifas discutidas y el script 11_insert_fares.sql anterior\n",
    "fare_data_definitions = [\n",
    "    {\n",
    "        \"fare_id\": 1,\n",
    "        \"fare_type\": \"STANDARD_SITP\",\n",
    "        \"value\": 2950.00,\n",
    "        \"start_date\": date(2024, 1, 15).strftime('%Y-%m-%d'),\n",
    "        \"end_date\": \"NULL\",\n",
    "        \"description\": \"Tarifa estándar del componente Troncal y Zonal del SITP.\"\n",
    "    },\n",
    "    {\n",
    "        \"fare_id\": 2,\n",
    "        \"fare_type\": \"TRANSFER_0_COST\",\n",
    "        \"value\": 0.00,\n",
    "        \"start_date\": date(2024, 1, 15).strftime('%Y-%m-%d'),\n",
    "        \"end_date\": \"NULL\",\n",
    "        \"description\": \"Transbordo sin costo adicional (dentro de la ventana de tiempo y condiciones).\"\n",
    "    },\n",
    "    {\n",
    "        \"fare_id\": 3,\n",
    "        \"fare_type\": \"TRANSFER_200_COST\",\n",
    "        \"value\": 200.00,\n",
    "        \"start_date\": date(2024, 1, 15).strftime('%Y-%m-%d'),\n",
    "        \"end_date\": \"NULL\",\n",
    "        \"description\": \"Transbordo con costo de $200 COP (dentro de la ventana de tiempo y condiciones).\"\n",
    "    },\n",
    "    {\n",
    "        \"fare_id\": 4,\n",
    "        \"fare_type\": \"STANDARD_CABLE\",\n",
    "        \"value\": 2950.00,\n",
    "        \"start_date\": date(2024, 1, 15).strftime('%Y-%m-%d'),\n",
    "        \"end_date\": \"NULL\",\n",
    "        \"description\": \"Tarifa estándar para TransMiCable.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Generating {len(fare_data_definitions)} fare records...\")\n",
    "all_records_strings = []\n",
    "\n",
    "for fare_def in fare_data_definitions:\n",
    "    fare_id_val = fare_def[\"fare_id\"] # Python controla el ID\n",
    "    fare_type_val = fare_def[\"fare_type\"].replace(\"'\", \"''\")\n",
    "    value_val = fare_def[\"value\"]\n",
    "    start_date_val = fare_def[\"start_date\"]\n",
    "    end_date_val_str = f\"'{fare_def['end_date']}'\" if fare_def[\"end_date\"] != \"NULL\" else \"NULL\"\n",
    "    description_val = fare_def[\"description\"].replace(\"'\", \"''\")\n",
    "    \n",
    "    all_records_strings.append(\n",
    "        f\"({fare_id_val}, '{fare_type_val}', {value_val}, '{start_date_val}', {end_date_val_str}, '{description_val}')\"\n",
    "    )\n",
    "\n",
    "try:\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(\"INSERT INTO fares (fare_id, fare_type, value, start_date, end_date, description) OVERRIDING SYSTEM VALUE VALUES\\n\")\n",
    "        for i, record_string in enumerate(all_records_strings):\n",
    "            file.write(record_string)\n",
    "            if i < len(all_records_strings) - 1:\n",
    "                file.write(\",\\n\")\n",
    "            else:\n",
    "                file.write(\";\\n\")\n",
    "    print(f\"SQL script for fares generated successfully: {os.path.abspath(output_file)}\")\n",
    "except IOError as e:\n",
    "    print(f\"Error writing to file {output_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8eeb55db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 67646 recharge records (max_recharge_point_id set to 4850)...\n",
      "SQL script for recharges generated successfully: /home/kali/Documents/remote reps/distributed-systems-lab/travel-recharge-database/db/data/08_insert_recharges.sql\n"
     ]
    }
   ],
   "source": [
    "# Nombre del archivo: generate_recharges.py\n",
    "import faker\n",
    "import random\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import uuid\n",
    "\n",
    "fake_co = faker.Faker('es_CO')\n",
    "\n",
    "output_file = \"08_insert_recharges.sql\"\n",
    "\n",
    "# IDs máximos de scripts anteriores\n",
    "max_card_id = 2400000 // 100 # De 05_insert_cards.sql (24,000 tarjetas)\n",
    "assumed_active_card_threshold_id = 2000000 // 100\n",
    "\n",
    "# --- USAR EL MISMO NÚMERO FIJO QUE EN generate_recharge_points.py ---\n",
    "FIXED_NUM_RECHARGE_POINTS = 4850\n",
    "max_recharge_point_id = FIXED_NUM_RECHARGE_POINTS # Asegura que no se exceda el ID máximo real\n",
    "\n",
    "num_recharges = random.randint(max_card_id * 2, max_card_id * 4) # Ej: entre 48k y 96k recargas\n",
    "\n",
    "print(f\"Generating {num_recharges} recharge records (max_recharge_point_id set to {max_recharge_point_id})...\")\n",
    "\n",
    "recharge_amounts_cop = [2000, 2200, 2950, 5000, 5900, 10000, 11800, 15000, 20000, 23600, 30000, 50000, 100000]\n",
    "recharge_amounts_weights = [10, 5, 10, 20, 5, 25, 10, 5, 20, 5, 3, 10, 2]\n",
    "\n",
    "all_records_strings = []\n",
    "recharge_id_counter = 0\n",
    "\n",
    "for i in range(num_recharges):\n",
    "    recharge_id_counter += 1\n",
    "    recharge_id_val = recharge_id_counter\n",
    "\n",
    "    if random.random() < 0.85 and assumed_active_card_threshold_id > 0:\n",
    "        card_id_val = random.randint(1, assumed_active_card_threshold_id)\n",
    "    else:\n",
    "        card_id_val = random.randint(1, max_card_id)\n",
    "\n",
    "    # recharge_point_id_val ahora usará el límite correcto\n",
    "    recharge_point_id_val = random.randint(1, max_recharge_point_id) \n",
    "    amount_val = random.choices(recharge_amounts_cop, weights=recharge_amounts_weights, k=1)[0]\n",
    "\n",
    "    # Fechas de recarga contextualizadas alrededor de Junio 2024\n",
    "    reference_date_for_recharge = datetime(2024, 6, 15)\n",
    "    # Genera recargas en los 3 años anteriores a Junio 2024\n",
    "    days_back = random.randint(1, 3 * 365) \n",
    "    hour_val = random.randint(6, 22) # Horas de recarga más comunes\n",
    "    minute_val = random.randint(0, 59)\n",
    "    second_val = random.randint(0, 59)\n",
    "    \n",
    "    try:\n",
    "        recharge_datetime_obj = reference_date_for_recharge - timedelta(days=days_back)\n",
    "        recharge_datetime_obj = recharge_datetime_obj.replace(hour=hour_val, minute=minute_val, second=second_val)\n",
    "    except ValueError: # Manejo de fechas inválidas como 29 de febrero en año no bisiesto\n",
    "        recharge_datetime_obj = reference_date_for_recharge - timedelta(days=days_back + 1) # Ajustar al día anterior\n",
    "        recharge_datetime_obj = recharge_datetime_obj.replace(hour=hour_val, minute=minute_val, second=second_val)\n",
    "\n",
    "\n",
    "    recharge_timestamp_val = recharge_datetime_obj.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    transaction_id_val = str(uuid.uuid4())\n",
    "\n",
    "    all_records_strings.append(\n",
    "        f\"({recharge_id_val}, {card_id_val}, {recharge_point_id_val}, {amount_val}, '{recharge_timestamp_val}', '{transaction_id_val}')\"\n",
    "    )\n",
    "\n",
    "try:\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(\"INSERT INTO recharges (recharge_id, card_id, recharge_point_id, amount, recharge_timestamp, transaction_id) OVERRIDING SYSTEM VALUE VALUES\\n\")\n",
    "        batch_size = 1000\n",
    "        for i, record_string in enumerate(all_records_strings):\n",
    "            file.write(record_string)\n",
    "            if (i + 1) % batch_size == 0 and i < len(all_records_strings) - 1:\n",
    "                file.write(\";\\n\")\n",
    "                file.write(\"INSERT INTO recharges (recharge_id, card_id, recharge_point_id, amount, recharge_timestamp, transaction_id) OVERRIDING SYSTEM VALUE VALUES\\n\")\n",
    "            elif i < len(all_records_strings) - 1:\n",
    "                file.write(\",\\n\")\n",
    "            else:\n",
    "                file.write(\";\\n\")\n",
    "    print(f\"SQL script for recharges generated successfully: {os.path.abspath(output_file)}\")\n",
    "except IOError as e:\n",
    "    print(f\"Error writing to file {output_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "988d430e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating records for 9 portals, 4 cable, 129 other troncal stations, and 7623 zonal paraderos...\n",
      "SQL script for stations generated successfully: /home/kali/Documents/remote reps/distributed-systems-lab/travel-recharge-database/db/data/09_insert_stations.sql\n",
      "Total station records generated: 7765\n"
     ]
    }
   ],
   "source": [
    "# Nombre del archivo: generate_stations.py\n",
    "import faker\n",
    "import random\n",
    "import os\n",
    "\n",
    "fake_co = faker.Faker('es_CO')\n",
    "\n",
    "output_file = \"09_insert_stations.sql\"\n",
    "\n",
    "# IDs máximos de scripts anteriores\n",
    "max_location_id = 13 # De 01_insert_locations.sql\n",
    "\n",
    "# --- Station Counts from PDF ---\n",
    "NUM_PORTALS = 9\n",
    "NUM_CABLE_STATIONS_PDF = 4\n",
    "TOTAL_STATIONS_INC_CABLE_PDF = 142\n",
    "NUM_TRONCAL_STATIONS_OTHER_PDF = TOTAL_STATIONS_INC_CABLE_PDF - NUM_PORTALS - NUM_CABLE_STATIONS_PDF\n",
    "NUM_ZONAL_PARADEROS_PDF = 7623\n",
    "\n",
    "NUM_STATIONS_WITH_CYCLE_PARKING_PDF = 27\n",
    "TOTAL_CYCLE_PARKING_SPOTS_PDF = 7351\n",
    "\n",
    "print(f\"Generating records for {NUM_PORTALS} portals, {NUM_CABLE_STATIONS_PDF} cable, {NUM_TRONCAL_STATIONS_OTHER_PDF} other troncal stations, and {NUM_ZONAL_PARADEROS_PDF} zonal paraderos...\")\n",
    "\n",
    "portal_names_list = [\n",
    "    \"Portal Américas\", \"Portal del Norte\", \"Portal Suba\", \"Portal Calle 80\",\n",
    "    \"Portal del Sur\", \"Portal Eldorado\", \"Portal Tunal\", \"Portal 20 de Julio\", \"Portal Usme\"\n",
    "]\n",
    "if len(portal_names_list) > NUM_PORTALS: portal_names_list = portal_names_list[:NUM_PORTALS]\n",
    "while len(portal_names_list) < NUM_PORTALS: portal_names_list.append(f\"Portal Adicional {len(portal_names_list)+1}\")\n",
    "\n",
    "cable_station_names_list = [\"Portal Tunal - Cable\", \"Juan Pablo II - Cable\", \"Manitas - Cable\", \"Mirador del Paraíso - Cable\"]\n",
    "if len(cable_station_names_list) > NUM_CABLE_STATIONS_PDF: cable_station_names_list = cable_station_names_list[:NUM_CABLE_STATIONS_PDF]\n",
    "while len(cable_station_names_list) < NUM_CABLE_STATIONS_PDF: cable_station_names_list.append(f\"Estación Cable Adicional {len(cable_station_names_list)+1}\")\n",
    "\n",
    "real_troncal_station_names = [\n",
    "    \"SAN MATEO - C.C. UNISUR\", \"Calle 100 - Marketmedios\", \"Banderas\", \"Avenida Jiménez (Centro)\",\n",
    "    \"Toberín - Foundever\", \"Calle 76 - San Felipe\", \"TERREROS\", \"Calle 57 - Tecnoparque\", \"Alcalá - C.C. Futuro 140\", \"Calle 45 - American School\",\n",
    "    \"León XIII\", \"Despensa\", \"Bosa Estación\", \"Universidades - CityU\", \"Museo Nacional\", \"CAD\", \"Paloquemao\", \"Ricaurte\", \"Sabana\", \"Profamilia\", \"Marly\", \"Flores\",\n",
    "    \"Pepe Sierra\", \"Calle 127\", \"Mazurén\", \"Virrey\", \"Héroes\", \"Restrepo\", \"Santa Lucía\", \"Country Sur\"\n",
    "]\n",
    "random.shuffle(real_troncal_station_names)\n",
    "\n",
    "station_id_counter = 0\n",
    "all_station_objects = [] # Lista de diccionarios\n",
    "station_codes_generated = set()\n",
    "stations_eligible_for_cycle_parking = []\n",
    "\n",
    "def generate_station_code_unique(s_type, counter, zone_prefix=None):\n",
    "    global station_codes_generated\n",
    "    code_attempts = 0\n",
    "    while code_attempts < 200:\n",
    "        prefix_num_str = str(counter % 1000).zfill(3)\n",
    "        if s_type == \"PORTAL\": code = f\"P{str(counter).zfill(2)}\"\n",
    "        elif s_type == \"CABLE\": code = f\"TC{str(counter).zfill(2)}\"\n",
    "        elif s_type.startswith(\"TRONCAL\"):\n",
    "            line_letter = chr(65 + random.randint(0, 12))\n",
    "            code = f\"{line_letter}{str(counter % 100).zfill(2)}\"\n",
    "        elif s_type == \"ZONAL_PARADERO\":\n",
    "            p1 = zone_prefix if zone_prefix else str(random.randint(100,799))\n",
    "            p2 = chr(65 + random.randint(0,25))\n",
    "            p3 = str(counter % 100).zfill(2)\n",
    "            code = f\"{p1}{p2}{p3}\"\n",
    "        else: code = f\"UNK{prefix_num_str}\"\n",
    "        \n",
    "        if code not in station_codes_generated:\n",
    "            station_codes_generated.add(code)\n",
    "            return code\n",
    "        counter += random.randint(1,10)\n",
    "        code_attempts +=1\n",
    "    return f\"ERR{s_type}{random.randint(1000,9999)}\"\n",
    "\n",
    "# 1. Portals\n",
    "for i in range(NUM_PORTALS):\n",
    "    station_id_counter += 1\n",
    "    name_val = portal_names_list[i].replace(\"'\", \"''\")\n",
    "    code_val = generate_station_code_unique(\"PORTAL\", i + 1)\n",
    "    stations_eligible_for_cycle_parking.append({\"id\": station_id_counter, \"type\": \"PORTAL\"})\n",
    "    all_station_objects.append({\n",
    "        \"station_id\": station_id_counter, \"name\": name_val, \"station_code\": code_val,\n",
    "        \"station_type\": \"PORTAL\", \"address\": f\"{name_val}, Bogotá D.C.\".replace(\"'\", \"''\"),\n",
    "        \"location_id\": random.randint(1, max_location_id) if max_location_id > 0 else None,\n",
    "        \"latitude\": round(random.uniform(4.45, 4.75), 6),\n",
    "        \"longitude\": round(random.uniform(-74.18, -74.02), 6),\n",
    "        \"has_cycle_parking\": False, \"cycle_parking_spots\": 0, \"is_active\": True\n",
    "    })\n",
    "\n",
    "# 2. Cable Stations\n",
    "cable_station_code_counter = 0\n",
    "for i in range(NUM_CABLE_STATIONS_PDF):\n",
    "    station_id_counter += 1\n",
    "    cable_station_code_counter +=1\n",
    "    name_val = cable_station_names_list[i].replace(\"'\", \"''\")\n",
    "    code_val = generate_station_code_unique(\"CABLE\", cable_station_code_counter)\n",
    "    if random.random() < 0.25 : stations_eligible_for_cycle_parking.append({\"id\": station_id_counter, \"type\": \"CABLE\"})\n",
    "    all_station_objects.append({\n",
    "        \"station_id\": station_id_counter, \"name\": name_val, \"station_code\": code_val,\n",
    "        \"station_type\": \"CABLE\", \"address\": f\"{name_val}, Ciudad Bolívar\".replace(\"'\", \"''\"),\n",
    "        \"location_id\": random.randint(1, max_location_id) if max_location_id > 0 else None,\n",
    "        \"latitude\": round(random.uniform(4.50, 4.60), 6),\n",
    "        \"longitude\": round(random.uniform(-74.17, -74.12), 6),\n",
    "        \"has_cycle_parking\": False, \"cycle_parking_spots\": 0, \"is_active\": True\n",
    "    })\n",
    "\n",
    "# 3. Other Troncal Stations\n",
    "troncal_station_code_counter = 0\n",
    "for i in range(NUM_TRONCAL_STATIONS_OTHER_PDF):\n",
    "    station_id_counter += 1\n",
    "    troncal_station_code_counter +=1\n",
    "    if i < len(real_troncal_station_names):\n",
    "        name_val = real_troncal_station_names[i].replace(\"'\", \"''\")\n",
    "    else:\n",
    "        name_val = f\"Estación Troncal {fake_co.street_name().replace(\"'\", \"''\")}\"\n",
    "    \n",
    "    station_type_val = random.choice([\"TRONCAL_SIMPLE\", \"TRONCAL_INTERMEDIA\", \"TRONCAL_CABECERA\"])\n",
    "    code_val = generate_station_code_unique(station_type_val, troncal_station_code_counter)\n",
    "    if random.random() < 0.15 : stations_eligible_for_cycle_parking.append({\"id\": station_id_counter, \"type\": station_type_val})\n",
    "    all_station_objects.append({\n",
    "        \"station_id\": station_id_counter, \"name\": name_val, \"station_code\": code_val,\n",
    "        \"station_type\": station_type_val, \"address\": f\"Estación {name_val}, Bogotá D.C.\".replace(\"'\", \"''\"),\n",
    "        \"location_id\": random.randint(1, max_location_id) if max_location_id > 0 else None,\n",
    "        \"latitude\": round(random.uniform(4.55, 4.70), 6),\n",
    "        \"longitude\": round(random.uniform(-74.12, -74.05), 6),\n",
    "        \"has_cycle_parking\": False, \"cycle_parking_spots\": 0, \"is_active\": True\n",
    "    })\n",
    "\n",
    "# 4. Zonal Paraderos\n",
    "paradero_code_internal_counter = 0\n",
    "paradero_zone_prefixes = [str(random.randint(100, 799)) for _ in range(max_location_id if max_location_id > 0 else 1)]\n",
    "for i in range(NUM_ZONAL_PARADEROS_PDF):\n",
    "    station_id_counter += 1\n",
    "    paradero_code_internal_counter +=1\n",
    "    loc_id = random.randint(1, max_location_id) if max_location_id > 0 else 1\n",
    "    name_val = f\"Paradero {fake_co.street_name().replace(\"'\", \"''\")} con {random.choice(['Kr.', 'Cl.'])} {random.randint(10,150)}\"\n",
    "    code_val = generate_station_code_unique(\"ZONAL_PARADERO\", paradero_code_internal_counter, zone_prefix=paradero_zone_prefixes[loc_id-1])\n",
    "    all_station_objects.append({\n",
    "        \"station_id\": station_id_counter, \"name\": name_val, \"station_code\": code_val,\n",
    "        \"station_type\": \"ZONAL_PARADERO\", \"address\": f\"{name_val}, Bogotá D.C.\".replace(\"'\", \"''\"),\n",
    "        \"location_id\": loc_id,\n",
    "        \"latitude\": round(random.uniform(4.40, 4.80), 6),\n",
    "        \"longitude\": round(random.uniform(-74.20, -74.00), 6),\n",
    "        \"has_cycle_parking\": False, \"cycle_parking_spots\": 0, \"is_active\": True\n",
    "    })\n",
    "\n",
    "# --- Distribute Cycle Parking Spots ---\n",
    "stations_to_receive_parking = random.sample(\n",
    "    stations_eligible_for_cycle_parking, \n",
    "    min(NUM_STATIONS_WITH_CYCLE_PARKING_PDF, len(stations_eligible_for_cycle_parking))\n",
    ")\n",
    "\n",
    "if stations_to_receive_parking:\n",
    "    temp_spots_assignment = {} # Store {station_id: spots}\n",
    "    for station_info in stations_to_receive_parking:\n",
    "        base_spots = 0\n",
    "        if station_info[\"type\"] == \"PORTAL\": base_spots = random.randint(150, 600)\n",
    "        elif station_info[\"type\"] == \"TRONCAL_INTERMEDIA\" or station_info[\"type\"] == \"TRONCAL_CABECERA\": base_spots = random.randint(50, 200)\n",
    "        else: base_spots = random.randint(20, 100) # CABLE or TRONCAL_SIMPLE\n",
    "        temp_spots_assignment[station_info[\"id\"]] = max(10, base_spots)\n",
    "\n",
    "    current_assigned_total_spots = sum(temp_spots_assignment.values())\n",
    "    \n",
    "    if current_assigned_total_spots > 0:\n",
    "        adjustment_factor = TOTAL_CYCLE_PARKING_SPOTS_PDF / current_assigned_total_spots\n",
    "        final_spots_assignment = {}\n",
    "        normalized_total_spots = 0\n",
    "        \n",
    "        ids_in_temp = list(temp_spots_assignment.keys())\n",
    "        for s_id_pk in ids_in_temp:\n",
    "            assigned = int(temp_spots_assignment[s_id_pk] * adjustment_factor)\n",
    "            final_spots_assignment[s_id_pk] = assigned\n",
    "            normalized_total_spots += assigned\n",
    "        \n",
    "        # Distribute remainder due to int conversion\n",
    "        spots_remainder = TOTAL_CYCLE_PARKING_SPOTS_PDF - normalized_total_spots\n",
    "        idx = 0\n",
    "        while spots_remainder > 0 and idx < len(ids_in_temp):\n",
    "            final_spots_assignment[ids_in_temp[idx]] += 1\n",
    "            spots_remainder -= 1\n",
    "            idx = (idx + 1) % len(ids_in_temp) # Cycle through eligible stations\n",
    "        \n",
    "        # Update the main list of objects\n",
    "        for station_obj in all_station_objects:\n",
    "            if station_obj[\"station_id\"] in final_spots_assignment:\n",
    "                station_obj[\"cycle_parking_spots\"] = final_spots_assignment[station_obj[\"station_id\"]]\n",
    "                if station_obj[\"cycle_parking_spots\"] > 0:\n",
    "                    station_obj[\"has_cycle_parking\"] = True\n",
    "                else: # Ensure consistency if spots ended up as 0 after adjustment\n",
    "                    station_obj[\"has_cycle_parking\"] = False\n",
    "\n",
    "\n",
    "# --- Write to SQL file ---\n",
    "all_records_strings_for_sql = []\n",
    "for record_obj in all_station_objects:\n",
    "    # Handle NULL for location_id properly\n",
    "    loc_id_sql = str(record_obj['location_id']) if record_obj['location_id'] is not None else \"NULL\"\n",
    "    \n",
    "    # Python booleans True/False are directly converted to TRUE/FALSE in f-string for SQL\n",
    "    all_records_strings_for_sql.append(\n",
    "        f\"({record_obj['station_id']}, '{record_obj['name']}', '{record_obj['station_code']}', \"\n",
    "        f\"'{record_obj['station_type']}', '{record_obj['address']}', {loc_id_sql}, \"\n",
    "        f\"{record_obj['latitude']}, {record_obj['longitude']}, {record_obj['has_cycle_parking']}, \"\n",
    "        f\"{record_obj['cycle_parking_spots']}, {record_obj['is_active']})\"\n",
    "    )\n",
    "\n",
    "try:\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(\"INSERT INTO stations (station_id, name, station_code, station_type, address, location_id, latitude, longitude, has_cycle_parking, cycle_parking_spots, is_active) OVERRIDING SYSTEM VALUE VALUES\\n\")\n",
    "        batch_size = 1000\n",
    "        for i, record_string in enumerate(all_records_strings_for_sql):\n",
    "            file.write(record_string)\n",
    "            if (i + 1) % batch_size == 0 and i < len(all_records_strings_for_sql) - 1:\n",
    "                file.write(\";\\n\")\n",
    "                file.write(\"INSERT INTO stations (station_id, name, station_code, station_type, address, location_id, latitude, longitude, has_cycle_parking, cycle_parking_spots, is_active) OVERRIDING SYSTEM VALUE VALUES\\n\")\n",
    "            elif i < len(all_records_strings_for_sql) - 1:\n",
    "                file.write(\",\\n\")\n",
    "            else:\n",
    "                file.write(\";\\n\")\n",
    "    print(f\"SQL script for stations generated successfully: {os.path.abspath(output_file)}\")\n",
    "    print(f\"Total station records generated: {station_id_counter}\")\n",
    "except IOError as e:\n",
    "    print(f\"Error writing to file {output_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57c4a18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating vehicle records...\n",
      "SQL script for vehicles generated successfully: /home/kali/Documents/remote reps/distributed-systems-lab/travel-recharge-database/db/data/10_insert_vehicles.sql\n"
     ]
    }
   ],
   "source": [
    "# Nombre del archivo: generate_vehicles.py\n",
    "import faker\n",
    "import random\n",
    "import os\n",
    "\n",
    "fake_co = faker.Faker('es_CO')\n",
    "output_file = \"10_insert_vehicles.sql\"\n",
    "\n",
    "# IDs máximos de scripts anteriores\n",
    "max_concessionaire_id = 27 # De 02_insert_concessionaires.sql\n",
    "max_depot_id = 58          # De 03_insert_depots.sql\n",
    "\n",
    "print(\"Generating vehicle records...\")\n",
    "\n",
    "vehicle_specs_list = [\n",
    "    {\"type\": \"ALIMENTADOR_50\", \"capacity\": 50, \"count\": 86, \"component\": \"ALIMENTACION\"},\n",
    "    {\"type\": \"ALIMENTADOR_80\", \"capacity\": 80, \"count\": 862, \"component\": \"ALIMENTACION\"},\n",
    "    {\"type\": \"ARTICULADO\", \"capacity\": 160, \"count\": 602, \"component\": \"TRONCAL\"},\n",
    "    {\"type\": \"BIARTICULADO\", \"capacity\": 250, \"count\": 1317, \"component\": \"TRONCAL\"},\n",
    "    {\"type\": \"PADRON_DUAL\", \"capacity\": 80, \"count\": 272, \"component\": \"TRONCAL\"}, # O podría ser DUAL si se maneja como un componente separado\n",
    "    {\"type\": \"BUS_19\", \"capacity\": 19, \"count\": 5, \"component\": \"ZONAL\"},\n",
    "    {\"type\": \"BUS_40\", \"capacity\": 40, \"count\": 611, \"component\": \"ZONAL\"},\n",
    "    {\"type\": \"BUS_50\", \"capacity\": 50, \"count\": 3511, \"component\": \"ZONAL\"},\n",
    "    {\"type\": \"BUS_80\", \"capacity\": 80, \"count\": 3297, \"component\": \"ZONAL\"},\n",
    "    # Podríamos añadir CABLE_CABIN si es necesario, el PDF suma 10563 sin cabinas de cable explícitamente en esa tabla.\n",
    "]\n",
    "total_vehicles_to_generate = sum(spec[\"count\"] for spec in vehicle_specs_list)\n",
    "\n",
    "# Distribución de tecnologías basada en el PDF (página 10)\n",
    "tech_distribution_template = {\n",
    "    \"ELECTRICO\": 1486, \"GNV\": 2144, \"HIBRIDO\": 348,\n",
    "    \"DIESEL_EURO_VI\": 2382, \"DIESEL_EURO_V\": 4162\n",
    "}\n",
    "# Ajustar si la suma no da el total_vehicles_to_generate (10522 vs 10563)\n",
    "tech_sum = sum(tech_distribution_template.values())\n",
    "if total_vehicles_to_generate > tech_sum:\n",
    "    tech_distribution_template[\"DIESEL_EURO_V\"] += (total_vehicles_to_generate - tech_sum)\n",
    "elif tech_sum > total_vehicles_to_generate: # Improbable con los datos del PDF, pero por si acaso\n",
    "    # Reducir proporcionalmente o de la categoría más grande\n",
    "    diff = tech_sum - total_vehicles_to_generate\n",
    "    tech_distribution_template[\"DIESEL_EURO_V\"] -= diff # Asumiendo que Diesel Euro V puede absorber la diferencia\n",
    "\n",
    "technologies_list_flat = []\n",
    "for tech, count in tech_distribution_template.items():\n",
    "    technologies_list_flat.extend([tech] * count)\n",
    "random.shuffle(technologies_list_flat)\n",
    "\n",
    "# Distribución de años de modelo (aproximada y simplificada del PDF)\n",
    "model_year_dist_template = {\n",
    "    2023: 336, 2022: 1007, 2021: 1799, 2020: 1624, 2019: 313, 2017: 63, 2016: 160,\n",
    "    2015: 1264, 2014: 333, 2013: 335, 2012: 292, 2011: 142, 2010: 234, 2009: 53, 2008: 15\n",
    "}\n",
    "model_years_list_flat = []\n",
    "for year, count in model_year_dist_template.items():\n",
    "    model_years_list_flat.extend([year] * count)\n",
    "\n",
    "remaining_vehicles_for_year = total_vehicles_to_generate - len(model_years_list_flat)\n",
    "if remaining_vehicles_for_year > 0:\n",
    "    # Distribuir los restantes en un rango plausible, ej. 2010-2018 con más peso en años intermedios\n",
    "    additional_years = random.choices(\n",
    "        population=list(range(2010, 2019)), \n",
    "        weights=[1,1,2,2,3,3,2,2,1], # Pesos para un pico alrededor de 2014-2016\n",
    "        k=remaining_vehicles_for_year\n",
    "    )\n",
    "    model_years_list_flat.extend(additional_years)\n",
    "random.shuffle(model_years_list_flat)\n",
    "\n",
    "\n",
    "all_records_strings = []\n",
    "vehicle_id_counter = 0\n",
    "\n",
    "# Asignación simplificada de concesionarios por tipo de componente de vehículo\n",
    "# Debería coincidir con cómo se definieron en 02_insert_concessionaires.py\n",
    "concessionaires_by_type_from_script6 = {\n",
    "    \"TRONCAL\": [c[\"id\"] for c in [\n",
    "        {\"id\": 1, \"troncal\": True}, {\"id\": 2, \"troncal\": True}, {\"id\": 3, \"troncal\": True},\n",
    "        {\"id\": 4, \"troncal\": True}, {\"id\": 5, \"troncal\": True}, {\"id\": 6, \"troncal\": True},\n",
    "        {\"id\": 7, \"troncal\": True}, {\"id\": 8, \"troncal\": True}, {\"id\": 9, \"troncal\": True},\n",
    "        {\"id\": 26, \"troncal\": True}\n",
    "    ] if c[\"troncal\"]],\n",
    "    \"ZONAL_UCE\": [c[\"id\"] for c in [\n",
    "        {\"id\": 4, \"zonal_uce\": True}, {\"id\": 8, \"zonal_uce\": True}, {\"id\": 9, \"zonal_uce\": True},\n",
    "        {\"id\": 11, \"zonal_uce\": True}, {\"id\": 12, \"zonal_uce\": True}, {\"id\": 14, \"zonal_uce\": True},\n",
    "        {\"id\": 15, \"zonal_uce\": True}, {\"id\": 16, \"zonal_uce\": True}, {\"id\": 17, \"zonal_uce\": True},\n",
    "        {\"id\": 18, \"zonal_uce\": True}, {\"id\": 19, \"zonal_uce\": True}, {\"id\": 20, \"zonal_uce\": True},\n",
    "        {\"id\": 22, \"zonal_uce\": True}, {\"id\": 23, \"zonal_uce\": True}, {\"id\": 25, \"zonal_uce\": True},\n",
    "        {\"id\": 27, \"zonal_uce\": True}\n",
    "    ] if c[\"zonal_uce\"]],\n",
    "    \"ALIMENTACION\": [c[\"id\"] for c in [\n",
    "        {\"id\": 8, \"zonal_alimentacion\": True}, {\"id\": 9, \"zonal_alimentacion\": True},\n",
    "        {\"id\": 10, \"zonal_alimentacion\": True}, {\"id\": 11, \"zonal_alimentacion\": True},\n",
    "        {\"id\": 12, \"zonal_alimentacion\": True}, {\"id\": 13, \"zonal_alimentacion\": True},\n",
    "        {\"id\": 21, \"zonal_alimentacion\": True}, {\"id\": 25, \"zonal_alimentacion\": True}\n",
    "    ] if c[\"zonal_alimentacion\"]]\n",
    "}\n",
    "# Asegurar que las listas no estén vacías\n",
    "if not concessionaires_by_type_from_script6[\"TRONCAL\"]: concessionaires_by_type_from_script6[\"TRONCAL\"] = [1]\n",
    "if not concessionaires_by_type_from_script6[\"ZONAL_UCE\"]: concessionaires_by_type_from_script6[\"ZONAL_UCE\"] = [14]\n",
    "if not concessionaires_by_type_from_script6[\"ALIMENTACION\"]: concessionaires_by_type_from_script6[\"ALIMENTACION\"] = [10]\n",
    "\n",
    "\n",
    "for spec in vehicle_specs_list:\n",
    "    for _ in range(spec[\"count\"]):\n",
    "        vehicle_id_counter += 1\n",
    "        vehicle_id_val = vehicle_id_counter\n",
    "\n",
    "        license_plate_val = fake_co.unique.license_plate()\n",
    "        vehicle_type_val = spec[\"type\"]\n",
    "        capacity_val = spec[\"capacity\"]\n",
    "        \n",
    "        tech_val = technologies_list_flat.pop() if technologies_list_flat else \"DIESEL_EURO_V\"\n",
    "        model_year_val = model_years_list_flat.pop() if model_years_list_flat else random.randint(2010, 2018)\n",
    "\n",
    "        con_id_val = None\n",
    "        if spec[\"component\"] == \"TRONCAL\" and concessionaires_by_type_from_script6[\"TRONCAL\"]:\n",
    "            con_id_val = random.choice(concessionaires_by_type_from_script6[\"TRONCAL\"])\n",
    "        elif spec[\"component\"] == \"ZONAL\" and concessionaires_by_type_from_script6[\"ZONAL_UCE\"]:\n",
    "            con_id_val = random.choice(concessionaires_by_type_from_script6[\"ZONAL_UCE\"])\n",
    "        elif spec[\"component\"] == \"ALIMENTACION\" and concessionaires_by_type_from_script6[\"ALIMENTACION\"]:\n",
    "            con_id_val = random.choice(concessionaires_by_type_from_script6[\"ALIMENTACION\"])\n",
    "        else: # Fallback\n",
    "            con_id_val = random.randint(1, max_concessionaire_id)\n",
    "            \n",
    "        status_val = \"active\" if random.random() < 0.95 else random.choice([\"maintenance\", \"inactive\"])\n",
    "        current_depot_id_val_str = str(random.randint(1, max_depot_id)) if max_depot_id > 0 else \"NULL\"\n",
    "\n",
    "        all_records_strings.append(\n",
    "            f\"({vehicle_id_val}, '{license_plate_val}', '{vehicle_type_val}', {capacity_val}, '{tech_val}', \"\n",
    "            f\"{model_year_val}, {con_id_val}, '{status_val}', {current_depot_id_val_str})\"\n",
    "        )\n",
    "\n",
    "try:\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(\"INSERT INTO vehicles (vehicle_id, license_plate, vehicle_type, capacity, technology, model_year, concessionaire_id, status, current_depot_id) OVERRIDING SYSTEM VALUE VALUES\\n\")\n",
    "        batch_size = 1000\n",
    "        for i, record_string in enumerate(all_records_strings):\n",
    "            file.write(record_string)\n",
    "            if (i + 1) % batch_size == 0 and i < len(all_records_strings) - 1:\n",
    "                file.write(\";\\n\")\n",
    "                file.write(\"INSERT INTO vehicles (vehicle_id, license_plate, vehicle_type, capacity, technology, model_year, concessionaire_id, status, current_depot_id) OVERRIDING SYSTEM VALUE VALUES\\n\")\n",
    "            elif i < len(all_records_strings) - 1:\n",
    "                file.write(\",\\n\")\n",
    "            else:\n",
    "                file.write(\";\\n\")\n",
    "    print(f\"SQL script for vehicles generated successfully: {os.path.abspath(output_file)}\")\n",
    "except IOError as e:\n",
    "    print(f\"Error writing to file {output_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5ab4cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating driver records...\n",
      "SQL script for drivers generated successfully: /home/kali/Documents/remote reps/distributed-systems-lab/travel-recharge-database/db/data/11_insert_drivers.sql\n"
     ]
    }
   ],
   "source": [
    "# Nombre del archivo: generate_drivers.py\n",
    "import faker\n",
    "import random\n",
    "import os\n",
    "from datetime import timedelta, date\n",
    "\n",
    "fake_co = faker.Faker('es_CO')\n",
    "output_file = \"11_insert_drivers.sql\"\n",
    "\n",
    "max_concessionaire_id = 27 # De 02_insert_concessionaires.sql\n",
    "\n",
    "print(\"Generating driver records...\")\n",
    "\n",
    "driver_counts_by_component = {\n",
    "    \"TRONCAL\": 5003,\n",
    "    \"ZONAL_UCE\": 16544,\n",
    "    \"ALIMENTACION\": 2899\n",
    "}\n",
    "total_drivers_to_generate = sum(driver_counts_by_component.values())\n",
    "\n",
    "# Misma lógica simplificada para asignar concesionarios que en generate_vehicles\n",
    "concessionaires_by_type_from_script6 = {\n",
    "    \"TRONCAL\": [c[\"id\"] for c in [\n",
    "        {\"id\": 1, \"troncal\": True}, {\"id\": 2, \"troncal\": True}, {\"id\": 3, \"troncal\": True},\n",
    "        {\"id\": 4, \"troncal\": True}, {\"id\": 5, \"troncal\": True}, {\"id\": 6, \"troncal\": True},\n",
    "        {\"id\": 7, \"troncal\": True}, {\"id\": 8, \"troncal\": True}, {\"id\": 9, \"troncal\": True},\n",
    "        {\"id\": 26, \"troncal\": True}\n",
    "    ] if c[\"troncal\"]],\n",
    "    \"ZONAL_UCE\": [c[\"id\"] for c in [\n",
    "        {\"id\": 4, \"zonal_uce\": True}, {\"id\": 8, \"zonal_uce\": True}, {\"id\": 9, \"zonal_uce\": True},\n",
    "        {\"id\": 11, \"zonal_uce\": True}, {\"id\": 12, \"zonal_uce\": True}, {\"id\": 14, \"zonal_uce\": True},\n",
    "        {\"id\": 15, \"zonal_uce\": True}, {\"id\": 16, \"zonal_uce\": True}, {\"id\": 17, \"zonal_uce\": True},\n",
    "        {\"id\": 18, \"zonal_uce\": True}, {\"id\": 19, \"zonal_uce\": True}, {\"id\": 20, \"zonal_uce\": True},\n",
    "        {\"id\": 22, \"zonal_uce\": True}, {\"id\": 23, \"zonal_uce\": True}, {\"id\": 25, \"zonal_uce\": True},\n",
    "        {\"id\": 27, \"zonal_uce\": True}\n",
    "    ] if c[\"zonal_uce\"]],\n",
    "    \"ALIMENTACION\": [c[\"id\"] for c in [\n",
    "        {\"id\": 8, \"zonal_alimentacion\": True}, {\"id\": 9, \"zonal_alimentacion\": True},\n",
    "        {\"id\": 10, \"zonal_alimentacion\": True}, {\"id\": 11, \"zonal_alimentacion\": True},\n",
    "        {\"id\": 12, \"zonal_alimentacion\": True}, {\"id\": 13, \"zonal_alimentacion\": True},\n",
    "        {\"id\": 21, \"zonal_alimentacion\": True}, {\"id\": 25, \"zonal_alimentacion\": True}\n",
    "    ] if c[\"zonal_alimentacion\"]]\n",
    "}\n",
    "if not concessionaires_by_type_from_script6[\"TRONCAL\"]: concessionaires_by_type_from_script6[\"TRONCAL\"] = [1]\n",
    "if not concessionaires_by_type_from_script6[\"ZONAL_UCE\"]: concessionaires_by_type_from_script6[\"ZONAL_UCE\"] = [14]\n",
    "if not concessionaires_by_type_from_script6[\"ALIMENTACION\"]: concessionaires_by_type_from_script6[\"ALIMENTACION\"] = [10]\n",
    "\n",
    "\n",
    "driver_component_pool = []\n",
    "for component_type, count in driver_counts_by_component.items():\n",
    "    driver_component_pool.extend([component_type] * count)\n",
    "random.shuffle(driver_component_pool)\n",
    "\n",
    "all_records_strings = []\n",
    "driver_id_counter = 0\n",
    "\n",
    "for i in range(total_drivers_to_generate):\n",
    "    driver_id_counter += 1\n",
    "    driver_id_val = driver_id_counter\n",
    "\n",
    "    # Usar un formato diferente para employee_id para asegurar unicidad más fácil\n",
    "    employee_id_val = f\"E{str(fake_co.unique.random_number(digits=8, fix_len=True))}\"\n",
    "    first_name_val = fake_co.first_name().replace(\"'\", \"''\")\n",
    "    last_name_val = fake_co.last_name().replace(\"'\", \"''\")\n",
    "    \n",
    "    assigned_component = driver_component_pool[i]\n",
    "    con_id_val = None\n",
    "    if assigned_component == \"TRONCAL\" and concessionaires_by_type_from_script6[\"TRONCAL\"]:\n",
    "        con_id_val = random.choice(concessionaires_by_type_from_script6[\"TRONCAL\"])\n",
    "    elif assigned_component == \"ZONAL_UCE\" and concessionaires_by_type_from_script6[\"ZONAL_UCE\"]:\n",
    "        con_id_val = random.choice(concessionaires_by_type_from_script6[\"ZONAL_UCE\"])\n",
    "    elif assigned_component == \"ALIMENTACION\" and concessionaires_by_type_from_script6[\"ALIMENTACION\"]:\n",
    "        con_id_val = random.choice(concessionaires_by_type_from_script6[\"ALIMENTACION\"])\n",
    "    else: # Fallback\n",
    "        con_id_val = random.randint(1, max_concessionaire_id)\n",
    "\n",
    "    hire_date_obj = fake_co.date_between(start_date='-15y', end_date='-30d') # Contratado al menos hace 30 días\n",
    "    hire_date_val = hire_date_obj.strftime('%Y-%m-%d')\n",
    "    \n",
    "    license_number_val = f\"{chr(random.randint(65,90))}{chr(random.randint(65,90))}{str(fake_co.unique.random_number(digits=6, fix_len=True))}\"\n",
    "    \n",
    "    license_expiry_date_obj = fake_co.date_between(start_date='today', end_date='+5y')\n",
    "    license_expiry_date_val = license_expiry_date_obj.strftime('%Y-%m-%d')\n",
    "    \n",
    "    status_val = \"active\" if random.random() < 0.92 else random.choice([\"on_leave\", \"inactive\"])\n",
    "\n",
    "    all_records_strings.append(\n",
    "        f\"({driver_id_val}, '{employee_id_val}', '{first_name_val}', '{last_name_val}', {con_id_val}, \"\n",
    "        f\"'{hire_date_val}', '{license_number_val}', '{license_expiry_date_val}', '{status_val}')\"\n",
    "    )\n",
    "\n",
    "try:\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(\"INSERT INTO drivers (driver_id, employee_id, first_name, last_name, concessionaire_id, hire_date, license_number, license_expiry_date, status) OVERRIDING SYSTEM VALUE VALUES\\n\")\n",
    "        batch_size = 1000\n",
    "        for i, record_string in enumerate(all_records_strings):\n",
    "            file.write(record_string)\n",
    "            if (i + 1) % batch_size == 0 and i < len(all_records_strings) - 1:\n",
    "                file.write(\";\\n\")\n",
    "                file.write(\"INSERT INTO drivers (driver_id, employee_id, first_name, last_name, concessionaire_id, hire_date, license_number, license_expiry_date, status) OVERRIDING SYSTEM VALUE VALUES\\n\")\n",
    "            elif i < len(all_records_strings) - 1:\n",
    "                file.write(\",\\n\")\n",
    "            else:\n",
    "                file.write(\";\\n\")\n",
    "    print(f\"SQL script for drivers generated successfully: {os.path.abspath(output_file)}\")\n",
    "except IOError as e:\n",
    "    print(f\"Error writing to file {output_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52d9b01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating route records...\n",
      "SQL script for routes generated successfully: /home/kali/Documents/remote reps/distributed-systems-lab/travel-recharge-database/db/data/12_insert_routes.sql\n"
     ]
    }
   ],
   "source": [
    "# Nombre del archivo: generate_routes.py\n",
    "import faker\n",
    "import random\n",
    "import os\n",
    "\n",
    "fake_co = faker.Faker('es_CO')\n",
    "output_file = \"12_insert_routes.sql\"\n",
    "\n",
    "# IDs máximos/rangos de scripts anteriores\n",
    "max_concessionaire_id = 27 # De 02_insert_concessionaires.sql\n",
    "# De 09_insert_stations.sql\n",
    "NUM_PORTALS_GEN = 9\n",
    "NUM_CABLE_STATIONS_GEN = 4\n",
    "TOTAL_STATIONS_INC_CABLE_GEN = 142\n",
    "NUM_TRONCAL_STATIONS_OTHER_GEN = TOTAL_STATIONS_INC_CABLE_GEN - NUM_PORTALS_GEN - NUM_CABLE_STATIONS_GEN\n",
    "NUM_ZONAL_PARADEROS_GEN = 7623 # Este es el conteo usado en generate_stations\n",
    "\n",
    "PORTAL_IDS_LIST = list(range(1, NUM_PORTALS_GEN + 1))\n",
    "CABLE_STATION_IDS_LIST = list(range(NUM_PORTALS_GEN + 1, NUM_PORTALS_GEN + NUM_CABLE_STATIONS_GEN + 1))\n",
    "TRONCAL_STATIONS_OTHER_IDS_LIST = list(range(NUM_PORTALS_GEN + NUM_CABLE_STATIONS_GEN + 1, TOTAL_STATIONS_INC_CABLE_GEN + 1))\n",
    "ZONAL_PARADERO_IDS_LIST = list(range(TOTAL_STATIONS_INC_CABLE_GEN + 1, TOTAL_STATIONS_INC_CABLE_GEN + NUM_ZONAL_PARADEROS_GEN + 1))\n",
    "ALL_TRONCAL_TYPE_STATIONS_LIST = PORTAL_IDS_LIST + TRONCAL_STATIONS_OTHER_IDS_LIST\n",
    "\n",
    "\n",
    "# Concessionaire assignment (misma lógica simplificada que en vehicles/drivers)\n",
    "concessionaires_by_type_from_script6 = {\n",
    "    \"TRONCAL\": [c[\"id\"] for c in [{\"id\": 1, \"troncal\": True}, {\"id\": 2, \"troncal\": True}, {\"id\": 3, \"troncal\": True}, {\"id\": 4, \"troncal\": True}, {\"id\": 5, \"troncal\": True}, {\"id\": 6, \"troncal\": True}, {\"id\": 7, \"troncal\": True}, {\"id\": 8, \"troncal\": True}, {\"id\": 9, \"troncal\": True}, {\"id\": 26, \"troncal\": True}] if c[\"troncal\"]],\n",
    "    \"ZONAL_UCE\": [c[\"id\"] for c in [{\"id\": 4, \"zonal_uce\": True}, {\"id\": 8, \"zonal_uce\": True}, {\"id\": 9, \"zonal_uce\": True},{\"id\": 11, \"zonal_uce\": True}, {\"id\": 12, \"zonal_uce\": True}, {\"id\": 14, \"zonal_uce\": True},{\"id\": 15, \"zonal_uce\": True}, {\"id\": 16, \"zonal_uce\": True}, {\"id\": 17, \"zonal_uce\": True},{\"id\": 18, \"zonal_uce\": True}, {\"id\": 19, \"zonal_uce\": True}, {\"id\": 20, \"zonal_uce\": True},{\"id\": 22, \"zonal_uce\": True}, {\"id\": 23, \"zonal_uce\": True}, {\"id\": 25, \"zonal_uce\": True},{\"id\": 27, \"zonal_uce\": True}] if c[\"zonal_uce\"]],\n",
    "    \"ALIMENTACION\": [c[\"id\"] for c in [{\"id\": 8, \"zonal_alimentacion\": True}, {\"id\": 9, \"zonal_alimentacion\": True},{\"id\": 10, \"zonal_alimentacion\": True}, {\"id\": 11, \"zonal_alimentacion\": True},{\"id\": 12, \"zonal_alimentacion\": True}, {\"id\": 13, \"zonal_alimentacion\": True},{\"id\": 21, \"zonal_alimentacion\": True}, {\"id\": 25, \"zonal_alimentacion\": True}] if c[\"zonal_alimentacion\"]],\n",
    "    \"CABLE\": [c[\"id\"] for c in [{\"id\": 24, \"cable\": True}] if c[\"cable\"]]\n",
    "}\n",
    "if not concessionaires_by_type_from_script6[\"TRONCAL\"]: concessionaires_by_type_from_script6[\"TRONCAL\"] = [1]\n",
    "if not concessionaires_by_type_from_script6[\"ZONAL_UCE\"]: concessionaires_by_type_from_script6[\"ZONAL_UCE\"] = [14]\n",
    "if not concessionaires_by_type_from_script6[\"ALIMENTACION\"]: concessionaires_by_type_from_script6[\"ALIMENTACION\"] = [10]\n",
    "if not concessionaires_by_type_from_script6[\"CABLE\"]: concessionaires_by_type_from_script6[\"CABLE\"] = [24]\n",
    "\n",
    "\n",
    "# Route counts from PDF\n",
    "route_counts = {\n",
    "    \"TRONCAL\": 99, \"DUAL\": 5, \"ZONAL_UCE\": 347, \"ALIMENTADORA\": 106, \"CABLE\": 1\n",
    "}\n",
    "dual_route_codes_pdf = [\"DM81\", \"MK86\", \"ML82\", \"MC84\", \"M83\"]\n",
    "zonal_route_codes_pdf_examples = [\"T11\", \"T13\", \"BH907\", \"330\", \"T25\", \"CG147\", \"94\", \"SE14\", \"614\", \"SE6\"]\n",
    "\n",
    "\n",
    "print(\"Generating route records...\")\n",
    "all_records_strings = []\n",
    "route_id_counter = 0\n",
    "generated_route_codes_set = set()\n",
    "\n",
    "def generate_unique_route_code(r_type, counter, predefined_list=None):\n",
    "    global generated_route_codes_set\n",
    "    attempts = 0\n",
    "    max_attempts = 100\n",
    "    \n",
    "    if predefined_list and counter < len(predefined_list):\n",
    "        code = predefined_list[counter]\n",
    "        if code not in generated_route_codes_set:\n",
    "            generated_route_codes_set.add(code)\n",
    "            return code\n",
    "        # If predefined code already used (should not happen if list is unique), fall through to generate\n",
    "        \n",
    "    while attempts < max_attempts:\n",
    "        if r_type == \"TRONCAL\":\n",
    "            p = random.choice([\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"J\",\"K\",\"L\",\"M\"])\n",
    "            n = random.randint(1,99)\n",
    "            code = f\"{p}{n}\"\n",
    "        elif r_type == \"DUAL\": # Will be stored as TRONCAL type in DB as per current schema\n",
    "            p = random.choice([\"DM\",\"MD\",\"ML\",\"CM\",\"MF\"])\n",
    "            n = random.randint(80,99)\n",
    "            code = f\"{p}{n}\"\n",
    "        elif r_type == \"ZONAL_UCE\":\n",
    "            if random.random() < 0.5: code = str(random.randint(10, 999))\n",
    "            else: code = f\"{random.choice(['A','B','C','E','H','K','P','S','T','Z'])}{random.randint(10,999)}\"\n",
    "            if random.random() < 0.2: code = f\"SITP{code}\"\n",
    "        elif r_type == \"ALIMENTADORA\":\n",
    "            code = f\"{random.randint(1,16)}-{random.randint(1,12)}\"\n",
    "        elif r_type == \"CABLE\":\n",
    "            code = f\"TC{counter+1}\"\n",
    "        else:\n",
    "            code = f\"R{str(counter).zfill(4)}\"\n",
    "\n",
    "        if code not in generated_route_codes_set:\n",
    "            generated_route_codes_set.add(code)\n",
    "            return code\n",
    "        counter +=1 # Try different counter for generation\n",
    "        attempts +=1\n",
    "    return f\"ERR_CODE_{r_type}_{random.randint(1000,9999)}\"\n",
    "\n",
    "\n",
    "route_definitions_list = [\n",
    "    {\"type_pdf\": \"TRONCAL\", \"type_db\": \"TRONCAL\", \"count\": route_counts[\"TRONCAL\"], \"con_ids\": concessionaires_by_type_from_script6[\"TRONCAL\"], \"orig_pool\": ALL_TRONCAL_TYPE_STATIONS_LIST, \"dest_pool\": ALL_TRONCAL_TYPE_STATIONS_LIST, \"predefined_codes\": None},\n",
    "    {\"type_pdf\": \"DUAL\", \"type_db\": \"TRONCAL\", \"count\": route_counts[\"DUAL\"], \"con_ids\": concessionaires_by_type_from_script6[\"TRONCAL\"], \"orig_pool\": PORTAL_IDS_LIST, \"dest_pool\": PORTAL_IDS_LIST + TRONCAL_STATIONS_OTHER_IDS_LIST, \"predefined_codes\": dual_route_codes_pdf}, # Dual routes map to TRONCAL type in DB\n",
    "    {\"type_pdf\": \"ZONAL_UCE\", \"type_db\": \"ZONAL_UCE\", \"count\": route_counts[\"ZONAL_UCE\"], \"con_ids\": concessionaires_by_type_from_script6[\"ZONAL_UCE\"], \"orig_pool\": ZONAL_PARADERO_IDS_LIST + TRONCAL_STATIONS_OTHER_IDS_LIST, \"dest_pool\": ZONAL_PARADERO_IDS_LIST + TRONCAL_STATIONS_OTHER_IDS_LIST, \"predefined_codes\": zonal_route_codes_pdf_examples},\n",
    "    {\"type_pdf\": \"ALIMENTADORA\", \"type_db\": \"ALIMENTADORA\", \"count\": route_counts[\"ALIMENTADORA\"], \"con_ids\": concessionaires_by_type_from_script6[\"ALIMENTACION\"], \"orig_pool\": PORTAL_IDS_LIST + TRONCAL_STATIONS_OTHER_IDS_LIST, \"dest_pool\": ZONAL_PARADERO_IDS_LIST, \"predefined_codes\": None},\n",
    "    {\"type_pdf\": \"CABLE\", \"type_db\": \"CABLE\", \"count\": route_counts[\"CABLE\"], \"con_ids\": concessionaires_by_type_from_script6[\"CABLE\"], \"orig_pool\": [CABLE_STATION_IDS_LIST[0]], \"dest_pool\": [CABLE_STATION_IDS_LIST[-1]], \"predefined_codes\": None}\n",
    "]\n",
    "\n",
    "route_type_counter = {} # To use with predefined codes\n",
    "\n",
    "for definition in route_definitions_list:\n",
    "    pdf_type = definition[\"type_pdf\"]\n",
    "    db_type = definition[\"type_db\"]\n",
    "    if pdf_type not in route_type_counter:\n",
    "        route_type_counter[pdf_type] = 0\n",
    "\n",
    "    for _ in range(definition[\"count\"]):\n",
    "        route_id_counter += 1\n",
    "        route_id_val = route_id_counter\n",
    "        \n",
    "        code_val = generate_unique_route_code(pdf_type, route_type_counter[pdf_type], definition[\"predefined_codes\"])\n",
    "        route_type_counter[pdf_type] += 1\n",
    "        \n",
    "        origin_id_val, dest_id_val = None, None\n",
    "        if len(definition[\"orig_pool\"]) > 0 and len(definition[\"dest_pool\"]) > 0 :\n",
    "            origin_id_val = random.choice(definition[\"orig_pool\"])\n",
    "            # Ensure destination is different from origin\n",
    "            temp_dest_pool = [sid for sid in definition[\"dest_pool\"] if sid != origin_id_val]\n",
    "            if not temp_dest_pool: temp_dest_pool = definition[\"dest_pool\"] # Fallback if all are same as origin\n",
    "            dest_id_val = random.choice(temp_dest_pool) if temp_dest_pool else origin_id_val # Further fallback\n",
    "        else: # Should not happen with current data\n",
    "            origin_id_val = random.randint(1,10)\n",
    "            dest_id_val = random.randint(1,10)\n",
    "\n",
    "\n",
    "        # Simplified name, can be improved with actual station names if performance allows\n",
    "        route_name_val = f\"{code_val}: Origen Est.{origin_id_val} - Destino Est.{dest_id_val}\".replace(\"'\", \"''\")\n",
    "        concessionaire_id_val = random.choice(definition[\"con_ids\"]) if definition[\"con_ids\"] else random.randint(1,max_concessionaire_id)\n",
    "        is_active_val = True if random.random() < 0.9 else False\n",
    "\n",
    "        all_records_strings.append(\n",
    "            f\"({route_id_val}, '{code_val}', '{route_name_val}', '{db_type}', \"\n",
    "            f\"{origin_id_val}, {dest_id_val}, {concessionaire_id_val}, {is_active_val})\"\n",
    "        )\n",
    "\n",
    "try:\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(\"INSERT INTO routes (route_id, route_code, route_name, route_type, origin_station_id, destination_station_id, concessionaire_id, is_active) OVERRIDING SYSTEM VALUE VALUES\\n\")\n",
    "        batch_size = 1000\n",
    "        for i, record_string in enumerate(all_records_strings):\n",
    "            file.write(record_string)\n",
    "            if (i + 1) % batch_size == 0 and i < len(all_records_strings) - 1:\n",
    "                file.write(\";\\n\")\n",
    "                file.write(\"INSERT INTO routes (route_id, route_code, route_name, route_type, origin_station_id, destination_station_id, concessionaire_id, is_active) OVERRIDING SYSTEM VALUE VALUES\\n\")\n",
    "            elif i < len(all_records_strings) - 1:\n",
    "                file.write(\",\\n\")\n",
    "            else:\n",
    "                file.write(\";\\n\")\n",
    "    print(f\"SQL script for routes generated successfully: {os.path.abspath(output_file)}\")\n",
    "except IOError as e:\n",
    "    print(f\"Error writing to file {output_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6d618c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating intermediate station records for 558 routes...\n",
      "SQL script for intermediate_stations generated successfully: /home/kali/Documents/remote reps/distributed-systems-lab/travel-recharge-database/db/data/13_insert_intermediate_stations.sql\n"
     ]
    }
   ],
   "source": [
    "# Nombre del archivo: generate_intermediate_stations.py\n",
    "import random\n",
    "import os\n",
    "\n",
    "output_file = \"13_insert_intermediate_stations.sql\"\n",
    "\n",
    "# IDs máximos/rangos de scripts anteriores\n",
    "# From 12_insert_routes.sql\n",
    "NUM_TRONCAL_ROUTES_GEN = 99\n",
    "NUM_DUAL_ROUTES_GEN = 5\n",
    "NUM_ZONAL_UCE_ROUTES_GEN = 347\n",
    "NUM_ALIMENTADORA_ROUTES_GEN = 106\n",
    "NUM_CABLE_ROUTES_GEN = 1\n",
    "total_routes_generated = NUM_TRONCAL_ROUTES_GEN + NUM_DUAL_ROUTES_GEN + NUM_ZONAL_UCE_ROUTES_GEN + NUM_ALIMENTADORA_ROUTES_GEN + NUM_CABLE_ROUTES_GEN\n",
    "\n",
    "# From 09_insert_stations.sql\n",
    "NUM_PORTALS_GEN = 9\n",
    "NUM_CABLE_STATIONS_GEN = 4\n",
    "TOTAL_STATIONS_INC_CABLE_GEN = 142\n",
    "NUM_TRONCAL_STATIONS_OTHER_GEN = TOTAL_STATIONS_INC_CABLE_GEN - NUM_PORTALS_GEN - NUM_CABLE_STATIONS_GEN\n",
    "NUM_ZONAL_PARADEROS_GEN = 7623\n",
    "\n",
    "PORTAL_IDS_LIST = list(range(1, NUM_PORTALS_GEN + 1))\n",
    "CABLE_STATION_IDS_LIST = list(range(NUM_PORTALS_GEN + 1, NUM_PORTALS_GEN + NUM_CABLE_STATIONS_GEN + 1)) # 10, 11, 12, 13\n",
    "TRONCAL_STATIONS_OTHER_IDS_LIST = list(range(NUM_PORTALS_GEN + NUM_CABLE_STATIONS_GEN + 1, TOTAL_STATIONS_INC_CABLE_GEN + 1))\n",
    "ZONAL_PARADERO_IDS_LIST = list(range(TOTAL_STATIONS_INC_CABLE_GEN + 1, TOTAL_STATIONS_INC_CABLE_GEN + NUM_ZONAL_PARADEROS_GEN + 1))\n",
    "ALL_TRONCAL_TYPE_STATIONS_LIST = PORTAL_IDS_LIST + TRONCAL_STATIONS_OTHER_IDS_LIST\n",
    "\n",
    "# Route ID ranges and types (consistent with generate_routes.py)\n",
    "route_id_start = 1\n",
    "route_info_map = {} # Store type, origin, dest for each route_id\n",
    "\n",
    "# Troncal Routes\n",
    "for r_id in range(route_id_start, route_id_start + NUM_TRONCAL_ROUTES_GEN):\n",
    "    route_info_map[r_id] = {\"type\": \"TRONCAL\", \"stop_pool\": ALL_TRONCAL_TYPE_STATIONS_LIST, \"min_stops\": 3, \"max_stops\": 15}\n",
    "route_id_start += NUM_TRONCAL_ROUTES_GEN\n",
    "\n",
    "# Dual Routes\n",
    "for r_id in range(route_id_start, route_id_start + NUM_DUAL_ROUTES_GEN):\n",
    "    route_info_map[r_id] = {\"type\": \"DUAL\", \"stop_pool\": ALL_TRONCAL_TYPE_STATIONS_LIST + random.sample(ZONAL_PARADERO_IDS_LIST, k=min(len(ZONAL_PARADERO_IDS_LIST), 200)), \"min_stops\": 8, \"max_stops\": 25} # Can use zonal\n",
    "route_id_start += NUM_DUAL_ROUTES_GEN\n",
    "\n",
    "# Zonal UCE Routes\n",
    "for r_id in range(route_id_start, route_id_start + NUM_ZONAL_UCE_ROUTES_GEN):\n",
    "    route_info_map[r_id] = {\"type\": \"ZONAL_UCE\", \"stop_pool\": ZONAL_PARADERO_IDS_LIST + random.sample(TRONCAL_STATIONS_OTHER_IDS_LIST, k=min(len(TRONCAL_STATIONS_OTHER_IDS_LIST),50)), \"min_stops\": 10, \"max_stops\": 40}\n",
    "route_id_start += NUM_ZONAL_UCE_ROUTES_GEN\n",
    "\n",
    "# Alimentadora Routes\n",
    "for r_id in range(route_id_start, route_id_start + NUM_ALIMENTADORA_ROUTES_GEN):\n",
    "    route_info_map[r_id] = {\"type\": \"ALIMENTADORA\", \"stop_pool\": ZONAL_PARADERO_IDS_LIST, \"min_stops\": 5, \"max_stops\": 20}\n",
    "route_id_start += NUM_ALIMENTADORA_ROUTES_GEN\n",
    "\n",
    "# Cable Routes\n",
    "for r_id in range(route_id_start, route_id_start + NUM_CABLE_ROUTES_GEN):\n",
    "    # Cable route has specific intermediate stations: CABLE_STATION_IDS_LIST are [Origin, Inter1, Inter2, Dest] for 4 stations\n",
    "    # So intermediate are CABLE_STATION_IDS_LIST[1] and CABLE_STATION_IDS_LIST[2] if origin/dest are [0] and [-1]\n",
    "    fixed_stops = CABLE_STATION_IDS_LIST[1:-1] if len(CABLE_STATION_IDS_LIST) > 2 else []\n",
    "    route_info_map[r_id] = {\"type\": \"CABLE\", \"stop_pool\": fixed_stops, \"min_stops\": len(fixed_stops), \"max_stops\": len(fixed_stops), \"is_fixed\": True}\n",
    "\n",
    "\n",
    "print(f\"Generating intermediate station records for {total_routes_generated} routes...\")\n",
    "all_records_strings = []\n",
    "intermediate_station_id_counter = 0\n",
    "\n",
    "for route_id_val in range(1, total_routes_generated + 1):\n",
    "    route_data = route_info_map.get(route_id_val)\n",
    "    if not route_data:\n",
    "        print(f\"Warning: No route data found for route_id {route_id_val}\")\n",
    "        continue\n",
    "\n",
    "    num_stops = random.randint(route_data[\"min_stops\"], route_data[\"max_stops\"])\n",
    "    \n",
    "    potential_stops_pool = route_data[\"stop_pool\"]\n",
    "    if not potential_stops_pool: # Skip if no pool (e.g. Cable route with only 2 stations)\n",
    "        if route_data.get(\"is_fixed\") and not potential_stops_pool : # Expected if fixed stops is empty\n",
    "            pass\n",
    "        else:\n",
    "            print(f\"Warning: Empty stop_pool for route_id {route_id_val} of type {route_data['type']}\")\n",
    "        continue\n",
    "        \n",
    "    selected_stops_for_route = []\n",
    "    if route_data.get(\"is_fixed\"):\n",
    "        selected_stops_for_route = potential_stops_pool # Use the pre-defined fixed stops\n",
    "    elif len(potential_stops_pool) > 0:\n",
    "        num_to_sample = min(num_stops, len(potential_stops_pool))\n",
    "        selected_stops_for_route = random.sample(potential_stops_pool, k=num_to_sample)\n",
    "    \n",
    "    # Ensure origin and destination are not in the intermediate stops (conceptually)\n",
    "    # The route definition in `routes` table has origin and destination.\n",
    "    # Here we are only defining the sequence of stations *between* them.\n",
    "\n",
    "    for seq_order, station_id_val in enumerate(selected_stops_for_route):\n",
    "        intermediate_station_id_counter += 1\n",
    "        intermediate_station_id_val = intermediate_station_id_counter # Python controla el ID\n",
    "        \n",
    "        all_records_strings.append(\n",
    "            f\"({intermediate_station_id_val}, {route_id_val}, {station_id_val}, {seq_order + 1})\"\n",
    "        )\n",
    "\n",
    "try:\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(\"INSERT INTO intermediate_stations (intermediate_station_id, route_id, station_id, sequence_order) OVERRIDING SYSTEM VALUE VALUES\\n\")\n",
    "        batch_size = 1000\n",
    "        for i, record_string in enumerate(all_records_strings):\n",
    "            file.write(record_string)\n",
    "            if (i + 1) % batch_size == 0 and i < len(all_records_strings) - 1:\n",
    "                file.write(\";\\n\")\n",
    "                file.write(\"INSERT INTO intermediate_stations (intermediate_station_id, route_id, station_id, sequence_order) OVERRIDING SYSTEM VALUE VALUES\\n\")\n",
    "            elif i < len(all_records_strings) - 1:\n",
    "                file.write(\",\\n\")\n",
    "            else:\n",
    "                file.write(\";\\n\")\n",
    "    print(f\"SQL script for intermediate_stations generated successfully: {os.path.abspath(output_file)}\")\n",
    "except IOError as e:\n",
    "    print(f\"Error writing to file {output_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ef34b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating trips from 2024-06-03 to 2024-06-09...\n",
      "Generating ~33639 trip legs for 2024-06-03...\n",
      "Completed day 2024-06-03. Approx 33639 journeys initiated. Total trips (legs) so far: 40838\n",
      "Generating ~33639 trip legs for 2024-06-04...\n",
      "Completed day 2024-06-04. Approx 33639 journeys initiated. Total trips (legs) so far: 81518\n",
      "Generating ~33639 trip legs for 2024-06-05...\n",
      "Completed day 2024-06-05. Approx 33639 journeys initiated. Total trips (legs) so far: 122267\n",
      "Generating ~33639 trip legs for 2024-06-06...\n",
      "Completed day 2024-06-06. Approx 33639 journeys initiated. Total trips (legs) so far: 163142\n",
      "Generating ~33639 trip legs for 2024-06-07...\n",
      "Completed day 2024-06-07. Approx 33639 journeys initiated. Total trips (legs) so far: 203872\n",
      "Generating ~25941 trip legs for 2024-06-08...\n",
      "Completed day 2024-06-08. Approx 25941 journeys initiated. Total trips (legs) so far: 235322\n",
      "Generating ~15915 trip legs for 2024-06-09...\n",
      "Completed day 2024-06-09. Approx 15915 journeys initiated. Total trips (legs) so far: 254508\n",
      "SQL script for trips generated successfully: /home/kali/Documents/remote reps/distributed-systems-lab/travel-recharge-database/db/data/14_insert_trips.sql\n",
      "Total trip leg records generated: 254508\n"
     ]
    }
   ],
   "source": [
    "# Nombre del archivo: generate_trips.py\n",
    "import faker\n",
    "import random\n",
    "import os\n",
    "from datetime import datetime, timedelta, date, time\n",
    "import uuid\n",
    "\n",
    "fake_co = faker.Faker('es_CO')\n",
    "output_file = \"14_insert_trips.sql\"\n",
    "\n",
    "# --- Configuration ---\n",
    "SIMULATION_START_DATE = date(2024, 6, 3) # Lunes\n",
    "SIMULATION_END_DATE = date(2024, 6, 9)   # Domingo\n",
    "SIMULATION_DAYS = (SIMULATION_END_DATE - SIMULATION_START_DATE).days + 1\n",
    "\n",
    "# --- ID Ranges & Counts (from previous scripts - CRUCIAL for consistency) ---\n",
    "# Cards (Script 05)\n",
    "MAX_CARD_ID = 2400000 // 100\n",
    "ASSUMED_ACTIVE_CARD_THRESHOLD_ID = 2000000 // 100\n",
    "\n",
    "# Stations (Script 09)\n",
    "MAX_STATION_ID_FROM_SCRIPT_09 = 7765 # Ajusta si el contador final en script 09 fue diferente\n",
    "PORTAL_IDS_RANGE_TRIPS = (1, 9)\n",
    "CABLE_STATION_IDS_RANGE_TRIPS = (10, 13)\n",
    "TRONCAL_STATION_IDS_OTHER_RANGE_TRIPS = (14, 142)\n",
    "ZONAL_PARADERO_IDS_RANGE_TRIPS = (143, MAX_STATION_ID_FROM_SCRIPT_09)\n",
    "ALL_TRONCAL_STATIONS_IDS_TRIPS = list(range(PORTAL_IDS_RANGE_TRIPS[0], PORTAL_IDS_RANGE_TRIPS[1] + 1)) + \\\n",
    "                                 list(range(TRONCAL_STATION_IDS_OTHER_RANGE_TRIPS[0], TRONCAL_STATION_IDS_OTHER_RANGE_TRIPS[1] + 1))\n",
    "ALL_CABLE_STATIONS_IDS_TRIPS = list(range(CABLE_STATION_IDS_RANGE_TRIPS[0], CABLE_STATION_IDS_RANGE_TRIPS[1] + 1))\n",
    "ALL_ZONAL_PARADERO_IDS_TRIPS = list(range(ZONAL_PARADERO_IDS_RANGE_TRIPS[0], ZONAL_PARADERO_IDS_RANGE_TRIPS[1] + 1))\n",
    "ALL_STATION_IDS_TRIPS = list(range(1, MAX_STATION_ID_FROM_SCRIPT_09 + 1))\n",
    "\n",
    "\n",
    "# Routes (Script 12) & Intermediate Stations (Script 13)\n",
    "# Route counts from script 12\n",
    "NUM_TRONCAL_ROUTES_GEN_TRIPS = 99\n",
    "NUM_DUAL_ROUTES_GEN_TRIPS = 5\n",
    "NUM_ZONAL_UCE_ROUTES_GEN_TRIPS = 347\n",
    "NUM_ALIMENTADORA_ROUTES_GEN_TRIPS = 106\n",
    "NUM_CABLE_ROUTES_GEN_TRIPS = 1\n",
    "MAX_ROUTE_ID_TRIPS = NUM_TRONCAL_ROUTES_GEN_TRIPS + NUM_DUAL_ROUTES_GEN_TRIPS + NUM_ZONAL_UCE_ROUTES_GEN_TRIPS + NUM_ALIMENTADORA_ROUTES_GEN_TRIPS + NUM_CABLE_ROUTES_GEN_TRIPS\n",
    "\n",
    "# Route ID ranges (conceptual, based on order of generation in script 12)\n",
    "current_route_id_start_trips = 1\n",
    "TRONCAL_ROUTE_IDS_RANGE_TRIPS = (current_route_id_start_trips, current_route_id_start_trips + NUM_TRONCAL_ROUTES_GEN_TRIPS -1)\n",
    "current_route_id_start_trips += NUM_TRONCAL_ROUTES_GEN_TRIPS\n",
    "DUAL_ROUTE_IDS_RANGE_TRIPS = (current_route_id_start_trips, current_route_id_start_trips + NUM_DUAL_ROUTES_GEN_TRIPS -1)\n",
    "current_route_id_start_trips += NUM_DUAL_ROUTES_GEN_TRIPS\n",
    "ZONAL_UCE_ROUTE_IDS_RANGE_TRIPS = (current_route_id_start_trips, current_route_id_start_trips + NUM_ZONAL_UCE_ROUTES_GEN_TRIPS -1)\n",
    "current_route_id_start_trips += NUM_ZONAL_UCE_ROUTES_GEN_TRIPS\n",
    "ALIMENTADORA_ROUTE_IDS_RANGE_TRIPS = (current_route_id_start_trips, current_route_id_start_trips + NUM_ALIMENTADORA_ROUTES_GEN_TRIPS -1)\n",
    "current_route_id_start_trips += NUM_ALIMENTADORA_ROUTES_GEN_TRIPS\n",
    "CABLE_ROUTE_IDS_RANGE_TRIPS = (current_route_id_start_trips, current_route_id_start_trips + NUM_CABLE_ROUTES_GEN_TRIPS -1)\n",
    "\n",
    "# Vehicles (Script 10)\n",
    "MAX_VEHICLE_ID_TRIPS = 10563\n",
    "# Drivers (Script 11)\n",
    "MAX_DRIVER_ID_TRIPS = 24446\n",
    "# Fares (Script 07)\n",
    "FARE_ID_STANDARD_SITP_TRIPS = 1\n",
    "FARE_ID_TRANSFER_0_TRIPS = 2\n",
    "FARE_ID_TRANSFER_200_TRIPS = 3\n",
    "FARE_ID_STANDARD_CABLE_TRIPS = 4\n",
    "\n",
    "# --- Daily Trip Volume (Scaled by 1/100) ---\n",
    "TRIPS_PER_WEEKDAY_SCALED = random.randint(3200000, 3800000) // 100\n",
    "TRIPS_PER_SATURDAY_SCALED = random.randint(2200000, 2800000) // 100\n",
    "TRIPS_PER_SUNDAY_OR_HOLIDAY_SCALED = random.randint(1300000, 1800000) // 100\n",
    "\n",
    "PROB_TRANSFER_TRIPS = 0.18\n",
    "TRANSFER_TYPE_DIST_TRIPS = {\"ZONAL_TO_ZONAL\": 0.49, \"ZONAL_TO_TRONCAL_CABLE\": 0.29, \"TRONCAL_CABLE_TO_ZONAL\": 0.22}\n",
    "TRANSFER_WINDOW_MINUTES_TRIPS = 110\n",
    "\n",
    "# --- Popularity Biasing (Simplified) ---\n",
    "POPULAR_ZONAL_ROUTE_IDS_TRIPS = list(range(ZONAL_UCE_ROUTE_IDS_RANGE_TRIPS[0], min(ZONAL_UCE_ROUTE_IDS_RANGE_TRIPS[1]+1, ZONAL_UCE_ROUTE_IDS_RANGE_TRIPS[0] + 20))) # First 20 Zonal\n",
    "POPULAR_TRONCAL_ROUTE_IDS_TRIPS = list(range(TRONCAL_ROUTE_IDS_RANGE_TRIPS[0], min(TRONCAL_ROUTE_IDS_RANGE_TRIPS[1]+1, TRONCAL_ROUTE_IDS_RANGE_TRIPS[0] + 20))) # First 20 Troncal\n",
    "POPULAR_PORTAL_IDS_TRIPS = list(range(PORTAL_IDS_RANGE_TRIPS[0], PORTAL_IDS_RANGE_TRIPS[1] + 1))\n",
    "POPULAR_TRONCAL_STATION_IDS_TRIPS = list(range(TRONCAL_STATION_IDS_OTHER_RANGE_TRIPS[0], min(TRONCAL_STATION_IDS_OTHER_RANGE_TRIPS[1]+1, TRONCAL_STATION_IDS_OTHER_RANGE_TRIPS[0] + 30)))\n",
    "\n",
    "\n",
    "# --- Mocked Route Structures (VERY SIMPLIFIED - for standalone generation) ---\n",
    "# This is a placeholder. In a real scenario with DB access, you'd query intermediate_stations.\n",
    "# Here, we simulate that a route has a list of plausible stops.\n",
    "# We need to pre-load/define this structure based on how 13_insert_intermediate_stations.sql was generated.\n",
    "# For this script, we'll generate a *conceptual* path on the fly.\n",
    "# This is a MAJOR simplification point.\n",
    "route_conceptual_paths = {} # {route_id: [station1, station2, ...]}\n",
    "\n",
    "def get_conceptual_path_for_route(route_id, route_type_actual):\n",
    "    if route_id in route_conceptual_paths:\n",
    "        return route_conceptual_paths[route_id]\n",
    "\n",
    "    path = []\n",
    "    num_stops_on_path = 0\n",
    "    station_pool = []\n",
    "\n",
    "    if route_type_actual == \"TRONCAL\" or route_type_actual == \"DUAL\":\n",
    "        station_pool = ALL_TRONCAL_STATIONS_IDS_TRIPS\n",
    "        num_stops_on_path = random.randint(5, 20)\n",
    "    elif route_type_actual == \"ZONAL_UCE\":\n",
    "        station_pool = ALL_ZONAL_PARADERO_IDS_TRIPS + random.sample(ALL_TRONCAL_STATIONS_IDS_TRIPS, k=min(len(ALL_TRONCAL_STATIONS_IDS_TRIPS), 5))\n",
    "        num_stops_on_path = random.randint(10, 40)\n",
    "    elif route_type_actual == \"ALIMENTADORA\":\n",
    "        # Origin from Troncal, rest zonal\n",
    "        path.append(random.choice(ALL_TRONCAL_STATIONS_IDS_TRIPS))\n",
    "        station_pool = ALL_ZONAL_PARADERO_IDS_TRIPS\n",
    "        num_stops_on_path = random.randint(5, 20) -1 # -1 because origin is already added\n",
    "    elif route_type_actual == \"CABLE\":\n",
    "        route_conceptual_paths[route_id] = ALL_CABLE_STATIONS_IDS_TRIPS # Assumes they are in order\n",
    "        return ALL_CABLE_STATIONS_IDS_TRIPS\n",
    "    \n",
    "    if not station_pool: # Fallback\n",
    "        route_conceptual_paths[route_id] = []\n",
    "        return []\n",
    "\n",
    "    # Add origin if not alimentadora/cable\n",
    "    if route_type_actual != \"ALIMENTADORA\" and len(station_pool) > 0 :\n",
    "        path.append(random.choice(station_pool))\n",
    "\n",
    "    # Add intermediate and destination\n",
    "    available_for_path = [s for s in station_pool if s not in path]\n",
    "    num_to_sample = min(num_stops_on_path, len(available_for_path))\n",
    "    if num_to_sample > 0:\n",
    "        path.extend(random.sample(available_for_path, k=num_to_sample))\n",
    "    \n",
    "    if not path and station_pool : # If path is still empty, add at least one station\n",
    "        path.append(random.choice(station_pool))\n",
    "\n",
    "    route_conceptual_paths[route_id] = path\n",
    "    return path\n",
    "\n",
    "\n",
    "def get_route_type_from_id_trips(route_id): # Renamed to avoid conflict if running in same context\n",
    "    if TRONCAL_ROUTE_IDS_RANGE_TRIPS[0] <= route_id <= TRONCAL_ROUTE_IDS_RANGE_TRIPS[1]: return \"TRONCAL\"\n",
    "    if DUAL_ROUTE_IDS_RANGE_TRIPS[0] <= route_id <= DUAL_ROUTE_IDS_RANGE_TRIPS[1]: return \"DUAL\"\n",
    "    if ZONAL_UCE_ROUTE_IDS_RANGE_TRIPS[0] <= route_id <= ZONAL_UCE_ROUTE_IDS_RANGE_TRIPS[1]: return \"ZONAL_UCE\"\n",
    "    if ALIMENTADORA_ROUTE_IDS_RANGE_TRIPS[0] <= route_id <= ALIMENTADORA_ROUTE_IDS_RANGE_TRIPS[1]: return \"ALIMENTADORA\"\n",
    "    if CABLE_ROUTE_IDS_RANGE_TRIPS[0] <= route_id <= CABLE_ROUTE_IDS_RANGE_TRIPS[1]: return \"CABLE\"\n",
    "    return \"UNKNOWN\" # Should not happen\n",
    "\n",
    "def get_boarding_time_trips(current_date, day_type_idx):\n",
    "    time_slots_weights = [\n",
    "        # (h_start, m_start, h_end, m_end, [prob_weekday, prob_saturday, prob_sunday])\n",
    "        (0, 0, 3, 59,  [0.02, 0.03, 0.02]),   # Night Owl\n",
    "        (4, 0, 5, 29,  [0.10, 0.08, 0.05]),   # Early Morning\n",
    "        (5, 30, 8, 59, [0.30, 0.20, 0.10]),  # Morning Peak\n",
    "        (9, 0, 16, 29, [0.28, 0.35, 0.43]), # Mid-Day / Off-Peak\n",
    "        (16, 30, 19, 59,[0.25, 0.25, 0.30]),# Afternoon Peak\n",
    "        (20, 0, 23, 59,[0.05, 0.09, 0.10]), # Evening\n",
    "    ]\n",
    "    slots, weights = zip(*[(s[:4], s[4][day_type_idx]) for s in time_slots_weights])\n",
    "    chosen_slot = random.choices(slots, weights=weights, k=1)[0]\n",
    "    \n",
    "    hour = random.randint(chosen_slot[0], chosen_slot[2])\n",
    "    minute = random.randint(0, 59)\n",
    "    if hour == chosen_slot[2]: minute = random.randint(0, chosen_slot[3])\n",
    "    if hour == chosen_slot[0] and chosen_slot[1] > 0 : minute = random.randint(chosen_slot[1], 59)\n",
    "    \n",
    "    return datetime.combine(current_date, time(hour, minute, random.randint(0,59)))\n",
    "\n",
    "def get_travel_time_seconds_trips(num_stops, route_type):\n",
    "    time_per_stop = 120\n",
    "    if route_type == \"TRONCAL\" or route_type == \"DUAL\": time_per_stop = random.randint(100, 200)\n",
    "    elif route_type == \"ZONAL_UCE\" or route_type == \"ALIMENTADORA\": time_per_stop = random.randint(70, 160)\n",
    "    elif route_type == \"CABLE\": time_per_stop = random.randint(180, 300)\n",
    "    return num_stops * time_per_stop + random.randint(-30, 90)\n",
    "\n",
    "\n",
    "# --- Main Generation Loop ---\n",
    "trip_id_counter = 0\n",
    "all_trip_records_strings = []\n",
    "total_trips_generated_for_log = 0\n",
    "\n",
    "print(f\"Generating trips from {SIMULATION_START_DATE} to {SIMULATION_END_DATE}...\")\n",
    "\n",
    "for day_offset in range(SIMULATION_DAYS):\n",
    "    current_processing_date = SIMULATION_START_DATE + timedelta(days=day_offset)\n",
    "    weekday_idx = current_processing_date.weekday() # Monday=0, Sunday=6\n",
    "    \n",
    "    daily_trip_target = 0\n",
    "    day_type_for_time = 0 # 0:Weekday, 1:Sat, 2:Sun\n",
    "    if weekday_idx < 5: daily_trip_target, day_type_for_time = TRIPS_PER_WEEKDAY_SCALED, 0\n",
    "    elif weekday_idx == 5: daily_trip_target, day_type_for_time = TRIPS_PER_SATURDAY_SCALED, 1\n",
    "    else: daily_trip_target, day_type_for_time = TRIPS_PER_SUNDAY_OR_HOLIDAY_SCALED, 2\n",
    "    \n",
    "    print(f\"Generating ~{daily_trip_target} trip legs for {current_processing_date.strftime('%Y-%m-%d')}...\")\n",
    "    \n",
    "    journeys_initiated_today = 0 # Count distinct journeys, not legs\n",
    "    \n",
    "    # Loop until enough journey-initiating trips are made for the day's target\n",
    "    while journeys_initiated_today < daily_trip_target:\n",
    "        is_first_leg = True\n",
    "        current_transfer_group_id_val = str(uuid.uuid4())\n",
    "        prev_disembark_time = None\n",
    "        prev_route_type_actual = None\n",
    "        legs_this_journey = 0\n",
    "\n",
    "        while legs_this_journey < 3: # Max 2 transfers (3 legs)\n",
    "            legs_this_journey += 1\n",
    "            trip_id_counter += 1\n",
    "            trip_id_val = trip_id_counter\n",
    "\n",
    "            card_id_val = random.randint(1, ASSUMED_ACTIVE_CARD_THRESHOLD_ID) if random.random() < 0.8 else random.randint(1, MAX_CARD_ID)\n",
    "            \n",
    "            route_id_val = None\n",
    "            current_route_type_actual = None\n",
    "            fare_id_val = FARE_ID_STANDARD_SITP_TRIPS\n",
    "\n",
    "            if is_first_leg:\n",
    "                # Bias route selection for first leg\n",
    "                rand_route_choice = random.random()\n",
    "                if rand_route_choice < 0.1 and POPULAR_TRONCAL_ROUTE_IDS_TRIPS : route_id_val = random.choice(POPULAR_TRONCAL_ROUTE_IDS_TRIPS)\n",
    "                elif rand_route_choice < 0.2 and POPULAR_ZONAL_ROUTE_IDS_TRIPS : route_id_val = random.choice(POPULAR_ZONAL_ROUTE_IDS_TRIPS)\n",
    "                else: route_id_val = random.randint(1, MAX_ROUTE_ID_TRIPS) # General random choice\n",
    "                current_route_type_actual = get_route_type_from_id_trips(route_id_val)\n",
    "                fare_id_val = FARE_ID_STANDARD_CABLE_TRIPS if current_route_type_actual == \"CABLE\" else FARE_ID_STANDARD_SITP_TRIPS\n",
    "            else: # Transfer leg\n",
    "                # Determine new route type based on transfer logic\n",
    "                # This is simplified, assumes previous_route_type_actual is set\n",
    "                if prev_route_type_actual in [\"ZONAL_UCE\", \"ALIMENTADORA\"]:\n",
    "                    if random.random() < TRANSFER_TYPE_DIST_TRIPS[\"ZONAL_TO_ZONAL\"]:\n",
    "                        route_id_val = random.randint(ZONAL_UCE_ROUTE_IDS_RANGE_TRIPS[0], ZONAL_UCE_ROUTE_IDS_RANGE_TRIPS[1])\n",
    "                    else: # Zonal to Troncal/Cable\n",
    "                        route_id_val = random.choice(list(range(TRONCAL_ROUTE_IDS_RANGE_TRIPS[0],TRONCAL_ROUTE_IDS_RANGE_TRIPS[1]+1)) + list(range(DUAL_ROUTE_IDS_RANGE_TRIPS[0],DUAL_ROUTE_IDS_RANGE_TRIPS[1]+1)) + list(range(CABLE_ROUTE_IDS_RANGE_TRIPS[0],CABLE_ROUTE_IDS_RANGE_TRIPS[1]+1)))\n",
    "                elif prev_route_type_actual in [\"TRONCAL\", \"DUAL\", \"CABLE\"]: # Troncal/Cable to Zonal\n",
    "                    route_id_val = random.randint(ZONAL_UCE_ROUTE_IDS_RANGE_TRIPS[0], ZONAL_UCE_ROUTE_IDS_RANGE_TRIPS[1])\n",
    "                else: # Fallback\n",
    "                    route_id_val = random.randint(ZONAL_UCE_ROUTE_IDS_RANGE_TRIPS[0], ZONAL_UCE_ROUTE_IDS_RANGE_TRIPS[1])\n",
    "                \n",
    "                current_route_type_actual = get_route_type_from_id_trips(route_id_val)\n",
    "                fare_id_val = FARE_ID_TRANSFER_0_TRIPS if random.random() < 0.7 else FARE_ID_TRANSFER_200_TRIPS # Weighted transfer cost\n",
    "\n",
    "            vehicle_id_val = random.randint(1, MAX_VEHICLE_ID_TRIPS)\n",
    "            driver_id_val = random.randint(1, MAX_DRIVER_ID_TRIPS)\n",
    "            \n",
    "            conceptual_path = get_conceptual_path_for_route(route_id_val, current_route_type_actual)\n",
    "            if not conceptual_path or len(conceptual_path) < 1: # Need at least one station for origin/destination\n",
    "                 if is_first_leg: journeys_initiated_today +=1 # Count as an attempt\n",
    "                 break # End this journey if path is invalid\n",
    "\n",
    "            boarding_station_id_val, disembarking_station_id_val = None, None\n",
    "            boarding_time_obj, disembarking_time_obj = None, None\n",
    "            num_stops_on_leg = 0\n",
    "\n",
    "            if is_first_leg:\n",
    "                boarding_time_obj = get_boarding_time_trips(current_processing_date, day_type_for_time)\n",
    "                # Board anywhere except the very last station (if path > 1)\n",
    "                max_boarding_idx = len(conceptual_path) - 2 if len(conceptual_path) > 1 else 0\n",
    "                boarding_idx = random.randint(0, max_boarding_idx)\n",
    "                boarding_station_id_val = conceptual_path[boarding_idx]\n",
    "            else: # Transfer leg\n",
    "                boarding_time_obj = prev_disembark_time + timedelta(minutes=random.randint(5, TRANSFER_WINDOW_MINUTES_TRIPS - 10))\n",
    "                boarding_idx = 0 # Start at the conceptual origin of the new route for transfer\n",
    "                boarding_station_id_val = conceptual_path[boarding_idx]\n",
    "\n",
    "            # Ensure boarding time is within the current processing day (mostly)\n",
    "            if boarding_time_obj.date() != current_processing_date:\n",
    "                if boarding_time_obj > datetime.combine(current_processing_date + timedelta(days=1), time(4,0,0)) or \\\n",
    "                   boarding_time_obj < datetime.combine(current_processing_date, time(0,0,0)):\n",
    "                    if is_first_leg: journeys_initiated_today +=1\n",
    "                    break # Invalid time, break journey\n",
    "\n",
    "            # Disembark at a station after boarding_idx\n",
    "            if boarding_idx < len(conceptual_path) - 1:\n",
    "                disembarking_idx = random.randint(boarding_idx + 1, len(conceptual_path) -1)\n",
    "                disembarking_station_id_val = conceptual_path[disembarking_idx]\n",
    "                num_stops_on_leg = disembarking_idx - boarding_idx\n",
    "            else: # Boarded at the last conceptual stop, so disembark there (short/null trip for this leg)\n",
    "                disembarking_station_id_val = boarding_station_id_val\n",
    "                num_stops_on_leg = 0\n",
    "            \n",
    "            travel_secs = get_travel_time_seconds_trips(num_stops_on_leg, current_route_type_actual)\n",
    "            disembarking_time_obj = boarding_time_obj + timedelta(seconds=max(60, travel_secs)) # Min 1 min travel time\n",
    "\n",
    "            # Cap disembark time to avoid spilling too far into next day excessively\n",
    "            if disembarking_time_obj.date() > current_processing_date and disembarking_time_obj.time() > time(5,0,0):\n",
    "                disembarking_time_obj = datetime.combine(current_processing_date, time(23,58,0)) + timedelta(seconds=random.randint(0,119))\n",
    "                if disembarking_time_obj <= boarding_time_obj : disembarking_time_obj = boarding_time_obj + timedelta(minutes=5)\n",
    "\n",
    "\n",
    "            boarding_time_sql = boarding_time_obj.strftime('%Y-%m-%d %H:%M:%S')\n",
    "            disembarking_time_sql = disembarking_time_obj.strftime('%Y-%m-%d %H:%M:%S')\n",
    "            is_transfer_sql = 'TRUE' if not is_first_leg else 'FALSE'\n",
    "\n",
    "            all_trip_records_strings.append(\n",
    "                f\"({trip_id_val}, {card_id_val}, {vehicle_id_val}, {route_id_val}, {driver_id_val}, \"\n",
    "                f\"{boarding_station_id_val}, {disembarking_station_id_val}, '{boarding_time_sql}', '{disembarking_time_sql}', \"\n",
    "                f\"{fare_id_val}, {is_transfer_sql}, '{current_transfer_group_id_val}')\"\n",
    "            )\n",
    "            \n",
    "            if is_first_leg:\n",
    "                journeys_initiated_today += 1 # Count this as one main journey initiated for the day's target\n",
    "            \n",
    "            prev_disembark_time = disembarking_time_obj\n",
    "            prev_route_type_actual = current_route_type_actual\n",
    "            \n",
    "            if random.random() < PROB_TRANSFER_TRIPS:\n",
    "                is_first_leg = False # Next leg will be a transfer\n",
    "            else:\n",
    "                break # No more transfers for this journey\n",
    "    \n",
    "    total_trips_generated_for_log += journeys_initiated_today # Using initiated journeys for daily log\n",
    "    print(f\"Completed day {current_processing_date.strftime('%Y-%m-%d')}. Approx {journeys_initiated_today} journeys initiated. Total trips (legs) so far: {trip_id_counter}\")\n",
    "\n",
    "\n",
    "# --- Write to SQL file ---\n",
    "try:\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(\"INSERT INTO trips (trip_id, card_id, vehicle_id, route_id, driver_id, boarding_station_id, disembarking_station_id, boarding_time, disembarking_time, fare_id, is_transfer, transfer_group_id) OVERRIDING SYSTEM VALUE VALUES\\n\")\n",
    "        batch_size = 1000\n",
    "        for i, record_string in enumerate(all_trip_records_strings):\n",
    "            file.write(record_string)\n",
    "            if (i + 1) % batch_size == 0 and i < len(all_trip_records_strings) - 1:\n",
    "                file.write(\";\\n\")\n",
    "                file.write(\"INSERT INTO trips (trip_id, card_id, vehicle_id, route_id, driver_id, boarding_station_id, disembarking_station_id, boarding_time, disembarking_time, fare_id, is_transfer, transfer_group_id) OVERRIDING SYSTEM VALUE VALUES\\n\")\n",
    "            elif i < len(all_trip_records_strings) - 1:\n",
    "                file.write(\",\\n\")\n",
    "            else:\n",
    "                file.write(\";\\n\")\n",
    "    print(f\"SQL script for trips generated successfully: {os.path.abspath(output_file)}\")\n",
    "    print(f\"Total trip leg records generated: {len(all_trip_records_strings)}\")\n",
    "except IOError as e:\n",
    "    print(f\"Error writing to file {output_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3407bb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating ~416 realtime arrival predictions around 2024-06-04 07:30:00...\n",
      "SQL script for realtime_arrivals generated successfully: /home/kali/Documents/remote reps/distributed-systems-lab/travel-recharge-database/db/data/15_insert_realtime_arrivals.sql\n",
      "Total realtime_arrival records generated: 210\n"
     ]
    }
   ],
   "source": [
    "# Nombre del archivo: generate_realtime_arrivals.py\n",
    "import faker\n",
    "import random\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "fake_co = faker.Faker('es_CO')\n",
    "output_file = \"15_insert_realtime_arrivals.sql\"\n",
    "\n",
    "# --- Simulation Time (consistent with previous snapshots) ---\n",
    "SIMULATION_CURRENT_DATETIME_SNAPSHOT = datetime(2024, 6, 4, 7, 30, 0) # Martes, Junio 4, 2024, 07:30 AM\n",
    "\n",
    "# --- ID Ranges (from previous scripts) ---\n",
    "# Stations (Script 09)\n",
    "MAX_STATION_ID_SNAPSHOT = 7765\n",
    "PORTAL_IDS_SNAPSHOT = list(range(1, 9 + 1))\n",
    "TRONCAL_STATIONS_OTHER_SNAPSHOT = list(range(14, 142 + 1))\n",
    "STATIONS_FOR_ARRIVALS_SNAPSHOT = PORTAL_IDS_SNAPSHOT + random.sample(TRONCAL_STATIONS_OTHER_SNAPSHOT, k=min(30, len(TRONCAL_STATIONS_OTHER_SNAPSHOT)))\n",
    "\n",
    "# Routes (Script 12)\n",
    "TRONCAL_ROUTE_IDS_START_SNAPSHOT = 1 \n",
    "NUM_TRONCAL_ROUTES_GEN_SNAPSHOT = 99\n",
    "DUAL_ROUTE_IDS_START_SNAPSHOT = TRONCAL_ROUTE_IDS_START_SNAPSHOT + NUM_TRONCAL_ROUTES_GEN_SNAPSHOT\n",
    "NUM_DUAL_ROUTES_GEN_SNAPSHOT = 5\n",
    "RELEVANT_ROUTE_IDS_FOR_ARRIVALS_SNAPSHOT = list(range(TRONCAL_ROUTE_IDS_START_SNAPSHOT, TRONCAL_ROUTE_IDS_START_SNAPSHOT + NUM_TRONCAL_ROUTES_GEN_SNAPSHOT)) + \\\n",
    "                                          list(range(DUAL_ROUTE_IDS_START_SNAPSHOT, DUAL_ROUTE_IDS_START_SNAPSHOT + NUM_DUAL_ROUTES_GEN_SNAPSHOT))\n",
    "\n",
    "# Vehicles (Script 10)\n",
    "MAX_VEHICLE_ID_SNAPSHOT = 10563\n",
    "\n",
    "# --- Number of Records ---\n",
    "NUM_ARRIVALS_TO_GENERATE_TOTAL = random.randint(400, 700) # Total predictions in this snapshot\n",
    "\n",
    "print(f\"Generating ~{NUM_ARRIVALS_TO_GENERATE_TOTAL} realtime arrival predictions around {SIMULATION_CURRENT_DATETIME_SNAPSHOT.strftime('%Y-%m-%d %H:%M:%S')}...\")\n",
    "\n",
    "all_records_strings = []\n",
    "arrival_id_counter = 0\n",
    "\n",
    "# Distribute arrivals somewhat evenly among selected stations\n",
    "arrivals_per_station_target = NUM_ARRIVALS_TO_GENERATE_TOTAL // len(STATIONS_FOR_ARRIVALS_SNAPSHOT)\n",
    "if arrivals_per_station_target == 0: arrivals_per_station_target = 1\n",
    "\n",
    "\n",
    "for station_id_val in STATIONS_FOR_ARRIVALS_SNAPSHOT:\n",
    "    # For each station, show arrivals for a few routes\n",
    "    num_routes_displaying = random.randint(2, 5)\n",
    "    \n",
    "    for _ in range(num_routes_displaying):\n",
    "        if not RELEVANT_ROUTE_IDS_FOR_ARRIVALS_SNAPSHOT: continue\n",
    "        route_id_val = random.choice(RELEVANT_ROUTE_IDS_FOR_ARRIVALS_SNAPSHOT)\n",
    "        \n",
    "        # For this route at this station, generate 1 or 2 upcoming predictions\n",
    "        num_predictions_this_route = random.randint(1, 2)\n",
    "        last_arrival_offset_minutes = 0\n",
    "\n",
    "        for _ in range(num_predictions_this_route):\n",
    "            if arrival_id_counter >= NUM_ARRIVALS_TO_GENERATE_TOTAL: # Stop if total reached\n",
    "                break\n",
    "            \n",
    "            arrival_id_counter += 1\n",
    "            arrival_id_val = arrival_id_counter\n",
    "\n",
    "            vehicle_id_val = random.randint(1, MAX_VEHICLE_ID_SNAPSHOT)\n",
    "\n",
    "            # Stagger arrival times for the same route\n",
    "            current_offset = last_arrival_offset_minutes + random.randint(3 if last_arrival_offset_minutes == 0 else 7, \n",
    "                                                                         12 if last_arrival_offset_minutes == 0 else 20)\n",
    "            estimated_arrival_time_obj = SIMULATION_CURRENT_DATETIME_SNAPSHOT + timedelta(minutes=current_offset)\n",
    "            estimated_arrival_time_sql = estimated_arrival_time_obj.strftime('%Y-%m-%d %H:%M:%S')\n",
    "            last_arrival_offset_minutes = current_offset\n",
    "\n",
    "            status_val = \"EXPECTED\"\n",
    "            actual_arrival_time_sql = \"NULL\"\n",
    "            \n",
    "            rand_status_chance = random.random()\n",
    "            if rand_status_chance < 0.05 and current_offset <= 5: # Just arrived\n",
    "                status_val = \"ARRIVED\"\n",
    "                actual_arrival_obj = estimated_arrival_time_obj - timedelta(seconds=random.randint(0,90))\n",
    "                actual_arrival_time_sql = f\"'{actual_arrival_obj.strftime('%Y-%m-%d %H:%M:%S')}'\"\n",
    "            elif rand_status_chance < 0.10 and current_offset <= 10: # Delayed\n",
    "                status_val = \"DELAYED\"\n",
    "                # Update estimated_arrival_time for delayed buses\n",
    "                estimated_arrival_time_obj += timedelta(minutes=random.randint(2,6))\n",
    "                estimated_arrival_time_sql = estimated_arrival_time_obj.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            # Prediction created a few moments before the snapshot time\n",
    "            created_at_sql = (SIMULATION_CURRENT_DATETIME_SNAPSHOT - timedelta(seconds=random.randint(10, 180))).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            all_records_strings.append(\n",
    "                f\"({arrival_id_val}, {station_id_val}, {route_id_val}, {vehicle_id_val}, \"\n",
    "                f\"'{estimated_arrival_time_sql}', {actual_arrival_time_sql}, '{status_val}', '{created_at_sql}')\"\n",
    "            )\n",
    "        if arrival_id_counter >= NUM_ARRIVALS_TO_GENERATE_TOTAL: break\n",
    "    if arrival_id_counter >= NUM_ARRIVALS_TO_GENERATE_TOTAL: break\n",
    "\n",
    "\n",
    "try:\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(\"INSERT INTO realtime_arrivals (arrival_id, station_id, route_id, vehicle_id, estimated_arrival_time, actual_arrival_time, status, created_at) OVERRIDING SYSTEM VALUE VALUES\\n\")\n",
    "        batch_size = 1000\n",
    "        for i, record_string in enumerate(all_records_strings):\n",
    "            file.write(record_string)\n",
    "            if (i + 1) % batch_size == 0 and i < len(all_records_strings) - 1:\n",
    "                file.write(\";\\n\")\n",
    "                file.write(\"INSERT INTO realtime_arrivals (arrival_id, station_id, route_id, vehicle_id, estimated_arrival_time, actual_arrival_time, status, created_at) OVERRIDING SYSTEM VALUE VALUES\\n\")\n",
    "            elif i < len(all_records_strings) - 1:\n",
    "                file.write(\",\\n\")\n",
    "            else:\n",
    "                file.write(\";\\n\")\n",
    "    print(f\"SQL script for realtime_arrivals generated successfully: {os.path.abspath(output_file)}\")\n",
    "    print(f\"Total realtime_arrival records generated: {len(all_records_strings)}\")\n",
    "except IOError as e:\n",
    "    print(f\"Error writing to file {output_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c38c23b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating ~1567 route current location records around 2024-06-04 07:30:00...\n",
      "SQL script for route_current_location generated successfully: /home/kali/Documents/remote reps/distributed-systems-lab/travel-recharge-database/db/data/16_insert_route_current_location.sql\n",
      "Total route_current_location records generated: 1567\n"
     ]
    }
   ],
   "source": [
    "# Nombre del archivo: generate_route_current_location.py\n",
    "import faker\n",
    "import random\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "fake_co = faker.Faker('es_CO')\n",
    "output_file = \"16_insert_route_current_location.sql\"\n",
    "\n",
    "# --- Simulation Time (consistent with realtime_arrivals) ---\n",
    "SIMULATION_CURRENT_DATETIME_SNAPSHOT = datetime(2024, 6, 4, 7, 30, 0) # Martes, Junio 4, 2024, 07:30 AM\n",
    "\n",
    "# --- ID Ranges (from previous scripts) ---\n",
    "# Routes (Script 12)\n",
    "MAX_ROUTE_ID_SNAPSHOT_LOC = 558 # Total routes generated in script 12\n",
    "ALL_ROUTE_IDS_SNAPSHOT_LOC = list(range(1, MAX_ROUTE_ID_SNAPSHOT_LOC + 1))\n",
    "\n",
    "# Vehicles (Script 10)\n",
    "MAX_VEHICLE_ID_SNAPSHOT_LOC = 10563\n",
    "\n",
    "# --- Number of Records ---\n",
    "NUM_VEHICLES_TO_TRACK_SNAPSHOT = random.randint(1000, 1800)\n",
    "\n",
    "print(f\"Generating ~{NUM_VEHICLES_TO_TRACK_SNAPSHOT} route current location records around {SIMULATION_CURRENT_DATETIME_SNAPSHOT.strftime('%Y-%m-%d %H:%M:%S')}...\")\n",
    "\n",
    "all_records_strings = []\n",
    "location_update_id_counter = 0\n",
    "# Keep track of vehicles already assigned a location in this snapshot to promote uniqueness\n",
    "vehicles_with_location_snapshot = set()\n",
    "\n",
    "\n",
    "for _ in range(NUM_VEHICLES_TO_TRACK_SNAPSHOT):\n",
    "    location_update_id_counter += 1\n",
    "    location_update_id_val = location_update_id_counter\n",
    "\n",
    "    route_id_val = random.choice(ALL_ROUTE_IDS_SNAPSHOT_LOC)\n",
    "    \n",
    "    vehicle_id_val = None\n",
    "    for attempt in range(10): # Try to get a unique vehicle\n",
    "        temp_vid = random.randint(1, MAX_VEHICLE_ID_SNAPSHOT_LOC)\n",
    "        if temp_vid not in vehicles_with_location_snapshot:\n",
    "            vehicle_id_val = temp_vid\n",
    "            vehicles_with_location_snapshot.add(temp_vid)\n",
    "            break\n",
    "    if vehicle_id_val is None: # Fallback if all attempts fail\n",
    "        vehicle_id_val = random.randint(1, MAX_VEHICLE_ID_SNAPSHOT_LOC)\n",
    "        \n",
    "    # Plausible Lat/Long for Bogotá (general area, not specific to route path for this snapshot)\n",
    "    latitude_val = round(random.uniform(4.40, 4.80), 6)\n",
    "    longitude_val = round(random.uniform(-74.20, -74.00), 6)\n",
    "    \n",
    "    speed_val = round(random.uniform(5, 55), 2) # km/h, assuming moving\n",
    "    if random.random() < 0.15: # 15% chance vehicle is currently stopped\n",
    "        speed_val = 0.0\n",
    "        \n",
    "    timestamp_obj = SIMULATION_CURRENT_DATETIME_SNAPSHOT - timedelta(seconds=random.randint(5, 90)) # Location reported recently\n",
    "    timestamp_sql = timestamp_obj.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    all_records_strings.append(\n",
    "        f\"({location_update_id_val}, {route_id_val}, {vehicle_id_val}, {latitude_val}, {longitude_val}, {speed_val}, '{timestamp_sql}')\"\n",
    "    )\n",
    "\n",
    "try:\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(\"INSERT INTO route_current_location (location_update_id, route_id, vehicle_id, latitude, longitude, speed, \\\"timestamp\\\") OVERRIDING SYSTEM VALUE VALUES\\n\")\n",
    "        batch_size = 1000\n",
    "        for i, record_string in enumerate(all_records_strings):\n",
    "            file.write(record_string)\n",
    "            if (i + 1) % batch_size == 0 and i < len(all_records_strings) - 1:\n",
    "                file.write(\";\\n\")\n",
    "                file.write(\"INSERT INTO route_current_location (location_update_id, route_id, vehicle_id, latitude, longitude, speed, \\\"timestamp\\\") OVERRIDING SYSTEM VALUE VALUES\\n\")\n",
    "            elif i < len(all_records_strings) - 1:\n",
    "                file.write(\",\\n\")\n",
    "            else:\n",
    "                file.write(\";\\n\")\n",
    "    print(f\"SQL script for route_current_location generated successfully: {os.path.abspath(output_file)}\")\n",
    "    print(f\"Total route_current_location records generated: {len(all_records_strings)}\")\n",
    "except IOError as e:\n",
    "    print(f\"Error writing to file {output_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5a33880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating alert records contextualized around June 2024...\n",
      "SQL script for alerts generated successfully: /home/kali/Documents/remote reps/distributed-systems-lab/travel-recharge-database/db/data/17_insert_alerts.sql\n",
      "Total alert records generated: 30\n"
     ]
    }
   ],
   "source": [
    "# Nombre del archivo: generate_alerts.py\n",
    "import random\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "output_file = \"17_insert_alerts.sql\"\n",
    "\n",
    "# --- ID Ranges (from previous scripts) ---\n",
    "# Stations (Script 09)\n",
    "MAX_STATION_ID_ALERTS = 7765\n",
    "PORTAL_IDS_ALERTS = list(range(1, 9 + 1))\n",
    "TRONCAL_STATIONS_OTHER_ALERTS = list(range(14, 142 + 1))\n",
    "RELEVANT_STATION_IDS_FOR_ALERTS_PY = PORTAL_IDS_ALERTS + TRONCAL_STATIONS_OTHER_ALERTS # Keep variable name unique to script\n",
    "\n",
    "# Routes (Script 12)\n",
    "MAX_ROUTE_ID_ALERTS = 558 # Total routes from script 12\n",
    "RELEVANT_ROUTE_IDS_FOR_ALERTS_PY = list(range(1, MAX_ROUTE_ID_ALERTS + 1))\n",
    "\n",
    "print(\"Generating alert records contextualized around June 2024...\")\n",
    "\n",
    "alert_templates_list = [\n",
    "    {\"type\": \"STATION_ISSUE\", \"severity\": \"CRITICAL\", \"msg_template\": \"Estación {} presenta cierre temporal por novedad ajena a la operación. Rutas realizan desvíos.\", \"d_hr_min\": 2, \"d_hr_max\": 5, \"needs_station\": True},\n",
    "    {\"type\": \"STATION_ISSUE\", \"severity\": \"WARNING\", \"msg_template\": \"Alta afluencia de usuarios en estación {}. Considere mayor tiempo de espera.\", \"d_hr_min\": 1, \"d_hr_max\": 3, \"needs_station\": True},\n",
    "    {\"type\": \"STATION_ISSUE\", \"severity\": \"INFO\", \"msg_template\": \"Mantenimiento de ascensor en estación {}. Personal en sitio disponible.\", \"d_hr_min\": 24, \"d_hr_max\": 72, \"needs_station\": True},\n",
    "    {\"type\": \"ROUTE_DELAY\", \"severity\": \"WARNING\", \"msg_template\": \"Ruta {} con demoras de hasta 20 min por alta congestión vehicular en sector Chapinero.\", \"d_hr_min\": 1, \"d_hr_max\": 3, \"needs_route\": True},\n",
    "    {\"type\": \"ROUTE_INFO\", \"severity\": \"INFO\", \"msg_template\": \"Ruta {} operará con desvío por ciclovía nocturna el Jueves.\", \"d_hr_min\": 6, \"d_hr_max\": 6, \"needs_route\": True, \"future_event\": True, \"event_day_offset\": 3}, # Assuming current day is Monday for planning\n",
    "    {\"type\": \"SYSTEM_WIDE\", \"severity\": \"INFO\", \"msg_template\": \"Recuerde personalizar y recargar su tarjeta Tullave para acceder a beneficios.\", \"d_hr_min\": 24*10, \"d_hr_max\": 24*20, \"is_general\": True},\n",
    "    {\"type\": \"SERVICE_INFO\", \"severity\": \"INFO\", \"msg_template\": \"Servicio de cicloparqueaderos disponible. Consulte cupos en nuestra app.\", \"d_hr_min\": 24*5, \"d_hr_max\": 24*15, \"is_general\": True},\n",
    "    {\"type\": \"SYSTEM_WIDE\", \"severity\": \"WARNING\", \"msg_template\": \"Se prevén lluvias para la tarde. Planee su viaje.\", \"d_hr_min\": 4, \"d_hr_max\": 8, \"is_general\": True}\n",
    "]\n",
    "\n",
    "NUM_ALERTS_TO_GENERATE_PY = 30\n",
    "all_records_strings = []\n",
    "alert_id_counter = 0\n",
    "\n",
    "# Contexto temporal para las alertas (alrededor de Junio 2024)\n",
    "alert_context_start_date = datetime(2024, 5, 25)\n",
    "alert_context_end_date = datetime(2024, 6, 15)\n",
    "\n",
    "for i in range(NUM_ALERTS_TO_GENERATE_PY):\n",
    "    alert_id_counter += 1\n",
    "    alert_id_val = alert_id_counter\n",
    "    template = random.choice(alert_templates_list)\n",
    "\n",
    "    station_id_sql = \"NULL\"\n",
    "    route_id_sql = \"NULL\"\n",
    "    message_text = template[\"msg_template\"]\n",
    "\n",
    "    if template.get(\"needs_station\") and RELEVANT_STATION_IDS_FOR_ALERTS_PY:\n",
    "        s_id = random.choice(RELEVANT_STATION_IDS_FOR_ALERTS_PY)\n",
    "        station_id_sql = str(s_id)\n",
    "        message_text = template[\"msg_template\"].format(f\"Est.ID {s_id}\")\n",
    "    elif template.get(\"needs_route\") and RELEVANT_ROUTE_IDS_FOR_ALERTS_PY:\n",
    "        r_id = random.choice(RELEVANT_ROUTE_IDS_FOR_ALERTS_PY)\n",
    "        route_id_sql = str(r_id)\n",
    "        message_text = template[\"msg_template\"].format(f\"Ruta ID {r_id}\")\n",
    "    \n",
    "    message_sql = message_text.replace(\"'\", \"''\")\n",
    "    severity_sql = template[\"severity\"]\n",
    "    alert_type_sql = template[\"type\"]\n",
    "\n",
    "    duration_h = random.randint(template[\"d_hr_min\"], template[\"d_hr_max\"])\n",
    "    \n",
    "    if template.get(\"future_event\"):\n",
    "        # Starts a few days from a random point in our context window\n",
    "        base_day_for_future = alert_context_start_date + timedelta(days=random.randint(0,10))\n",
    "        start_ts_obj = base_day_for_future + timedelta(days=template.get(\"event_day_offset\", 1), hours=random.randint(6,10))\n",
    "    else:\n",
    "        # Starts at a random time within our context window\n",
    "        start_ts_obj = alert_context_start_date + timedelta(\n",
    "            days=random.randint(0, (alert_context_end_date - alert_context_start_date).days),\n",
    "            hours=random.randint(0,23), minutes=random.randint(0,59)\n",
    "        )\n",
    "    start_ts_sql = start_ts_obj.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    end_ts_sql = \"NULL\"\n",
    "    if random.random() < 0.7: # 70% of alerts have an end time\n",
    "        end_ts_obj = start_ts_obj + timedelta(hours=duration_h)\n",
    "        end_ts_sql = f\"'{end_ts_obj.strftime('%Y-%m-%d %H:%M:%S')}'\"\n",
    "    \n",
    "    all_records_strings.append(\n",
    "        f\"({alert_id_val}, '{message_sql}', '{severity_sql}', '{alert_type_sql}', \"\n",
    "        f\"'{start_ts_sql}', {end_ts_sql}, {station_id_sql}, {route_id_sql})\"\n",
    "    )\n",
    "\n",
    "try:\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(\"INSERT INTO alerts (alert_id, message, severity, alert_type, start_timestamp, end_timestamp, station_id, route_id) OVERRIDING SYSTEM VALUE VALUES\\n\")\n",
    "        for i, record_string in enumerate(all_records_strings):\n",
    "            file.write(record_string)\n",
    "            if i < len(all_records_strings) - 1:\n",
    "                file.write(\",\\n\")\n",
    "            else:\n",
    "                file.write(\";\\n\")\n",
    "    print(f\"SQL script for alerts generated successfully: {os.path.abspath(output_file)}\")\n",
    "    print(f\"Total alert records generated: {len(all_records_strings)}\")\n",
    "except IOError as e:\n",
    "    print(f\"Error writing to file {output_file}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
